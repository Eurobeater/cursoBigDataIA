{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practica 23 RNA Multicapa Regresor\n",
    "\n",
    "En este ejercicio vamos a trabajar con una RNA secuencial y el dataset MPG que consiste en un conjunto de datos clásico utilizado en problemas de regresión. \n",
    "\n",
    "Contiene información sobre el consumo de combustible de diferentes automóviles, medido en millas por galón (MPG). Además del consumo de combustible, el dataset incluye características como el número de cilindros, desplazamiento del motor, potencia, peso, aceleración, año del modelo y origen del vehículo.\n",
    "\n",
    "Características principales:\\\n",
    "MPG : Variable objetivo (dependiente). Representa las millas por galón que un automóvil puede recorrer con un galón de combustible.\\\n",
    "Cilindros : Número de cilindros en el motor.\\\n",
    "Desplazamiento : Volumen total del desplazamiento del motor (en pulgadas cúbicas).\\\n",
    "Potencia : Potencia del motor (en caballos de fuerza).\\\n",
    "Peso : Peso del vehículo (en libras).\\\n",
    "Aceleración : Tiempo en segundos para alcanzar una velocidad específica.\\\n",
    "Año : Año del modelo del automóvil.\\\n",
    "Origen : País de origen del automóvil (1: América, 2: Europa, 3: Asia).\\\n",
    "Este dataset es ideal para problemas de regresión, ya que intentamos predecir el valor continuo de MPG en función de las características mencionadas.\n",
    "\n",
    "Escalado (Scaling):\n",
    "Escalar las características implica ajustar el rango de los valores de las características para que estén dentro de un intervalo específico.\n",
    "El método más común de escalado es la estandarización (StandardScaler) , que transforma los datos para que tengan una media de 0 y una desviación estándar de 1. \n",
    "\n",
    "Para redes neuronales, generalmente se prefiere el escalado (StandardScaler) porque funcionan mejor cuando los datos están centrados en 0 y tienen una varianza unitaria.\n",
    "\n",
    "Métricas Utilizadas:Error Cuadrático Medio (MSE) y Coeficiente de Determinación (R²).\\\n",
    "(R² nos dice cuánto de lo que cambia en Y se puede predecir gracias a los datos de entrada X.)\n",
    "\n",
    "Funcion de activación:\\\n",
    "En problemas de regresión, la capa de salida no tiene función de activación para permitir la predicción de valores continuos sin restricciones.\n",
    "\n",
    "En las capas ocultas puede ser ReLu(relu), Sigmoide (sigmoid) o tangente hiperbólica (tanh) entre otras.\n",
    "\n",
    "Modelo secuencial (feedforward):\\\n",
    "Un modelo secuencial es un tipo de arquitectura de red neuronal en la que las capas están organizadas en una secuencia lineal , es decir, las conexiones entre las neuronas van en una sola dirección, de la entrada hacia la salida, sin ciclos ni retroalimentación.\n",
    "\n",
    "En términos prácticos, un modelo secuencial es como un \"tubo\" donde los datos fluyen de una capa a la siguiente, sin bifurcaciones ni conexiones complejas entre capas no consecutivas.\n",
    "Para crear un modelo secuencial primero se declara una estructura vacía a la que vas añadiendo capas Dense (u otros tipos de capas) para construir tu red neuronal. \n",
    "\n",
    "#----------------------------------------------------------------------------------------------\\\n",
    "Parámetros del método fit():\n",
    "\n",
    "X_train_scaled:\\\n",
    "Es el conjunto de datos de entrada para el entrenamiento (las características).\n",
    "En este caso ya está escalado, probablemente con StandardScaler o MinMaxScaler.\n",
    "\n",
    "y_train:\\\n",
    "Es el conjunto de etiquetas o salidas correspondiente a las entradas X_train_scaled.\n",
    "\n",
    "epochs=100:\\\n",
    "Indica cuántas veces se repite el entrenamiento completo sobre todo el conjunto de entrenamiento.\n",
    "→ Aquí entrenarás durante 100 ciclos completos.\n",
    "\n",
    "batch_size=32:\\\n",
    "El tamaño del lote (batch): la red actualiza sus pesos cada vez que procesa 32 muestras.\n",
    "→ Esto permite entrenar más rápido y estabiliza el aprendizaje.\n",
    "\n",
    "validation_split=0.2:\\\n",
    "Se reserva el 20% de los datos de entrenamiento para validación durante el entrenamiento.\n",
    "→ Esto se hace automáticamente, sin necesidad de tener un conjunto de validación aparte.\n",
    "\n",
    "verbose=1:\\\n",
    "Controla el nivel de información que se muestra por pantalla durante el entrenamiento.\n",
    "\n",
    "0: sin salida\n",
    "\n",
    "1: barra de progreso\n",
    "\n",
    "2: una línea por época\n",
    "→ En este caso, verás una barra de progreso con la pérdida y la precisión.\n",
    "\n",
    "----------------------------------------------------------------------------------\n",
    "Respecto del apartado de compilación del modelo hay que aclarar que:\\\n",
    "- El proceso de compilación prepara el modelo para que se pueda entrenar correctamente.\\\n",
    "- Define la estrategia que el modelo seguirá para aprender a partir de los datos de entrenamiento.\\\n",
    "- Sin la compilación, Keras no sabría qué optimizador usar ni cómo evaluar el error durante el entrenamiento.\\\n",
    "- Una vez que el modelo está compilado, podemos proceder con el entrenamiento del modelo.\\\n",
    "- Debemos especificar el optimizador a utilizar, la función de pérdida y las métricas a evaluar.\\\n",
    "\n",
    "El optimizador es el algoritmo que ajusta los pesos de la red para minimizar la función de pérdida durante el entrenamiento:\\\n",
    "\n",
    "Alternativas para \"optimice\":\\\n",
    "'adam' (Adaptive Moment Estimation) es uno de los más usados por su rapidez y buen desempeño general.\n",
    "\n",
    "'sgd': Gradiente descendente clásico (stochastic gradient descent).\n",
    "\n",
    "'rmsprop': Bueno para RNNs.\n",
    "\n",
    "'adagrad', 'adadelta', 'nadam': Variaciones adaptativas.\n",
    "\n",
    "\n",
    "La función de pérdida mide el error entre las predicciones del modelo y las etiquetas reales. El objetivo es minimizar esta pérdida durante el entrenamiento.\n",
    "\n",
    "Alternativas para \"loss\":\\\n",
    "'sparse_categorical_crossentropy': Se usa para clasificación multiclase cuando las etiquetas son enteros (0,1,2...) \n",
    "\n",
    "'categorical_crossentropy': Para clasificación multiclase con etiquetas en one-hot encoding.\n",
    "\n",
    "'binary_crossentropy': Para clasificación binaria (0 o 1).\n",
    "\n",
    "'mean_squared_error', 'mean_absolute_error': Para regresión.\n",
    "\n",
    "'hinge': Para clasificación tipo SVM.\n",
    "\n",
    "\n",
    "La métrica permite evaluar el rendimiento del modelo durante el entrenamiento y evaluación.\n",
    "\n",
    "Alternativas para \"metrics\":\\\n",
    "'accuracy': porcentaje de predicciones correctas.\n",
    "\n",
    "'mae': Error absoluto medio (útil en regresión).\n",
    "\n",
    "'mse': Error cuadrático medio.\n",
    "\n",
    "'Precision', 'Recall', 'AUC': Métricas más específicas para clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "0  18.0          8         307.0       130.0    3504          12.0   \n",
      "1  15.0          8         350.0       165.0    3693          11.5   \n",
      "2  18.0          8         318.0       150.0    3436          11.0   \n",
      "3  16.0          8         304.0       150.0    3433          12.0   \n",
      "4  17.0          8         302.0       140.0    3449          10.5   \n",
      "\n",
      "   model_year origin                       name  \n",
      "0          70    usa  chevrolet chevelle malibu  \n",
      "1          70    usa          buick skylark 320  \n",
      "2          70    usa         plymouth satellite  \n",
      "3          70    usa              amc rebel sst  \n",
      "4          70    usa                ford torino  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    392 non-null    float64\n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   origin        398 non-null    object \n",
      " 8   name          398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "None\n",
      "Registros de entrenamiento: 313\n",
      "Registros de test: 79\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 593.9805 - val_loss: 641.5266\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 532.7098 - val_loss: 616.6187\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 532.4515 - val_loss: 587.9912\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 532.7831 - val_loss: 554.3361\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 465.9974 - val_loss: 514.7284\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 419.1887 - val_loss: 466.8621\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 392.2576 - val_loss: 410.0706\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 328.0092 - val_loss: 347.1815\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 279.1275 - val_loss: 280.3584\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 220.7912 - val_loss: 215.3881\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 164.0642 - val_loss: 155.4126\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 109.7735 - val_loss: 106.7512\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 75.4175 - val_loss: 73.0184\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 59.4826 - val_loss: 53.2262\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 40.1335 - val_loss: 43.1214\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 35.1119 - val_loss: 36.7147\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.0390 - val_loss: 31.7634\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27.8021 - val_loss: 27.9795\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.3702 - val_loss: 25.0241\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 19.0881 - val_loss: 22.8126\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20.4820 - val_loss: 20.9640\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16.5965 - val_loss: 19.5648\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17.3949 - val_loss: 18.2225\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15.9275 - val_loss: 17.1117\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 16.3731 - val_loss: 16.1489\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17.2768 - val_loss: 15.3375\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 12.5406 - val_loss: 14.6738\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11.6130 - val_loss: 14.0580\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.5857 - val_loss: 13.4766\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.0002 - val_loss: 13.0073\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.3139 - val_loss: 12.4484\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11.4345 - val_loss: 12.0570\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10.1497 - val_loss: 11.7918\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.8752 - val_loss: 11.4098\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10.3328 - val_loss: 11.1077\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11.9422 - val_loss: 10.8477\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11.7154 - val_loss: 10.6468\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.9674 - val_loss: 10.4445\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.8757 - val_loss: 10.3189\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.5253 - val_loss: 10.0854\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.4367 - val_loss: 9.9752\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.6756 - val_loss: 9.8680\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.8392 - val_loss: 9.6476\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.0621 - val_loss: 9.5243\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6854 - val_loss: 9.2980\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.3156 - val_loss: 9.2914\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10.5641 - val_loss: 9.1355\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.5892 - val_loss: 9.0394\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.7628 - val_loss: 8.9948\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.7160 - val_loss: 8.8852\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6751 - val_loss: 8.7444\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5242 - val_loss: 8.7152\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.9907 - val_loss: 8.6271\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.9750 - val_loss: 8.6018\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.0857 - val_loss: 8.4770\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.4635 - val_loss: 8.4430\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6313 - val_loss: 8.3725\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.0738 - val_loss: 8.2813\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.0986 - val_loss: 8.1611\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9507 - val_loss: 8.2666\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.0786 - val_loss: 8.0797\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.2857 - val_loss: 8.0641\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.7806 - val_loss: 8.0207\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.9649 - val_loss: 7.9444\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.3197 - val_loss: 7.9230\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.2519 - val_loss: 7.8649\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.9958 - val_loss: 7.7802\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.4305 - val_loss: 7.7666\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.4832 - val_loss: 7.7306\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.3834 - val_loss: 7.6018\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.4227 - val_loss: 7.8047\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.3086 - val_loss: 7.6080\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.4654 - val_loss: 7.6066\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.8885 - val_loss: 7.4758\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.5853 - val_loss: 7.5788\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.4431 - val_loss: 7.4766\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.6801 - val_loss: 7.3157\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5738 - val_loss: 7.3183\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.9275 - val_loss: 7.3524\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.8144 - val_loss: 7.4630\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7024 - val_loss: 7.3297\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.8043 - val_loss: 7.2294\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.8380 - val_loss: 7.0492\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.6197 - val_loss: 7.2308\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4873 - val_loss: 7.2829\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.7035 - val_loss: 7.1904\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.6783 - val_loss: 7.1474\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5423 - val_loss: 7.0421\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.0811 - val_loss: 6.9858\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.3446 - val_loss: 6.9501\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.4350 - val_loss: 7.0660\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3744 - val_loss: 7.0636\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.1299 - val_loss: 7.0628\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.9004 - val_loss: 6.9696\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.0362 - val_loss: 6.8818\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.5947 - val_loss: 6.9728\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1264 - val_loss: 6.8127\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.7270 - val_loss: 6.8670\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.8653 - val_loss: 6.9725\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.4348 - val_loss: 6.9137\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "Calculando métricas\n",
      "Error Cuadrático Medio (MSE): 6.352077871774102\n",
      "Coeficiente de Determinación (R²): 0.8755484857623493\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd  # Para manipulación de datos\n",
    "import numpy as np  # Para operaciones numéricas\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
    "from sklearn.preprocessing import StandardScaler  # Para escalar las características\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Métricas para evaluar el modelo\n",
    "from tensorflow.keras.models import Sequential  # Para construir el modelo secuencial\n",
    "from tensorflow.keras.layers import Dense  # Capas densas para la red neuronal\n",
    "import seaborn as sns                      # Para carga del dataset MPG desde seaborn\n",
    "\n",
    "\n",
    "\n",
    "mpg_data = sns.load_dataset('mpg')  # Cargamos el dataset MPG\n",
    "\n",
    "# Exploramos el dataset\n",
    "print(mpg_data.head())  # Mostramos las primeras filas del dataset\n",
    "print(mpg_data.info())  # Información general del dataset (tipos de datos, valores nulos, etc.)\n",
    "\n",
    "# Limpieza de datos: Eliminamos filas con valores nulos\n",
    "mpg_data = mpg_data.dropna()  # Eliminamos filas con valores faltantes\n",
    "\n",
    "# Convertimos la columna 'origin' en variables categóricas (one-hot encoding)\n",
    "mpg_data = pd.get_dummies(mpg_data, columns=['origin'], drop_first=True)\n",
    "\n",
    "# Convertimos la columna 'horsepower' a valores numéricos, forzando los valores no numéricos a NaN \n",
    "# y luego eliminando filas con NaN\n",
    "mpg_data['horsepower'] = pd.to_numeric(mpg_data['horsepower'], errors='coerce')\n",
    "mpg_data = mpg_data.dropna(subset=['horsepower'])  # Elimina filas donde 'horsepower' es NaN\n",
    "\n",
    "# Definimos las características (X) y la variable objetivo (y)\n",
    "X = mpg_data[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', \n",
    "              'origin_usa', 'origin_japan']]  # Variables independientes (eliminamos 'name' que es texto)\n",
    "y = mpg_data['mpg']  # Variable dependiente (objetivo)\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Registros de entrenamiento:\", X_train.shape[0])\n",
    "print(\"Registros de test:\", X_test.shape[0])\n",
    "\n",
    "# Escalamos las características para mejorar el rendimiento de la red neuronal\n",
    "scaler = StandardScaler()  # Creamos un objeto para escalar\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Escalamos los datos de entrenamiento\n",
    "X_test_scaled = scaler.transform(X_test)  # Escalamos los datos de prueba\n",
    "\n",
    "# Construimos el modelo de red neuronal artificial\n",
    "modelo = Sequential()  # Inicializamos un modelo secuencial\n",
    "\n",
    "# Agregamos capas al modelo\n",
    "modelo.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))  # Capa oculta con 64 neuronas y función ReLU\n",
    "modelo.add(Dense(32, activation='relu'))  # Segunda capa oculta con 32 neuronas y función ReLU\n",
    "modelo.add(Dense(1))  # Capa de salida con 1 neurona (para regresión)\n",
    "\n",
    "\n",
    "\n",
    "# Compilamos el modelo\n",
    "modelo.compile(optimizer='adam', loss='mse')  # Usamos el optimizador Adam y la función de pérdida MSE (Error Cuadrático Medio)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "historia = modelo.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluamos el modelo en el conjunto de prueba\n",
    "predicciones = modelo.predict(X_test_scaled)  # Realizamos predicciones en los datos de prueba\n",
    "\n",
    "# Calculamos las métricas de evaluación\n",
    "print(f\"\\nCalculando métricas despues de pasar valores de test\")\n",
    "mse = mean_squared_error(y_test, predicciones)  # Error Cuadrático Medio\n",
    "r2 = r2_score(y_test, predicciones)  # Coeficiente de Determinación (R²)\n",
    "\n",
    "# Mostramos las métricas\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2}\")\n",
    "\n",
    "# Comentarios adicionales:\n",
    "# - El Error Cuadrático Medio (MSE) mide el promedio de los errores al cuadrado entre las predicciones y los valores reales.\n",
    "# - El Coeficiente de Determinación (R²) indica qué tan bien se ajusta el modelo a los datos. Un valor cercano a 1 es ideal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntas:\n",
    "- Tipo de funcion de activación utilizada en capas ocultas.\n",
    "- Estructura de la RNA. Cuantas capas ocultas y cuantas neuronas en cada capa, incluida la de salida?\n",
    "- ¿En cuantos bloques se divide cada epoca?\n",
    "- ¿Notamos algún cambio significativo si en lugar de reservar el 20% para valización inter-epoca utilizamos solo el 10%?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: Repite el entrenamiento y prueba con la funcion sigmoide. Compara los mejores resultados.\n",
    "\n",
    "\n",
    "Ejercicio: Tomando como referencia el codigo disponible en el archivo \"punto de ruptura\", modifica el programa para\n",
    "conseguir que el entrenamiento finalice después de que le valor val_loss no mejores en 5 epocas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
