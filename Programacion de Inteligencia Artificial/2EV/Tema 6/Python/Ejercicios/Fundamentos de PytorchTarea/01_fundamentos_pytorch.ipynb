{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSNK7duj5SeU"
   },
   "source": [
    "# Módulo 1. Fundamentos de PyTorch\n",
    "\n",
    "## ¿Qué es PyTorch?\n",
    "\n",
    "[PyTorch](https://pytorch.org/) es un framework de aprendizaje automático y profundo de código abierto.\n",
    "\n",
    "## ¿Para qué se puede usar PyTorch?\n",
    "\n",
    "PyTorch te permite manipular y procesar datos y escribir algoritmos de aprendizaje automático usando código en Python.\n",
    "\n",
    "## ¿Quién usa PyTorch?\n",
    "\n",
    "Muchas de las compañías de tecnología más grandes del mundo, como [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla y Microsoft, así como empresas de investigación en inteligencia artificial como [OpenAI usan PyTorch](https://openai.com/blog/openai-pytorch/) para impulsar la investigación y llevar el aprendizaje automático a sus productos.\n",
    "\n",
    "Por ejemplo, Andrej Karpathy (jefe de IA en Tesla) ha dado varias charlas ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) sobre cómo Tesla usa PyTorch para potenciar sus modelos de visión computacional para conducción autónoma.\n",
    "\n",
    "PyTorch también se usa en otras industrias, como en la agricultura, para [potenciar la visión computacional en tractores](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
    "\n",
    "## ¿Por qué usar PyTorch?\n",
    "\n",
    "A los investigadores de aprendizaje automático les encanta usar PyTorch. Y a partir de febrero de 2022, PyTorch es el [framework de aprendizaje profundo más usado en Papers With Code](https://paperswithcode.com/trends), un sitio web que sigue artículos de investigación en aprendizaje automático y los repositorios de código asociados.\n",
    "\n",
    "PyTorch también se encarga de muchas cosas detrás de escena, como la aceleración con GPU (haciendo que tu código se ejecute más rápido).\n",
    "\n",
    "Esto te permite concentrarte en manipular datos y escribir algoritmos, mientras PyTorch se asegura de que se ejecuten rápido.\n",
    "\n",
    "Y si compañías como Tesla y Meta (Facebook) lo usan para construir modelos que implementan en cientos de aplicaciones, impulsan miles de autos y entregan contenido a miles de millones de personas, también está claro que es capaz en el frente de desarrollo.\n",
    "\n",
    "## Qué vamos a cubrir en este módulo\n",
    "\n",
    "Este curso está dividido en diferentes secciones (notebooks).\n",
    "\n",
    "Cada notebook cubre ideas y conceptos importantes dentro de PyTorch.\n",
    "\n",
    "Los notebooks siguientes se basan en el conocimiento del anterior (la numeración empieza en 00, 01, 02 y continúa hasta donde sea necesario).\n",
    "\n",
    "Este notebook trata sobre el bloque básico del aprendizaje automático y profundo, el tensor.\n",
    "\n",
    "Específicamente, vamos a cubrir:\n",
    "\n",
    "| **Tema** | **Contenido** |\n",
    "| ----- | ----- |\n",
    "| **Introducción a los tensores** | Los tensores son el bloque básico de todo el aprendizaje automático y profundo. |\n",
    "| **Creación de tensores** | Los tensores pueden representar casi cualquier tipo de datos (imágenes, palabras, tablas de números). |\n",
    "| **Obtener información de los tensores** | Si puedes poner información en un tensor, también querrás obtenerla. |\n",
    "| **Manipulación de tensores** | Los algoritmos de aprendizaje automático (como las redes neuronales) implican manipular tensores de muchas maneras, como sumarlos, multiplicarlos, combinarlos. |\n",
    "| **Manejo de las formas de los tensores** | Uno de los problemas más comunes en el aprendizaje automático es manejar desajustes de forma (intentar mezclar tensores con formas incorrectas con otros tensores). |\n",
    "| **Indexación en tensores** | Si has indexado en una lista de Python o un array de NumPy, es muy similar con tensores, salvo que pueden tener muchas más dimensiones. |\n",
    "| **Mezcla de tensores de PyTorch y NumPy** | PyTorch maneja tensores ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy maneja arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) a veces querrás combinarlos. |\n",
    "| **Reproducibilidad** | El aprendizaje automático es muy experimental y como usa mucha *aleatoriedad* para funcionar, a veces querrás que esa *aleatoriedad* no sea tan aleatoria. |\n",
    "| **Ejecutar tensores en GPU** | Las GPUs (unidades de procesamiento gráfico) hacen que tu código sea más rápido, PyTorch facilita la ejecución de tu código en GPUs. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v3iRCRUTGeu"
   },
   "source": [
    "## Importar PyTorch\n",
    "\n",
    "> **Nota:** Echa un ojo primero a los pasos para poner en marcha PyTorch [PyTorch setup steps](https://pytorch.org/get-started/locally/). \n",
    "\n",
    "Importamos torch y vemos su version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:46:09.774180Z",
     "start_time": "2024-11-28T14:46:09.771565Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1VxEOik46Y4i",
    "outputId": "f3141076-29bc-4600-c1c3-1586b1fe2292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "#importa pytorch y comprueba su versión\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-33BKR16iWc"
   },
   "source": [
    "## Introducción a los tensores\n",
    "\n",
    "Ahora que hemos importado PyTorch, es momento de aprender sobre los tensores.\n",
    "\n",
    "Los tensores son el bloque fundamental del aprendizaje automático.\n",
    "\n",
    "Su función es representar datos de manera numérica.\n",
    "\n",
    "Por ejemplo, podrías representar una imagen como un tensor con forma `[3, 224, 224]`, lo que significaría `[canales_de_color, altura, anchura]`, ya que la imagen tiene `3` canales de color (rojo, verde, azul), una altura de `224` píxeles y una anchura de `224` píxeles.\n",
    "\n",
    "\n",
    "En el lenguaje de los tensores, el tensor tendría tres dimensiones, una para `canales_de_color`, otra para `altura` y otra para `anchura`.\n",
    "\n",
    "Pero estamos adelantándonos.\n",
    "\n",
    "Vamos a aprender más sobre los tensores programándolos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFF0N2TU7S7Q"
   },
   "source": [
    "### Creación de tensores\n",
    "\n",
    "A PyTorch le encantan los tensores. Tanto que tiene una página completa de documentación dedicada a la clase [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html).\n",
    "\n",
    "Tu primera tarea es [leer la documentación de `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) durante 10 minutos. Pero eso lo puedes hacer más adelante.\n",
    "\n",
    "Vamos a programar.\n",
    "\n",
    "Lo primero que vamos a crear es un **escalar**.\n",
    "\n",
    "Un escalar es un solo número y, en el lenguaje de los tensores, es un tensor de dimensión cero.\n",
    "\n",
    "> **Nota:** Esa es una tendencia en este curso. Nos enfocaremos en escribir código específico. Pero, a menudo, estableceré ejercicios que impliquen leer y familiarizarse con la documentación de PyTorch. Porque, después de todo, una vez que termines este curso, sin duda querrás aprender más. Y la documentación será un lugar que visitarás con frecuencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:14.630260Z",
     "start_time": "2024-11-21T07:49:14.583677Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUDgG2zk7Us5",
    "outputId": "0ac22bd2-16bc-4307-f312-31ae89d6c375"
   },
   "outputs": [],
   "source": [
    "# crea un tensor escalar\n",
    "escalar = torch.tensor(3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:14.731167Z",
     "start_time": "2024-11-21T07:49:14.725256Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV98Yz868bav",
    "outputId": "502a625e-ff3c-4fc4-b523-f7634ea82128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor escalar: tensor(3.1400)\n",
      "Dimensión: 0\n"
     ]
    }
   ],
   "source": [
    "# comprueba su dimensión\n",
    "print(\"Tensor escalar:\", escalar)\n",
    "print(\"Dimensión:\", escalar.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO2YW_QGTGez"
   },
   "source": [
    "¿Qué pasa si queremos recuperar el número del tensor?\n",
    "\n",
    "Es decir, convertirlo de `torch.Tensor` a un número entero en Python.\n",
    "\n",
    "Para hacerlo, podemos usar el método `item()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:14.815011Z",
     "start_time": "2024-11-21T07:49:14.810289Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k4cyKumPfbE",
    "outputId": "1f6a7916-0c7c-403f-8ebd-875454a94470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalar: 3.140000104904175\n",
      "Tipo: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Consigue el escalar del tensor anterior\n",
    "valor = escalar.item()\n",
    "\n",
    "print(\"Escalar:\", valor)\n",
    "print(\"Tipo:\", type(valor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:14.987652Z",
     "start_time": "2024-11-21T07:49:14.969516Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IZF6ASs8QH9",
    "outputId": "e556ed2a-e58a-440f-b103-0f06c91bc75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor de tipo vector\n",
    "vector = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:15.116491Z",
     "start_time": "2024-11-21T07:49:15.110059Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03hm3VVv8kr4",
    "outputId": "2035bb26-0189-4b28-fa02-34220d44677f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Cuantas dimensiones tiene?\n",
    "print(vector.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:15.236069Z",
     "start_time": "2024-11-21T07:49:15.219538Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zREV1bDTGe2",
    "outputId": "2a6e7ceb-7eb2-422b-b006-2c6e4825272f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# comprueba su forma\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:15.361426Z",
     "start_time": "2024-11-21T07:49:15.353339Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5iNwCYL8QO9",
    "outputId": "88fc63a7-4130-4c7a-a574-c61e85d2e99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Crea ahora un tensor de tipo matriz\n",
    "matriz = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(matriz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:21.159340Z",
     "start_time": "2024-11-21T07:49:21.153045Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LREUbeb8r8j",
    "outputId": "636246b0-b109-472a-c6d5-8601a9e08654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Comprueba el número de dimensiones\n",
    "print(matriz.dim())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:21.213035Z",
     "start_time": "2024-11-21T07:49:21.205138Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TL26I31TGe3",
    "outputId": "f05ec0b6-0bc1-4381-9474-56cbe6c67139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Comprueba la forma de la matriz\n",
    "print(matriz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:21.725926Z",
     "start_time": "2024-11-21T07:49:21.707652Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEMDQr188QWW",
    "outputId": "4230e6bd-1844-4210-eea8-245bb8b8b265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.],\n",
      "         [10., 11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "# Crea ahora un tensor de tres dimensiones\n",
    "tensor_3d = torch.tensor([\n",
    "    [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], [[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]\n",
    "])\n",
    "\n",
    "print(tensor_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.260052Z",
     "start_time": "2024-11-21T07:49:22.251600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dhuEsjS8QcT",
    "outputId": "7a45df1b-fc32-4cc5-e330-527c6ef7ba5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Comprueba su forma y dimensión\n",
    "print(tensor_3d.shape)\n",
    "print(tensor_3d.dim())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dms7G4nkTGe5"
   },
   "source": [
    "### Tensores aleatorios\n",
    "\n",
    "Hemos establecido que los tensores representan alguna forma de datos.\n",
    "\n",
    "Y los modelos de aprendizaje automático, como las redes neuronales, manipulan y buscan patrones dentro de los tensores.\n",
    "\n",
    "Sin embargo, al construir modelos de aprendizaje automático con PyTorch, es raro que crees tensores a mano (como lo hemos estado haciendo).\n",
    "\n",
    "En cambio, un modelo de aprendizaje automático a menudo comienza con grandes tensores aleatorios de números y ajusta estos números aleatorios mientras procesa datos para representarlos mejor.\n",
    "\n",
    "En esencia:\n",
    "\n",
    "`Comienza con números aleatorios -> observa los datos -> actualiza los números aleatorios -> observa los datos -> actualiza los números aleatorios...`\n",
    "\n",
    "Como científico de datos, puedes definir cómo inicia el modelo de aprendizaje automático (inicialización), cómo observa los datos (representación) y cómo actualiza (optimización) sus números aleatorios.\n",
    "\n",
    "Practicaremos estos pasos más adelante.\n",
    "\n",
    "Por ahora, veamos cómo crear un tensor de números aleatorios.\n",
    "\n",
    "Podemos hacerlo usando [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) y pasando el parámetro `size`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.434262Z",
     "start_time": "2024-11-21T07:49:22.375312Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOJEtDx--GnK",
    "outputId": "2680d44b-e31c-4ab1-d5b1-c0cd76706a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3696, 0.6876, 0.1265, 0.0738],\n",
      "        [0.0175, 0.5356, 0.4067, 0.3878],\n",
      "        [0.8914, 0.3718, 0.2565, 0.8675]])\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor aleatorio de tamaño (3, 4)\n",
    "tensor_random = torch.rand(3, 4)\n",
    "\n",
    "print(tensor_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wB1c_cXTGe5"
   },
   "source": [
    "La flexibilidad de `torch.rand()` radica en que podemos ajustar el `size` para que sea lo que queramos.\n",
    "\n",
    "Por ejemplo, supongamos que quieres un tensor aleatorio con la forma común de imagen `[224, 224, 3]` (`[altura, anchura, canales_de_color]`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.498909Z",
     "start_time": "2024-11-21T07:49:22.493170Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMF_NUp3Ym__",
    "outputId": "8346b853-0b1e-481a-d9ee-a410ee21bab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor aleatorio de tamaño (224, 224, 3)\n",
    "tensor_random_2 = torch.rand(224, 224, 3)\n",
    "\n",
    "print(tensor_random_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MQNTY0eTGe6"
   },
   "source": [
    "### Ceros y unos\n",
    "\n",
    "A veces querrás llenar tensores solo con ceros o unos.\n",
    "\n",
    "Esto ocurre mucho con el enmascaramiento (como enmascarar algunos de los valores en un tensor con ceros para indicarle al modelo que no los aprenda).\n",
    "\n",
    "Vamos a crear un tensor lleno de ceros con [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
    "\n",
    "De nuevo, el parámetro `size` entra en juego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.611047Z",
     "start_time": "2024-11-21T07:49:22.591202Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCzhd0hl9Vp6",
    "outputId": "9c8ec87f-d8c9-4751-a13e-6a5e986daaa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor de ceros con forma 3,4 y muestra su tipo\n",
    "tensor_ceros = torch.zeros(size=(3, 4))\n",
    "\n",
    "print(tensor_ceros)\n",
    "print( tensor_ceros.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.742366Z",
     "start_time": "2024-11-21T07:49:22.736202Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRe6sSXiTGe6",
    "outputId": "3f45b0b8-7f65-423d-c664-f5b5f7866fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor de unos de forma 3,4 y muestra su tipo\n",
    "tensor_unos = torch.ones(size=(3, 4))\n",
    "\n",
    "print(tensor_unos)\n",
    "print(tensor_unos.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hib1NYrSarL2"
   },
   "source": [
    "### Creación de un rango y tensores similares\n",
    "\n",
    "A veces es posible que necesites un rango de números, como de 1 a 10 o de 0 a 100.\n",
    "\n",
    "Puedes usar `torch.arange(start, end, step)` para hacerlo.\n",
    "\n",
    "Donde:\n",
    "* `start` = inicio del rango (por ejemplo, 0)\n",
    "* `end` = fin del rango (por ejemplo, 10)\n",
    "* `step` = cantidad de pasos entre cada valor (por ejemplo, 1)\n",
    "\n",
    "> **Nota:** En Python, puedes usar `range()` para crear un rango. Sin embargo, en PyTorch, `torch.range()` está en desuso y podría mostrar un error en el futuro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.866419Z",
     "start_time": "2024-11-21T07:49:22.855417Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IqUs81d9W4W",
    "outputId": "2a6f0c08-052e-4b36-b4eb-6a537239026f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "# Usa torch.arange() para crear un tensor con valores de 0 a 10\n",
    "rango = torch.arange(start=0, end=11)\n",
    "\n",
    "print(rango)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-bXf0Ugbh-D"
   },
   "source": [
    "A veces puede que necesites un tensor de un cierto tipo con la misma forma que otro tensor.\n",
    "\n",
    "Por ejemplo, un tensor lleno de ceros con la misma forma que un tensor anterior.\n",
    "\n",
    "Para hacerlo, puedes usar [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) o [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html), que devuelven un tensor lleno de ceros o unos, respectivamente, con la misma forma que el `input`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:22.967374Z",
     "start_time": "2024-11-21T07:49:22.961659Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvXwUut5BhHq",
    "outputId": "096b2f8e-8c21-4ace-97b9-c36b92b2fe77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor de ceros con la misma forma que el anterior\n",
    "rango = torch.arange(start=0, end=11)\n",
    "ceros_como_rango = torch.zeros_like(rango)\n",
    "\n",
    "print(ceros_como_rango)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huKZ6QlYTGe7"
   },
   "source": [
    "### Tipos de datos de tensores\n",
    "\n",
    "Existen muchos [tipos de datos de tensores disponibles en PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "Algunos son específicos para CPU y otros son mejores para GPU.\n",
    "\n",
    "Familiarizarse con ellos puede llevar tiempo.\n",
    "\n",
    "Generalmente, si ves `torch.cuda` en alguna parte, el tensor está siendo usado para GPU (ya que las GPUs de Nvidia usan un conjunto de herramientas de computación llamado CUDA).\n",
    "\n",
    "El tipo más común (y generalmente el predeterminado) es `torch.float32` o `torch.float`.\n",
    "\n",
    "Esto se conoce como \"punto flotante de 32 bits\".\n",
    "\n",
    "Pero también existe el punto flotante de 16 bits (`torch.float16` o `torch.half`) y el de 64 bits (`torch.float64` o `torch.double`).\n",
    "\n",
    "Y para complicarlo aún más, también hay enteros de 8, 16, 32 y 64 bits.\n",
    "\n",
    "¡Y más!\n",
    "\n",
    "> **Nota:** Un número entero es un número redondo como `7`, mientras que un número en punto flotante tiene un decimal, como `7.0`.\n",
    "\n",
    "La razón de todos estos tipos de datos tiene que ver con la **precisión en la computación**.\n",
    "\n",
    "La precisión es la cantidad de detalle utilizada para describir un número.\n",
    "\n",
    "Cuanto mayor es el valor de precisión (8, 16, 32), más detalle y, por ende, más datos se usan para expresar un número.\n",
    "\n",
    "Esto es importante en el aprendizaje profundo y la computación numérica porque, al realizar tantas operaciones, cuanto más detalle tienes para calcular, más recursos computacionales necesitas.\n",
    "\n",
    "Por lo tanto, los tipos de datos de menor precisión son generalmente más rápidos de calcular, pero sacrifican algo de rendimiento en métricas de evaluación como la precisión (más rápido de calcular pero menos preciso).\n",
    "\n",
    "> **Recursos:** \n",
    "  * Consulta la [documentación de PyTorch para ver la lista de todos los tipos de datos de tensores disponibles](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Lee la [página de Wikipedia para obtener una descripción general de la precisión en computación](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "Veamos cómo crear algunos tensores con tipos de datos específicos. Podemos hacerlo usando el parámetro `dtype`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.097560Z",
     "start_time": "2024-11-21T07:49:23.089792Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3MoGnpw9XaF",
    "outputId": "61070939-8c52-4ac6-bed7-e64b3ce24615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor con el tipo por defecto (float32)\n",
    "# Usando float32 por la documentación\n",
    "tensor_f32 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "\n",
    "print(tensor_f32)\n",
    "print(tensor_f32.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhP8kzDfe_ty"
   },
   "source": [
    "\n",
    "Aparte de los problemas de forma (las formas de los tensores no coinciden), dos de los problemas más comunes que encontrarás en PyTorch son los de tipo de dato y de dispositivo.\n",
    "\n",
    "Por ejemplo, uno de los tensores es `torch.float32` y el otro es `torch.float16` (PyTorch suele preferir que los tensores tengan el mismo formato).\n",
    "\n",
    "O uno de tus tensores está en la CPU y el otro en la GPU (a PyTorch le gusta que los cálculos entre tensores se realicen en el mismo dispositivo).\n",
    "\n",
    "Veremos más sobre esta cuestión de dispositivos más adelante.\n",
    "\n",
    "Por ahora, vamos a crear un tensor con `dtype=torch.float16`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.261317Z",
     "start_time": "2024-11-21T07:49:23.255613Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKSuajld_09s",
    "outputId": "cbac29d9-3371-4fe1-b47c-3af4623b5fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# crea un tensor float_16_tensor con el tipo dtype=torch.float16\n",
    "tensor_f16 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float16)\n",
    "\n",
    "print(tensor_f16)\n",
    "print(tensor_f16.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUjkB2AX7Upz"
   },
   "source": [
    "## Obtener información de los tensores\n",
    "\n",
    "Una vez que has creado tensores (o alguien más o un módulo de PyTorch los ha creado por ti), es posible que quieras obtener alguna información de ellos.\n",
    "\n",
    "Ya los hemos visto antes, pero tres de los atributos más comunes que querrás conocer sobre los tensores son:\n",
    "* `shape` - ¿cuál es la forma del tensor? (algunas operaciones requieren reglas específicas de forma)\n",
    "* `dtype` - ¿en qué tipo de datos están almacenados los elementos dentro del tensor?\n",
    "* `device` - ¿en qué dispositivo está almacenado el tensor? (usualmente GPU o CPU)\n",
    "\n",
    "Vamos a crear un tensor aleatorio y obtener detalles sobre él.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.367625Z",
     "start_time": "2024-11-21T07:49:23.357599Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd_X4D0j7Umq",
    "outputId": "86045713-ab36-4c8e-840c-e788f80c5266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2336, 0.3358, 0.3961, 0.0517],\n",
      "        [0.4781, 0.2118, 0.3505, 0.3373],\n",
      "        [0.8359, 0.9379, 0.4529, 0.9478]])\n",
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor aleatorio de forma 3,4\n",
    "tensor_random3 = torch.rand(size=(3, 4))\n",
    "\n",
    "# Imprimir sus detalles\n",
    "print(tensor_random3)\n",
    "print(tensor_random3.shape)\n",
    "print(tensor_random3.dtype)\n",
    "print(tensor_random3.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdiWvoAi7UjL"
   },
   "source": [
    "## Manipulación de tensores (operaciones con tensores)\n",
    "\n",
    "En el aprendizaje profundo, los datos (imágenes, texto, video, audio, estructuras de proteínas, etc.) se representan como tensores.\n",
    "\n",
    "Un modelo aprende investigando esos tensores y realizando una serie de operaciones (que pueden ser millones) sobre los tensores para crear una representación de los patrones en los datos de entrada.\n",
    "\n",
    "Estas operaciones suelen ser una combinación entre:\n",
    "* Suma\n",
    "* Resta\n",
    "* Multiplicación (elemento a elemento)\n",
    "* División\n",
    "* Multiplicación de matrices\n",
    "\n",
    "Y eso es todo. Claro que hay algunas otras aquí y allá, pero estos son los bloques básicos de las redes neuronales.\n",
    "\n",
    "Apilando estos bloques básicos de la manera correcta, puedes crear las redes neuronales más sofisticadas (¡como si fueran piezas de lego!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk_6Dd7L7Uce"
   },
   "source": [
    "### Operaciones básicas\n",
    "\n",
    "Empecemos con algunas de las operaciones fundamentales: suma (`+`), resta (`-`), multiplicación (`*`).\n",
    "\n",
    "Funcionan tal como esperarías.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.464380Z",
     "start_time": "2024-11-21T07:49:23.456907Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X71WpQoPD7a4",
    "outputId": "ab30f13e-fc67-4ae4-c5ce-1006410dba07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11., 12., 13.])\n"
     ]
    }
   ],
   "source": [
    "tensor_operaciones = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# suma 10 a un tensor\n",
    "suma = tensor_operaciones + 10\n",
    "\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.568483Z",
     "start_time": "2024-11-21T07:49:23.554852Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp4TlTWWEFeO",
    "outputId": "ce7d2296-881f-4eb3-802e-fd12bc25d6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 20., 30.])\n"
     ]
    }
   ],
   "source": [
    "# multiplica por 10 un tensor\n",
    "multiplicacion = tensor_operaciones * 10\n",
    "\n",
    "print(multiplicacion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1VEHnuRkn8Q"
   },
   "source": [
    "Puedes comprobar que los tensores original no se modifican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original: tensor([1., 2., 3.])\n",
      "tensor([-9., -8., -7.])\n"
     ]
    }
   ],
   "source": [
    "# Resta 10 al tensor y reasigna\n",
    "tensor_reasignado = tensor_operaciones - 10\n",
    "\n",
    "print(tensor_reasignado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.642180Z",
     "start_time": "2024-11-21T07:49:23.637732Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuB1UjCIEJIA",
    "outputId": "57cae862-c145-4681-d74b-fe6d77f2125a"
   },
   "outputs": [],
   "source": [
    "# Los tensores no cambian, a no ser que reasignes\n",
    "print(tensor_operaciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch también tiene un conjunto de funciones integradas como [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (abreviatura de  `multiply`) y [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) para realizar operaciones básicas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:23.726367Z",
     "start_time": "2024-11-21T07:49:23.708116Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4iWKoLsENry",
    "outputId": "14d6771d-eb57-4b11-88a7-b1bb308ddc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 20., 30.])\n"
     ]
    }
   ],
   "source": [
    "# Multiplica el tensor por 10 usando las funciones de torch\n",
    "tensor_multiplicado_10 = torch.mul(tensor_operaciones, 10)\n",
    "\n",
    "print(tensor_multiplicado_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n"
     ]
    }
   ],
   "source": [
    "# Realiza una multiplicación de tensores por elemento \n",
    "# (cada elemento multiplica su equivalente, index 0->0, 1->1, 2->2)\n",
    "tensor_multiplicar_por_elemento = torch.tensor([4.0, 5.0, 6.0])\n",
    "resultado = torch.mul(tensor_operaciones, tensor_multiplicar_por_elemento)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT5fVuyu7q5z"
   },
   "source": [
    "### Multiplicación de matrices\n",
    "\n",
    "Una de las operaciones más comunes en los algoritmos de aprendizaje automático y aprendizaje profundo (como las redes neuronales) es la [multiplicación de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "PyTorch implementa la funcionalidad de multiplicación de matrices en el método [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Las dos reglas principales para recordar en la multiplicación de matrices son:\n",
    "\n",
    "1. Las **dimensiones internas** deben coincidir:\n",
    "   * `(3, 2) @ (3, 2)` no funcionará\n",
    "   * `(2, 3) @ (3, 2)` funcionará\n",
    "   * `(3, 2) @ (2, 3)` funcionará\n",
    "2. La matriz resultante tiene la forma de las **dimensiones externas**:\n",
    "   * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "   * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **Nota:** \"`@`\" en Python es el símbolo para la multiplicación de matrices.\n",
    "\n",
    "> **Recurso:** Puedes ver todas las reglas para la multiplicación de matrices usando `torch.matmul()` [en la documentación de PyTorch](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Vamos a crear un tensor y realizar una multiplicación elemento a elemento y una multiplicación de matrices en él.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:11:01.659398Z",
     "start_time": "2024-11-28T11:10:59.756993Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE7loucmDlEM",
    "outputId": "44032bf9-c1f7-42fc-c842-dbe7a5c1221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUAZ3_b0vOKv"
   },
   "source": [
    "La diferencia entre la multiplicación elemento a elemento y la multiplicación matricial radica en la forma en que se suman los valores.\n",
    "\n",
    "Para nuestra variable `tensor` con valores `[1, 2, 3]`:\n",
    "\n",
    "| Operación | Cálculo | Código |\n",
    "| ----- | ----- | ----- |\n",
    "| **Multiplicación elemento a elemento** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **Multiplicación matricial** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:24.141011Z",
     "start_time": "2024-11-21T07:49:24.124186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i42gkUeHvI_1",
    "outputId": "18a630ce-bb56-4c40-81b4-9fdbb2ed7a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "tensor_multplicacion_matrices = torch.tensor([1, 2, 3])\n",
    "\n",
    "# realiza una multiplicación elemento a elemento\n",
    "multiplicacion_elemento = tensor * tensor\n",
    "print(multiplicacion_elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:24.219274Z",
     "start_time": "2024-11-21T07:49:24.209388Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvCBiiTTDk8y",
    "outputId": "cf623247-8f1b-49f1-e788-16da3ed1e59c"
   },
   "outputs": [],
   "source": [
    "# realiza una multiplicación \"normal\" usando matmul\n",
    "multiplicacion_matmul = torch.matmul(tensor, tensor)\n",
    "print(multiplicacion_matmul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:24.301660Z",
     "start_time": "2024-11-21T07:49:24.292570Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4E_pROBDk2r",
    "outputId": "a09af00f-277b-479e-b0a2-ad6311ee5413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El operador @ es de python, no se recomienda!\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obbginUMv43A"
   },
   "source": [
    "`torch.matmul()` es mucho más rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:24.415264Z",
     "start_time": "2024-11-21T07:49:24.407352Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qMSaLOoJscL",
    "outputId": "8bcad8a2-c900-4966-e13c-ff2cc02b9207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 998 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Se puede multiplicar \"a mano\" \n",
    "#  pero es muy lento, evita el uso de bucles, es muy lento computacionalmente\n",
    "# fíjate en las siguientes celdas y su tiempo de ejecución\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:24.601463Z",
     "start_time": "2024-11-21T07:49:24.590434Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVWiKB0KwH74",
    "outputId": "fce58235-5c09-49ec-f34b-a90e5640281e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ4DDmo1TGe-"
   },
   "source": [
    "## Uno de los errores más comunes en el aprendizaje profundo (errores de forma \"shape errors\")\n",
    "\n",
    "Dado que gran parte del aprendizaje profundo implica multiplicar y realizar operaciones con matrices, y las matrices tienen reglas estrictas sobre qué formas y tamaños se pueden combinar, uno de los errores más comunes con los que te encontrarás en el aprendizaje profundo es la incompatibilidad de formas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:22:03.518821Z",
     "start_time": "2024-11-28T11:22:03.472728Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rN5RcoD4Jo6y",
    "outputId": "20f6c65b-86f4-4903-d253-f6cbf0583934"
   },
   "outputs": [],
   "source": [
    "# Las formas deben ser las correctas para poder realizar la mulitplicación  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "# torch.matmul(tensor_A, tensor_B) # (producirá error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNA6MZEFxWVt"
   },
   "source": [
    "Podemos hacer que la multiplicación de matrices funcione entre `tensor_A` y `tensor_B` haciendo que sus dimensiones internas coincidan.\n",
    "\n",
    "Una de las formas de lograr esto es con una **transposición** (intercambiar las dimensiones de un tensor dado).\n",
    "\n",
    "Puedes realizar transposiciones en PyTorch usando:\n",
    "\n",
    "* `torch.transpose(input, dim0, dim1)` - donde `input` es el tensor deseado para transponer y `dim0` y `dim1` son las dimensiones a intercambiar.\n",
    "* `tensor.T` - donde `tensor` es el tensor deseado para transponer.\n",
    "\n",
    "Vamos a probar esta última opción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:22:07.838532Z",
     "start_time": "2024-11-28T11:22:07.832490Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUqgaANiy1wq",
    "outputId": "e48bbf0c-8008-434e-d372-caa658b2f36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# examinar tensores\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:22:10.129299Z",
     "start_time": "2024-11-28T11:22:10.118200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DveqxO7iy_Fi",
    "outputId": "1bd2e85b-ea4d-4948-c408-8eb46ef3534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# examinar tensor_A y su transpuesta\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:22:18.981001Z",
     "start_time": "2024-11-28T11:22:18.965650Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35rEIu-NKtVE",
    "outputId": "0b32c7f1-556e-45d4-de22-388419e93dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formas originales: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "Nuevas formas: tensor_A = torch.Size([3, 2]) (igual que arriba), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplicando: torch.Size([3, 2]) * torch.Size([2, 3]) <- las dimensiones internas coinciden\n",
      "\n",
      "Salida:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Forma de la salida: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# La operación funciona cuando tensor_B es transpuesto\n",
    "print(f\"Formas originales: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"Nuevas formas: tensor_A = {tensor_A.shape} (igual que arriba), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplicando: {tensor_A.shape} * {tensor_B.T.shape} <- las dimensiones internas coinciden\\n\")\n",
    "print(\"Salida:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nForma de la salida: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfcFEqfLjN24"
   },
   "source": [
    "también se puede usar [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:22:28.268062Z",
     "start_time": "2024-11-28T11:22:28.259236Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3rJvW_TTGe_",
    "outputId": "2c501972-20bf-4a83-ad4a-b5f1b2424097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm es una abreviatura\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA64Z4DmkB31"
   },
   "source": [
    "> **Nota:** Una multiplicación matricial como esta también se conoce como el [**producto punto**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) de dos matrices.\n",
    "\n",
    "\n",
    "Las redes neuronales están llenas de multiplicaciones de matrices y productos punto.\n",
    "\n",
    "El módulo [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) (lo veremos en acción más adelante), también conocido como capa feed-forward o capa completamente conectada, implementa una multiplicación de matrices entre una entrada `x` y una matriz de pesos `A`.\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "\n",
    "Donde:\n",
    "* `x` es la entrada de la capa (el aprendizaje profundo es una pila de capas como `torch.nn.Linear()` y otras, una sobre otra).\n",
    "* `A` es la matriz de pesos creada por la capa; comienza como números aleatorios que se ajustan a medida que una red neuronal aprende a representar mejor los patrones en los datos (observa la \"`T`\", eso es porque la matriz de pesos se transpone).\n",
    "  * **Nota:** También es común ver `W` u otra letra como `X` para representar la matriz de pesos.\n",
    "* `b` es el término de sesgo que se usa para ajustar ligeramente los pesos y las entradas.\n",
    "* `y` es la salida (una manipulación de la entrada con la esperanza de descubrir patrones en ella).\n",
    "\n",
    "Esta es una función lineal (probablemente hayas visto algo como $y = mx+b$ en secundaria o en otro lugar) y ¡puede usarse para trazar una línea recta!\n",
    "\n",
    "Vamos a experimentar con una capa lineal.\n",
    "\n",
    "Prueba cambiando los valores de `in_features` y `out_features` a continuación y observa qué sucede.\n",
    "\n",
    "¿Notas algo relacionado con las formas?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:06:10.276547Z",
     "start_time": "2024-11-28T17:06:10.270980Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC_MjKW1LX7T",
    "outputId": "768f75d2-c978-4df3-e18a-4684d46bdfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=6, bias=True)\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Como la capa lineal comienza con una matriz de pesos aleatoria, hagámosla reproducible \n",
    "torch.manual_seed(42)\n",
    "\n",
    "# crea un objeto de tipo torch.nn.Linear con in_features=2 y out features=6\n",
    "# in_features = coincide con la dimensión interna de la entrada\n",
    "# out_features = describe el valor externo\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
    "\n",
    "print(linear)\n",
    "\n",
    "# pasa el tensor_A al objeto linear y comprueba su forma de salida\n",
    "output_linear = linear(tensor_A)\n",
    "\n",
    "print(output_linear)\n",
    "print(output_linear.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIGrP5j1pN7j"
   },
   "source": [
    "> **Pregunta:** ¿Qué sucede si cambias `in_features` de 2 a 3 en el código anterior? ¿Da un error? ¿Cómo podrías cambiar la forma de la entrada (`x`) para adaptarte al error? Pista: ¿qué tuvimos que hacer con `tensor_B` anteriormente?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salta un error porque tensor_A tiene la forma (3, 2), cuando se espera entradas con 3 columnas.\n",
    "- Para solucionarlo, se adapta la forma de la entrada con un nuevo tensor con 3 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2342, -1.4334,  1.2115,  0.5391,  1.5456, -0.2382],\n",
      "        [-3.8890, -4.0221,  2.6416,  1.3352,  3.4043, -0.7888],\n",
      "        [-6.5438, -6.6107,  4.0717,  2.1314,  5.2630, -1.3394]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "linear_error = torch.nn.Linear(in_features=3, out_features=6)\n",
    "\n",
    "# ERROR. El tensor_A tiene solo 2 columnas\n",
    "# salida = linear_error(tensor_A)\n",
    "\n",
    "\n",
    "# Para solucionarlo, se crea un tensor con forma (3, 3)\n",
    "tensor_modificado = torch.tensor([[1, 2, 3],\n",
    "                                  [4, 5, 6],\n",
    "                                  [7, 8, 9]], dtype=torch.float32)\n",
    "\n",
    "linear = torch.nn.Linear(in_features=3, out_features=6)\n",
    "salida = linear(tensor_modificado)\n",
    "\n",
    "print(salida)\n",
    "print(salida.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPNF0nMWoGEj"
   },
   "source": [
    "Si nunca lo has hecho antes, la multiplicación de matrices puede ser un tema confuso al principio.\n",
    "\n",
    "Pero después de experimentarlo algunas veces e incluso explorar algunas redes neuronales, notarás que está en todas partes.\n",
    "\n",
    "Recuerda, la multiplicación de matrices es todo lo que necesitas.\n",
    "\n",
    "![la multiplicación de matrices es todo lo que necesitas](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbec318e-38cc-4018-a425-dd5766405001_888x499.jpeg)\n",
    "\n",
    "*Cuando comienzas a profundizar en las capas de redes neuronales y a construir las tuyas propias, encontrarás multiplicaciones de matrices en todas partes. **Fuente:** https://marksaroufim.substack.com/p/working-class-deep-learner*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjMmrJOOPv5e"
   },
   "source": [
    "### Encontrar el mínimo, máximo, media, suma, etc. (agregación)\n",
    "\n",
    "Ahora que hemos visto algunas formas de manipular tensores, vamos a repasar algunas maneras de agregarlos (pasar de más valores a menos valores).\n",
    "\n",
    "Primero crearemos un tensor y luego encontraremos el máximo, mínimo, media y suma de este.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:21.430474Z",
     "start_time": "2024-11-21T07:51:21.425243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrFQbe5fP1Rk",
    "outputId": "034013c1-b384-4a0d-edf8-295ed3a456f1"
   },
   "outputs": [],
   "source": [
    "# Crear un tensor con la función arange\n",
    "tensor = torch.arange(start=0, end=10, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J-wfMdlsEco"
   },
   "source": [
    "Hagamos alguna operación de agregación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:22.759863Z",
     "start_time": "2024-11-21T07:51:22.743726Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5wSP9YKP3Lb",
    "outputId": "3aa238c7-646f-434f-a55c-292aabef7227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor(9.)\n",
      "tensor(0.)\n",
      "tensor(4.5000)\n",
      "tensor(45.)\n"
     ]
    }
   ],
   "source": [
    "# muestra el máximo, mínimo, media y suma\n",
    "print(tensor)\n",
    "print(tensor.max())\n",
    "print(tensor.min())\n",
    "print(tensor.mean())\n",
    "print(tensor.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHoKpsg3sKQE"
   },
   "source": [
    "> **Nota:** Es posible que algunos métodos como `torch.mean()` requieran que los tensores estén en `torch.float32` (el más común) u otro tipo de dato específico, de lo contrario, la operación fallará.\n",
    "\n",
    "También puedes realizar lo mismo que lo anterior utilizando métodos de `torch`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:24.750921Z",
     "start_time": "2024-11-21T07:51:24.733652Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Cr23Y9uP3HO",
    "outputId": "9c86d805-eef2-465c-e2c8-2bccd515e6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n",
      "tensor(0.)\n",
      "tensor(4.5000)\n",
      "tensor(45.)\n"
     ]
    }
   ],
   "source": [
    "# repite la celda anterior, pero con las funciones de torch\n",
    "print(tensor)\n",
    "print(torch.max(tensor))\n",
    "print(torch.min(tensor))\n",
    "print(torch.mean(tensor))\n",
    "print(torch.sum(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7ApCaZjDkvp"
   },
   "source": [
    "### Mínimo/Máximo Posicional\n",
    "\n",
    "También puedes encontrar el índice de un tensor donde ocurre el valor máximo o mínimo utilizando [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) y [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html), respectivamente.\n",
    "\n",
    "Esto es útil en caso de que solo quieras la posición donde se encuentra el valor más alto (o más bajo) y no el valor en sí mismo (veremos esto en una sección posterior cuando utilicemos la [función de activación softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:27.199122Z",
     "start_time": "2024-11-21T07:51:27.183535Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzNBl9JSGlHi",
    "outputId": "01e0740e-c34f-469b-9c8f-9e6e5f0363af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "\n",
    "# extrae la posición del máximo y del mínimo\n",
    "pos_max = torch.argmax(tensor)\n",
    "print(pos_max)\n",
    "\n",
    "pos_min = torch.argmin(tensor)\n",
    "print(pos_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBu33WihOXBk"
   },
   "source": [
    "### Cambiar el tipo de dato de un tensor\n",
    "\n",
    "Como se mencionó, un problema común en las operaciones de deep learning es que los tensores estén en diferentes tipos de datos.\n",
    "\n",
    "Si un tensor está en `torch.float64` y otro en `torch.float32`, podrías encontrarte con algunos errores.\n",
    "\n",
    "Pero hay una solución.\n",
    "\n",
    "Puedes cambiar el tipo de dato de los tensores utilizando [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html), donde el parámetro `dtype` es el tipo de dato que deseas usar.\n",
    "\n",
    "Primero, crearemos un tensor y verificaremos su tipo de dato (el tipo por defecto es `torch.float32`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:29.719774Z",
     "start_time": "2024-11-21T07:51:29.701971Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY2FEsCAOaLu",
    "outputId": "507f1ade-7c7a-4172-fa48-60c9ac4831c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor y comprobar su tipo\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR30FHEc92of"
   },
   "source": [
    "Ahora creamos otro tensor con tipo `torch.float16`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:31.292066Z",
     "start_time": "2024-11-21T07:51:31.278417Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cac8gRYjOeab",
    "outputId": "96e5ce12-bc29-4a2b-f81c-bfc89ea2d075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# crear un tensor float16\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "\n",
    "print(tensor_float16)\n",
    "print(tensor_float16.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndVlKJZ4-7_5"
   },
   "source": [
    "También podríamos crear uno de 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:33.073407Z",
     "start_time": "2024-11-21T07:51:33.055392Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Yqovld2Oj6s",
    "outputId": "667da17f-e38f-404a-bd2d-63683e45c99a"
   },
   "outputs": [],
   "source": [
    "# Crear un tensor int8\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "\n",
    "print(tensor_int8)\n",
    "print(tensor_int8.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44GxVabar-xe"
   },
   "source": [
    "> **Nota:** Los diferentes tipos de datos pueden ser confusos al principio. Pero piensa en ello de esta manera: cuanto menor es el número (por ejemplo, 32, 16, 8), menos precisa es la forma en que un ordenador almacena el valor. Y con una menor cantidad de almacenamiento, generalmente se obtienen cálculos más rápidos y modelos más pequeños en general. Las redes neuronales basadas en dispositivos móviles a menudo operan con enteros de 8 bits, que son más pequeños y rápidos de ejecutar, pero menos precisos que sus equivalentes en `float32`. Para más información sobre esto, te recomiendo leer acerca de la [precisión en informática](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "> **Ejercicio:** Hasta ahora hemos cubierto bastantes métodos de tensores, pero hay muchos más en la [documentación de `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html). Te recomiendo dedicar 10 minutos a explorarla y observar cualquier método que te llame la atención. Haz clic en ellos y luego escribe el código correspondiente para ver qué sucede.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CkCtAYmGsHY"
   },
   "source": [
    "### Cambiar la forma, apilar, comprimir y expandir tensores\n",
    "\n",
    "A menudo, querrás cambiar la forma o las dimensiones de tus tensores sin modificar los valores que contienen.\n",
    "\n",
    "Para ello, algunos métodos populares son:\n",
    "\n",
    "| Método | Descripción en una línea |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Cambia la forma de `input` a `shape` (si es compatible). También puedes usar `torch.Tensor.reshape()`. |\n",
    "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Devuelve una vista del tensor original con una forma diferente (`shape`) pero comparte los mismos datos que el tensor original. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatena una secuencia de `tensors` a lo largo de una nueva dimensión (`dim`). Todos los `tensors` deben tener el mismo tamaño. |\n",
    "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Comprime `input` eliminando todas las dimensiones con valor `1`. |\n",
    "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Devuelve `input` con un valor de dimensión `1` añadido en `dim`. |\n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Devuelve una *vista* del tensor `input` original con sus dimensiones permutadas (reordenadas) según `dims`. |\n",
    "\n",
    "¿Por qué usar estos métodos?\n",
    "\n",
    "Porque los modelos de deep learning (redes neuronales) se basan en la manipulación de tensores de diversas maneras. Y debido a las reglas de la multiplicación de matrices, si las formas de los tensores no coinciden, tendrás errores. Estos métodos te ayudan a asegurarte de que los elementos correctos de tus tensores interactúen con los elementos correctos de otros tensores.\n",
    "\n",
    "¡Probémoslos!\n",
    "\n",
    "Primero, crearemos un tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:35.873069Z",
     "start_time": "2024-11-21T07:51:35.854544Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjRTLOzG4Ev",
    "outputId": "f7f2719c-15ce-406b-dc8f-4477046cd5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_VarMO9CoT8"
   },
   "source": [
    "Añadamos una dimensión `torch.reshape()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:38.142155Z",
     "start_time": "2024-11-21T07:51:38.135217Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US4WjpQ3SG-8",
    "outputId": "c519d59e-85f1-4a10-eaaa-acb487028e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "# Añade al tensor una dimensión extra con reshape\n",
    "x_reshape = x.reshape(1, 7)\n",
    "\n",
    "print(x_reshape)\n",
    "print(x_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tig5xm0jCxuU"
   },
   "source": [
    "También se puede cambiar _la vista_ con `torch.view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:51:39.479370Z",
     "start_time": "2024-11-21T07:51:39.463091Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDN2BNe5TGfB",
    "outputId": "3df1b0d6-2548-4ecc-ca25-0c4e28a6e536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "# Cambiar la vista \"view\" (mantiene los datos originales pero cambia la vista)\n",
    "# https://stackoverflow.com/a/54507446/7900723\n",
    "\n",
    "#pruébalo\n",
    "z = x.view(1, 7)\n",
    "print(z)\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8joAaUEC2NX"
   },
   "source": [
    "Recuerda que cambiar la vista de un tensor con `torch.view()` solo crea una nueva vista del *mismo* tensor.\n",
    "\n",
    "Por lo tanto, cambiar la vista también modifica el tensor original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:18.098435Z",
     "start_time": "2024-11-21T07:54:18.087824Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DxURVvXTGfC",
    "outputId": "668d194d-dd0a-4db1-da00-9c3fd8849186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[999.,   2.,   3.,   4.,   5.,   6.,   7.]])\n",
      "tensor([999.,   2.,   3.,   4.,   5.,   6.,   7.])\n"
     ]
    }
   ],
   "source": [
    "# Cambiando z, se cambia x: Prueba a cambiar un elemento\n",
    "z[0, 0] = 999.\n",
    "print(z)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxnqDBlpDDJ_"
   },
   "source": [
    "Si quisiéramos apilar nuestro nuevo tensor sobre sí mismo cinco veces, podríamos hacerlo con `torch.stack()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:02:42.933939Z",
     "start_time": "2024-11-28T15:02:42.930545Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pX5Adf3ORiTK",
    "outputId": "703e8568-61df-4ebd-f4d3-a6366dc265c0"
   },
   "outputs": [],
   "source": [
    "# Prueba a apilar tensores uno encima de otro\n",
    "x_stacked = torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET56QzNHDuOI"
   },
   "source": [
    "¿Qué tal eliminar todas las dimensiones de tamaño 1 de un tensor?\n",
    "\n",
    "Para hacerlo, puedes usar `torch.squeeze()` (*comprimir* el tensor para que solo tenga dimensiones mayores a 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:23.269045Z",
     "start_time": "2024-11-21T07:54:23.259392Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Y2HEoDRxJZ",
    "outputId": "dd0645a6-1cdd-46bc-a3a2-433d9cd09336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[999.,   2.,   3.,   4.,   5.,   6.,   7.]])\n",
      "torch.Size([1, 7])\n",
      "tensor([999.,   2.,   3.,   4.,   5.,   6.,   7.])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "# muestra el contenido y la forma del tensor x_reshaped\n",
    "print(x_reshape)\n",
    "print(x_reshape.shape)\n",
    "\n",
    "# Elimina las dimensiones adicionales de x_reshaped\n",
    "x_squeezed = torch.squeeze(x_reshape)\n",
    "\n",
    "print(x_squeezed)\n",
    "print(x_squeezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acjDLk8WD8NC"
   },
   "source": [
    "Y para hacer lo inverso de `torch.squeeze()`, puedes usar `torch.unsqueeze()` para agregar una dimensión con valor 1 en un índice específico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:25.573701Z",
     "start_time": "2024-11-21T07:54:25.562329Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUC-DEEwSYv7",
    "outputId": "da60e019-3ea6-42f8-8e47-ba037ead737f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 3],\n",
      "          [4, 5, 6],\n",
      "          [7, 8, 9]]]])\n",
      "torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Agrega una dimensión adicional con unsqueeze\n",
    "x_unsqueezed = torch.unsqueeze(x, dim=0)\n",
    "\n",
    "print(x_unsqueezed)\n",
    "print(x_unsqueezed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9DuJzXgFbM5"
   },
   "source": [
    "También puedes reorganizar el orden de los ejes de un tensor con `torch.permute(input, dims)`, donde el `input` se convierte en una *vista* con las nuevas `dims`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:05:29.882146Z",
     "start_time": "2024-11-28T15:05:29.877261Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCRGCX8DTGfC",
    "outputId": "6853328b-a1cf-4470-f366-106a231a189c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensor con una forma específica\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permuta el tensor original para reorganizar el orden de los ejes\n",
    "x_permutado = x_original.permute(2, 0, 1)\n",
    "\n",
    "print(x_permutado.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06LKaFemGBoE"
   },
   "source": [
    "> **Nota**: Como `permute` devuelve una *vista* (comparte los mismos datos que el tensor original), los valores en el tensor permutado serán los mismos que en el tensor original, y si cambias los valores en la vista, también cambiarán los valores del tensor original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEPqVL7fTGfC"
   },
   "source": [
    "## Indexación (selección de datos de tensores)\n",
    "\n",
    "A veces querrás seleccionar datos específicos de los tensores (por ejemplo, solo la primera columna o la segunda fila).\n",
    "\n",
    "Para hacerlo, puedes usar la indexación.\n",
    "\n",
    "Si alguna vez has hecho indexación en listas de Python o arrays de NumPy, la indexación en PyTorch con tensores es muy similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:30.112866Z",
     "start_time": "2024-11-21T07:54:30.102277Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSXzdxCQTGfD",
    "outputId": "05a72c08-5f8c-433a-cd31-46065686f825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQG5krnKG43B"
   },
   "source": [
    "La indexación de valores sigue el orden de dimensión exterior -> dimensión interior (observa los corchetes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:31.698292Z",
     "start_time": "2024-11-21T07:54:31.692824Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zv_Z3IAzTGfD",
    "outputId": "cf6c0936-7600-4af4-9b6f-f6b8ac9b4c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0]:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "x[0][0]: tensor([1, 2, 3])\n",
      "x[0][0][0]: tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# indexa cada una de las dimensiones\n",
    "print(\"x[0]:\\n\", x[0])\n",
    "print(\"x[0][0]:\", x[0][0])\n",
    "print(\"x[0][0][0]:\", x[0][0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaLjaIFxHe89"
   },
   "source": [
    "También puedes usar `:` para especificar \"todos los valores en esta dimensión\" y luego usar una coma (`,`) para añadir otra dimensión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:33.405660Z",
     "start_time": "2024-11-21T07:54:33.399201Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCT09pqeTGfD",
    "outputId": "a91f9b73-f8f0-476a-9c69-fcd03b042f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[:, 0]:\n",
      " tensor([[1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "# Dame todos los valores de la dimensión 0 y el índice 0 de la dimensión 1\n",
    "print(\"x[:, 0]:\\n\", x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:34.945880Z",
     "start_time": "2024-11-21T07:54:34.936850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwDx_gMsTGfD",
    "outputId": "8165cfd9-a88d-4212-8c45-1eb84ef5be83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[:, :, 1]:\n",
      " tensor([[2, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Dame todos los valores de las dimensiones 0 y 1,  y el índice 1 de la dimensión 2\n",
    "print(\"x[:, :, 1]:\\n\", x[:, :, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:36.786433Z",
     "start_time": "2024-11-21T07:54:36.781093Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiw3_1E3TGfD",
    "outputId": "12fa4749-cf52-4e88-c2c0-44d26aeb633c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[:, 1, 1]:\n",
      " tensor([5])\n"
     ]
    }
   ],
   "source": [
    "# Todos los valores de la dimensión 0, pero sólo el índice 1 de las dimensiones 1 y 2\n",
    "print(\"x[:, 1, 1]:\\n\", x[:, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ZaW0Bq7rCm"
   },
   "source": [
    "## Tensores de PyTorch y NumPy\n",
    "\n",
    "Dado que NumPy es una biblioteca popular para cálculos numéricos en Python, PyTorch tiene funcionalidades para interactuar con ella de manera eficiente.\n",
    "\n",
    "Los dos métodos principales que necesitarás para convertir entre NumPy y PyTorch (y viceversa) son:\n",
    "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html): Convierte un array de NumPy en un tensor de PyTorch.\n",
    "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html): Convierte un tensor de PyTorch en un array de NumPy.\n",
    "\n",
    "¡Probémoslos!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:38.602995Z",
     "start_time": "2024-11-21T07:54:38.581782Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDrDCnvY7rKS",
    "outputId": "86155a63-01f9-4372-e889-61a65ebf0fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array a tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16JG6cONLPnO"
   },
   "source": [
    "> **Nota:** Por defecto, los arrays de NumPy se crean con el tipo de dato `float64`, y si los conviertes a un tensor de PyTorch, conservarán el mismo tipo de dato (como en el ejemplo anterior).  \n",
    ">\n",
    "> Sin embargo, muchas operaciones en PyTorch usan por defecto `float32`.  \n",
    "> \n",
    "> Por lo tanto, si deseas convertir un array de NumPy (`float64`) -> tensor de PyTorch (`float64`) -> tensor de PyTorch (`float32`), puedes usar: `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
    "\n",
    "Como reasignamos `tensor` en el ejemplo anterior, si cambias el tensor, el array original permanecerá igual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:40.204038Z",
     "start_time": "2024-11-21T07:54:40.195109Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovwl7VCREv8L",
    "outputId": "efd21eb9-0010-436a-dc29-f851e3d7d77a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiar el array, mantener el tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geVvu1p0MTWc"
   },
   "source": [
    "Y si quieres obtener un array de numpy de un tensor tienes que llamar a `tensor.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:41.838216Z",
     "start_time": "2024-11-21T07:54:41.822362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw_7ZyVaTKxQ",
    "outputId": "54d6f347-d3f6-44df-9155-83d980c31780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor a NumPy array\n",
    "tensor = torch.ones(7) # tensor de unos con dtype=float32\n",
    "numpy_tensor = tensor.numpy() # será de tipo float32\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gU3ubCrUkI-"
   },
   "source": [
    "## Reproducibilidad (tratando de quitar lo aleatorio de lo aleatorio)\n",
    "\n",
    "A medida que aprendas más sobre redes neuronales y machine learning, empezarás a descubrir lo importante que es la aleatoriedad.\n",
    "\n",
    "Bueno, en realidad es pseudorandomness (pseudoaleatoriedad). Porque, al fin y al cabo, una computadora es fundamentalmente determinista (cada paso es predecible), por lo que la \"aleatoriedad\" que crean es una simulación de aleatoriedad (aunque esto también es objeto de debate, pero como no soy científico informático, te dejo investigar más por tu cuenta).\n",
    "\n",
    "¿Y cómo se relaciona esto con las redes neuronales y el deep learning?\n",
    "\n",
    "Hemos mencionado que las redes neuronales comienzan con números aleatorios para describir patrones en los datos (estos números son descripciones pobres) y tratan de mejorar esos números aleatorios mediante operaciones con tensores (y algunas otras cosas que aún no hemos discutido) para describir mejor los patrones en los datos.\n",
    "\n",
    "En resumen:\n",
    "\n",
    "``empezar con números aleatorios -> operaciones con tensores -> intentar mejorarlos (una y otra vez)``\n",
    "\n",
    "Aunque la aleatoriedad es útil y poderosa, a veces querrás que haya un poco menos de aleatoriedad.\n",
    "\n",
    "¿Por qué?\n",
    "\n",
    "Para poder realizar experimentos reproducibles.\n",
    "\n",
    "Por ejemplo, creas un algoritmo capaz de alcanzar cierto nivel de rendimiento.\n",
    "\n",
    "Y luego tu amigo lo prueba para verificar que no estás loco.\n",
    "\n",
    "¿Cómo podría hacerlo?\n",
    "\n",
    "Ahí es donde entra en juego la **reproducibilidad**.\n",
    "\n",
    "En otras palabras, ¿puedes obtener los mismos (o muy similares) resultados en tu computadora ejecutando el mismo código que obtengo en la mía?\n",
    "\n",
    "Veamos un breve ejemplo de reproducibilidad en PyTorch.\n",
    "\n",
    "Comenzaremos creando dos tensores aleatorios. Dado que son aleatorios, esperarías que sean diferentes, ¿verdad?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:44.413762Z",
     "start_time": "2024-11-21T07:54:44.388736Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSwxnwEbTGfF",
    "outputId": "73b34154-734f-496f-9b55-b6aaa137e854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
      "\n",
      "A == B? \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# dos tensores aleatorios\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"A == B? \")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPU6mDKJnr8M"
   },
   "source": [
    "Tal como podrías haber esperado, los tensores resultan con valores diferentes.\n",
    "\n",
    "Pero, ¿y si quisieras crear dos tensores aleatorios con los *mismos* valores?\n",
    "\n",
    "Es decir, los tensores seguirían conteniendo valores aleatorios, pero serían del mismo tipo o \"sabor\".\n",
    "\n",
    "Ahí es donde entra [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html), donde `seed` es un número entero (como `42`, aunque podría ser cualquier número) que define el \"sabor\" de la aleatoriedad.\n",
    "\n",
    "Probémoslo creando algunos tensores aleatorios con el mismo \"sabor\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:54:46.817334Z",
     "start_time": "2024-11-21T07:54:46.804912Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sB6d1GfYTGfF",
    "outputId": "4d11d38e-4406-4aff-9a81-cf13aa89ee5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "¿Es el Tensor C igual al Tensor D? (en algún elemento)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# Establecer la semilla aleatoria\n",
    "RANDOM_SEED = 42  # prueba cambiando este valor y observa qué sucede con los números a continuación\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Es necesario reiniciar la semilla cada vez que se llama a rand()\n",
    "# Sin esto, tensor_D sería diferente de tensor_C\n",
    "torch.random.manual_seed(seed=RANDOM_SEED)  # prueba comentando esta línea y observa qué sucede\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"¿Es el Tensor C igual al Tensor D? (en algún elemento)\")\n",
    "random_tensor_C == random_tensor_D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uct53Xr5QRC_"
   },
   "source": [
    "¡Genial!\n",
    "\n",
    "Parece que configurar la semilla funcionó.\n",
    "\n",
    "> **Recurso:** Lo que acabamos de cubrir es solo la superficie de la reproducibilidad en PyTorch. Para más información sobre reproducibilidad en general y semillas aleatorias, te recomiendo consultar:\n",
    "> * [La documentación de reproducibilidad de PyTorch](https://pytorch.org/docs/stable/notes/randomness.html) (un buen ejercicio sería leer esta sección durante 10 minutos; incluso si no lo entiendes completamente ahora, es importante estar al tanto).\n",
    "> * [La página de Wikipedia sobre semillas aleatorias](https://en.wikipedia.org/wiki/Random_seed) (ofrece una buena visión general sobre las semillas aleatorias y la pseudorandomness en general).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxIIM7t27rQ-"
   },
   "source": [
    "## Ejecutando tensores en GPUs (y realizando cálculos más rápidos)\n",
    "\n",
    "Los algoritmos de deep learning requieren muchas operaciones numéricas.\n",
    "\n",
    "Por defecto, estas operaciones se realizan en una CPU (unidad de procesamiento central).\n",
    "\n",
    "Sin embargo, existe otro tipo de hardware común llamado GPU (unidad de procesamiento gráfico), que a menudo es mucho más rápido para realizar los tipos específicos de operaciones que necesitan las redes neuronales (multiplicaciones de matrices) en comparación con las CPUs.\n",
    "\n",
    "Es posible que tu computadora tenga una.\n",
    "\n",
    "Si es así, deberías tratar de usarla siempre que puedas para entrenar redes neuronales, ya que probablemente acelerará el tiempo de entrenamiento de manera significativa.\n",
    "\n",
    "Hay algunas formas de, primero, obtener acceso a una GPU y, segundo, hacer que PyTorch use la GPU.\n",
    "\n",
    "> **Nota:** Cuando me refiero a \"GPU\" en este curso, estoy hablando de una [GPU Nvidia con CUDA](https://developer.nvidia.com/cuda-gpus) habilitada (CUDA es una plataforma y API de computación que permite usar las GPUs para cálculos de propósito general, no solo gráficos), a menos que se especifique lo contrario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UiR6QpoYQH_"
   },
   "source": [
    "### 1. Obtener una GPU\n",
    "\n",
    "\n",
    "| **Método** | **Dificultad de configuración** | **Ventajas** | **Desventajas** | **Cómo configurarlo** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Google Colab | Fácil | Gratis, casi sin configuración requerida, puedes compartir tu trabajo fácilmente con un enlace | No guarda los datos generados, capacidad de cálculo limitada, sujeta a desconexiones | [Sigue la guía de Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| Usa tu propia GPU | Media | Ejecuta todo localmente en tu máquina | Las GPUs no son gratis, requieren un costo inicial | Sigue las [guías de instalación de PyTorch](https://pytorch.org/get-started/locally/) |\n",
    "| Computación en la nube (AWS, GCP, Azure) | Media-Difícil | Costo inicial bajo, acceso a recursos casi infinitos | Puede ser caro si se usa continuamente, toma tiempo configurarlo correctamente | Sigue las [guías de instalación de PyTorch](https://pytorch.org/get-started/cloud-partners/) |\n",
    "\n",
    "Hay más opciones para usar GPUs, pero las tres anteriores son suficientes por ahora.\n",
    "\n",
    "Personalmente, utilizo una combinación de Google Colab y mi computadora personal para experimentos a pequeña escala (y para crear este curso) y recurro a recursos en la nube cuando necesito más potencia de cálculo.\n",
    "\n",
    "> **Recurso:** Si estás buscando comprar tu propia GPU pero no estás seguro de cuál elegir, [Tim Dettmers tiene una excelente guía](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
    "\n",
    "Para comprobar si tienes acceso a una GPU Nvidia, puedes ejecutar `!nvidia-smi`, donde el `!` (también llamado \"bang\") significa \"ejecutar esto en la línea de comandos\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:12:28.875056Z",
     "start_time": "2024-11-28T15:12:28.595657Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEMcO-9zYc-w",
    "outputId": "77405db7-3494-4add-cfc7-8415e52a0412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  7 21:06:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.03                 Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P0             12W /   35W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvkB9p5zYf8E"
   },
   "source": [
    "Si no tienes acceso a una GPU Nvidia, lo anterior mostrará algo como:\n",
    "\n",
    "\n",
    "```\n",
    "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
    "```\n",
    "\n",
    "y si tienes una GPU, te saldrá algo como esto: \n",
    "\n",
    "```\n",
    "Thu Nov 28 16:11:27 2024       \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA RTX A3000 12GB La...    Off |   00000000:01:00.0 Off |                  Off |\n",
    "| N/A   41C    P8              9W /   55W |       8MiB /  12288MiB |      0%      Default |\n",
    "|                                         |                        |                  N/A |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "                                                                                         \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "|    0   N/A  N/A      2670      G   /usr/lib/xorg/Xorg                              4MiB |\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvibZ6e0YcDk"
   },
   "source": [
    "\n",
    "\n",
    "### 2. Ejecutando PyTorch en la GPU:\n",
    "\n",
    "Una vez que tengas una GPU lista para usar, el siguiente paso es hacer que PyTorch la utilice para almacenar datos (tensores) y realizar cálculos (operaciones en tensores).\n",
    "\n",
    "Para ello, puedes usar el paquete [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html).\n",
    "\n",
    "En lugar de hablar sobre ello, ¡probémoslo!\n",
    "\n",
    "Puedes comprobar si PyTorch tiene acceso a una GPU utilizando [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OweDLgwjEvZ2",
    "outputId": "3a278a24-3ec3-4b1f-8f96-298086fa6ea6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobar si hay una GPU disponible\n",
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jedZcx2PZFpL"
   },
   "source": [
    "Si lo anterior muestra `True`, significa que PyTorch puede ver y usar la GPU. Si muestra `False`, no puede detectar la GPU y, en ese caso, tendrás que revisar los pasos de instalación.\n",
    "\n",
    "Ahora, supongamos que quieres configurar tu código para que se ejecute en la CPU *o* en la GPU si está disponible.\n",
    "\n",
    "De esta manera, si tú o alguien más decide ejecutar tu código, funcionará independientemente del dispositivo de cálculo que estén usando.\n",
    "\n",
    "Vamos a crear una variable `device` para almacenar el tipo de dispositivo disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j92HBCKB7rYa",
    "outputId": "8cca1643-645c-4b67-f1f5-37066f6b9549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjFyPP2WaCch"
   },
   "source": [
    "Si el resultado anterior es `\"cuda\"`, significa que podemos configurar todo nuestro código de PyTorch para usar el dispositivo CUDA disponible (una GPU). Y si el resultado es `\"cpu\"`, nuestro código de PyTorch se ejecutará en la CPU.\n",
    "\n",
    "> **Nota:** En PyTorch, es una buena práctica escribir [**código agnóstico al dispositivo**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). Esto significa que el código podrá ejecutarse en la CPU (siempre disponible) o en la GPU (si está disponible).\n",
    "\n",
    "Si quieres realizar cálculos más rápidos, puedes usar una GPU, pero si quieres hacer cálculos *mucho* más rápidos, puedes usar múltiples GPUs.\n",
    "\n",
    "Puedes contar el número de GPUs a las que PyTorch tiene acceso utilizando [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MArsn0DFTGfG",
    "outputId": "de717df5-bb67-4900-805e-a6f00ad0b409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar número de dispositivos\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqQLcuj68OA-"
   },
   "source": [
    "### 3. Enviando tensores (y modelos) a la GPU\n",
    "\n",
    "Puedes colocar tensores (y modelos, lo veremos más adelante) en un dispositivo específico llamando a [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) sobre ellos, donde `device` es el dispositivo de destino al que deseas mover el tensor (o modelo).\n",
    "\n",
    "¿Por qué hacerlo?\n",
    "\n",
    "Las GPUs ofrecen una capacidad de cálculo numérico mucho más rápida que las CPUs y, si no hay una GPU disponible, gracias a nuestro **código agnóstico al dispositivo** (ver arriba), se ejecutará en la CPU.\n",
    "\n",
    "> **Nota:** Colocar un tensor en la GPU usando `to(device)` (por ejemplo, `some_tensor.to(device)`) devuelve una copia de ese tensor. Es decir, el mismo tensor existirá tanto en la CPU como en la GPU. Para sobrescribir el tensor, debes reasignarlo:\n",
    ">\n",
    "> `some_tensor = some_tensor.to(device)`\n",
    "\n",
    "Vamos a intentar crear un tensor y colocarlo en la GPU (si está disponible).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:49:25.921590200Z",
     "start_time": "2024-11-17T16:59:54.837637Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhI3srFXEHfP",
    "outputId": "2f4f6435-fdc4-4e99-e87c-9421c2100f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 1085,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear tensor (por defecto en CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Mover a la GPU\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxXeRKO0TGfG"
   },
   "source": [
    "Si tienes GPU obtendrás algo así:\n",
    "\n",
    "```\n",
    "tensor([1, 2, 3]) cpu\n",
    "tensor([1, 2, 3], device='cuda:0')\n",
    "```\n",
    "\n",
    "Comprueba que el segundo tensor tiene `device='cuda:0'`, esto significa que está almacenado en la GPU número 0 `'cuda:0'`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4puyUX4Bci5D"
   },
   "source": [
    "### 4. Moviendo tensores de vuelta a la CPU\n",
    "\n",
    "¿Qué pasa si queremos mover el tensor de vuelta a la CPU?\n",
    "\n",
    "Por ejemplo, querrás hacer esto si deseas interactuar con tus tensores usando NumPy (NumPy no utiliza la GPU).\n",
    "\n",
    "Vamos a intentar usar el método [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) en nuestro `tensor_on_gpu`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "3ChSLJgPTGfG",
    "outputId": "32e92f62-db28-4dc7-ce93-c2ab33229252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si el tensor está en la GPU, no puedo transformarlo a numpy (dará error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhymtkRDTGfG"
   },
   "source": [
    "En su lugar, para devolver un tensor a la CPU y hacerlo usable con NumPy, podemos usar [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
    "\n",
    "Esto copia el tensor a la memoria de la CPU, haciéndolo utilizable con CPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN15s-NdTGfG",
    "outputId": "9fffb6f2-c200-4f9c-d987-d9ab5d9cba49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copia el tensor a la cpu primero:\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "00_pytorch_fundamentals.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
