{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creando modelos basados en otros modelos\n",
    "\n",
    "Hasta ahora hemos usado librer√≠as como TensorFlow para crear nuestros propios modelos capa por capa desde cero.\n",
    "\n",
    "Ahora vamos a realizar un proceso similar, excepto que la mayor√≠a de las capas de nuestro modelo provendr√°n de [Kaggle](https://www.kaggle.com/models).\n",
    "\n",
    "De hecho, vamos a utilizar dos modelos:\n",
    "1. [ResNetV2](https://arxiv.org/abs/1603.05027) - una arquitectura de modelo de visi√≥n artificial basada en redes residuales (residual network).\n",
    "2. [EfficientNet](https://arxiv.org/abs/1905.11946) - una arquitectura de visi√≥n artificial basada en redes convolucionales.\n",
    "\n",
    "En alg√∫n momento, ambos modelos han logrado la tasa de error m√°s baja en [ImageNet (ILSVRC-2012-CLS)](http://www.image-net.org/), el est√°ndar de oro de los benchmarks de visi√≥n artificial.\n",
    "\n",
    "\n",
    "pasos:\n",
    "1. Ir a [https://www.kaggle.com/models](https://www.kaggle.com/models).\n",
    "2. Elegir tu dominio de problema, por ejemplo, \"Imagen\" (estamos usando im√°genes de alimentos).\n",
    "\n",
    "> ü§î **Pregunta:** *Veo muchas opciones para modelos de clasificaci√≥n de im√°genes, ¬øc√≥mo s√© cu√°l es el mejor?*\n",
    "\n",
    "Puedes ver una lista de modelos de √∫ltima generaci√≥n en [paperswithcode.com](https://www.paperswithcode.com), un recurso para recopilar los √∫ltimos resultados de trabajos de investigaci√≥n en aprendizaje profundo que tienen implementaciones de c√≥digo para los hallazgos que informan.\n",
    "\n",
    "Dado que estamos trabajando con im√°genes, nuestro objetivo son los [modelos que mejor se desempe√±an en ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet).\n",
    "\n",
    "   * La regla general aqu√≠ es, generalmente, los nombres con n√∫meros m√°s grandes significan modelos de mejor rendimiento. Por ejemplo, EfficientNetB4 tiene mejor capacidad de predicci√≥n que EfficientNetB0, sin embargo, los modelos m√°s peque√±os predicen m√°s r√°pido.\n",
    "     \n",
    "7. Selecciona EfficientNet y en las variaciones de modelo, elige b0-feature-vector\n",
    "\n",
    "> ü§î **Pregunta:** *Pens√© que est√°bamos haciendo clasificaci√≥n de im√°genes, ¬øpor qu√© elegimos vector de caracter√≠sticas y no clasificaci√≥n?*\n",
    "\n",
    "Gran observaci√≥n. Aqu√≠ es donde entran en juego los diferentes tipos de transferencia de aprendizaje, como es, extracci√≥n de caracter√≠sticas y ajuste fino.\n",
    "\n",
    "1. **Aprendizaje por transferencia \"tal cual\"** es cuando tomas un modelo preentrenado tal cual es y lo aplicas a tu tarea sin ning√∫n cambio.\n",
    "\n",
    "   * Por ejemplo, muchos modelos de visi√≥n artificial est√°n preentrenados en el conjunto de datos en el conjunto de datos ImageNet, que contiene 1000 clases diferentes de im√°genes. Esto significa que pasar una sola imagen a este modelo producir√° 1000 valores de probabilidad de predicci√≥n diferentes (1 para cada clase).\n",
    "\n",
    "    * Esto es √∫til si tienes 1000 clases de im√°genes que te gustar√≠a clasificar y todas son iguales a las clases de ImageNet, sin embargo, no es √∫til si quieres clasificar solo un peque√±o subconjunto de clases (como 10 tipos diferentes de alimentos). Los modelos con `\"/classification\"` en su nombre proporcionan este tipo de funcionalidad.\n",
    "\n",
    "2. **Aprendizaje por transferencia de extracci√≥n de caracter√≠sticas** es cuando tomas los patrones subyacentes (tambi√©n llamados pesos) que un modelo preentrenado ha aprendido y ajustas sus salidas para que se adapten mejor a tu problema.\n",
    "\n",
    "  * Por ejemplo, supongamos que el modelo preentrenado que estabas usando ten√≠a 236 capas diferentes (EfficientNetB0 tiene 236 capas), pero la capa superior produce 1000 clases porque fue preentrenada en ImageNet. Para ajustar esto a tu propio problema, podr√≠as eliminar la capa de activaci√≥n original y reemplazarla con la tuya propia pero con el n√∫mero correcto de clases de salida. La parte importante aqu√≠ es que **solo las primeras capas se vuelven entrenables, el resto permanece congelado**.\n",
    "\n",
    "    * De esta manera, todos los patrones subyacentes permanecen en el resto de las capas y puedes utilizarlos para tu propio problema. Este tipo de aprendizaje por transferencia es muy √∫til cuando tus datos son similares a los datos con los que el modelo fue preentrenado.\n",
    "\n",
    "3. **Aprendizaje por transferencia de ajuste fino (fine tuning)** es cuando tomas los patrones subyacentes (tambi√©n llamados pesos) de un modelo preentrenado y los ajustas (afinas) a tu propio problema.\n",
    "\n",
    "    * Esto generalmente significa entrenar **algunas, muchas o todas** las capas en el modelo preentrenado. Esto es √∫til cuando tienes un conjunto de datos grande (por ejemplo, m√°s de 100 im√°genes por clase) donde tus datos son ligeramente diferentes a los datos con los que el modelo original fue entrenado.\n",
    "\n",
    "Un flujo de trabajo com√∫n es \"congelar\" todos los patrones aprendidos en las capas inferiores de un modelo preentrenado para que no se puedan entrenar. Y luego entrenar las 2-3 capas superiores para que el modelo preentrenado pueda ajustar sus salidas a tus datos personalizados (**extracci√≥n de caracter√≠sticas**).\n",
    "\n",
    "Despu√©s de haber entrenado las 2-3 capas superiores, puedes gradualmente \"descongelar\" m√°s y m√°s capas y ejecutar el proceso de entrenamiento en tus propios datos para afinar a√∫n m√°s el modelo preentrenado.\n",
    "\n",
    "> ü§î **Pregunta:** *¬øPor qu√© entrenar solo las 2-3 capas superiores en la extracci√≥n de caracter√≠sticas?*\n",
    "\n",
    "Cuanto m√°s baja es una capa en un modelo de visi√≥n artificial, es decir, cuanto m√°s cerca est√° de la capa de entrada, mayores son las caracter√≠sticas que aprende. Por ejemplo, una capa inferior en un modelo de visi√≥n por computadora para identificar im√°genes de gatos o perros podr√≠a aprender el contorno de las patas, mientras que, las capas m√°s cercanas a la salida podr√≠an aprender la forma de los dientes. A menudo, querr√°s que las caracter√≠sticas m√°s grandes (los patrones aprendidos tambi√©n se llaman caracter√≠sticas) permanezcan, ya que estas son similares para ambos animales, mientras que, las diferencias permanecen en las caracter√≠sticas m√°s detalladas.\n",
    "\n",
    "![image.png](transfer_learning.png)  \n",
    "*Los diferentes tipos de aprendizaje por transferencia. Un modelo original, un modelo de extracci√≥n de caracter√≠sticas (solo cambia la cabecera) y un modelo de afinamiento fino (cambian muchas o todas las capas del modelo original).*"
   ],
   "id": "2ceaa8a7dd60e9dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ],
   "id": "471d22ee88027c1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# USAREMOS TF_KERAS Para compatibilidad de resnet50v2\n",
    "# pip install tf_keras\n",
    "import tf_keras\n",
    "print(tf_keras.__version__)"
   ],
   "id": "a9774833c9b57bcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# En primer lugar, vamos a cargar nuestro dataset\n",
    "\n",
    "# Definir la forma de la imagen y el tama√±o del lote\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Directorios para los conjuntos de datos de entrenamiento y prueba\n",
    "train_dir = \"./10_food_classes_10_percent/train/\"\n",
    "test_dir = \"./10_food_classes_10_percent/test/\"\n",
    "\n",
    "# Crea el conjunto de datos de entrenamiento, utiliza los par√°metros batch_size, image_size y label_mode='categorical'\n",
    "\n",
    "# Crea el conjunto de datos de prueba de la  misma forma\n"
   ],
   "id": "8665cd1228951d48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#importamos las librer√≠as necesarias\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tf_keras import layers"
   ],
   "id": "8c725264be64f68f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora obtendremos las URLs de vector de caracter√≠sticas de dos arquitecturas, [EfficientNetB0 (2019)](https://www.kaggle.com/models/google/efficientnet-v2/tensorFlow2/imagenet1k-b0-feature-vector/2) y [ResNetV250 (2016)](https://www.kaggle.com/models/google/resnet-v2/tensorFlow2/50-feature-vector/1) desde Kaggle usando los pasos anteriores.\n",
    "\n",
    "Obtenemos ambos porque vamos a compararlos para ver cu√°l se desempe√±a mejor en nuestros datos."
   ],
   "id": "2c7e06011b43d7a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resnet_url = \"https://www.kaggle.com/models/google/resnet-v2/tensorFlow2/50-feature-vector/1\"\n",
    "\n",
    "efficientnet_url = \"https://www.kaggle.com/models/google/efficientnet-v2/tensorFlow2/imagenet1k-b0-feature-vector/2\""
   ],
   "id": "b95be2b15dc324e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model(model_url, num_classes=10):\n",
    "  \"\"\"Toma una URL de TensorFlow Hub y crea un modelo secuencial de Keras con ella.\n",
    "  \n",
    "  Args:\n",
    "    model_url (str): Una URL de extracci√≥n de caracter√≠sticas de TensorFlow Hub.\n",
    "    num_classes (int): N√∫mero de neuronas de salida en la capa de salida,\n",
    "      debe ser igual al n√∫mero de clases objetivo, por defecto 10.\n",
    "\n",
    "  Returns:\n",
    "    Un modelo secuencial de Keras sin compilar con model_url como capa\n",
    "    de extracci√≥n de caracter√≠sticas y capa de salida densa con num_classes salidas.\n",
    "  \"\"\"\n",
    "  model = ...\n",
    "  return model"
   ],
   "id": "7476ecc726d72511",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Crea un modelo basado en Resnet y compilalo\n",
   "id": "2c6fea3ecc0470c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# muestra el resumen del modelo",
   "id": "66b6540ff1d7cfa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entrena el modelo 5 √©pocas: Para el entrenamiento utiliza los par√°metros\n",
    "# steps_per_epoch=len(train_dataset),\n",
    "# validation_data=test_dataset,\n",
    "# validation_steps=len(test_dataset)\n"
   ],
   "id": "9eadd2b0201e7c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ¬°Impresionante!  \n",
    "\n",
    "Parece que despu√©s de solo 5 √©pocas, el modelo de extracci√≥n de caracter√≠sticas **ResNetV250** logr√≥ superar con creces cualquiera de las arquitecturas que creamos, alcanzando aproximadamente un **90% de precisi√≥n en el conjunto de entrenamiento** y casi un **80% de precisi√≥n en el conjunto de prueba... ¬°usando solo el 10% de las im√°genes de entrenamiento!**\n",
    "\n",
    "Esto demuestra el poder del **aprendizaje por transferencia**. Y es una de las principales razones por las que, siempre que intentes modelar tus propios conjuntos de datos, deber√≠as investigar qu√© modelos preentrenados ya existen.\n",
    "\n",
    "Vamos a revisar las curvas de entrenamiento de nuestro modelo utilizando nuestra funci√≥n `plot_loss_curves`.\n"
   ],
   "id": "1440d5887467c593"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizar los datos de validaci√≥n y entrenamiento por separado\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Devuelve curvas de p√©rdida separadas para las m√©tricas de entrenamiento y validaci√≥n.\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Visualizar p√©rdida (loss)\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('P√©rdida (Loss)')\n",
    "  plt.xlabel('√âpocas')\n",
    "  plt.legend()\n",
    "\n",
    "  # Visualizar acierto (accuracy)\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Acierto (Accuracy)')\n",
    "  plt.xlabel('√âpocas')\n",
    "  plt.legend();\n"
   ],
   "id": "e8e19d6e236a68b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# imprime las curvas de entrenamiento",
   "id": "ddb65c1f338c858e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# ¬øCu√°ntos par√°metros del modelo se han modificado?",
   "id": "f896df9ee6df9177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Puedes ver el poder de **TensorFlow Hub** aqu√≠. La capa de extracci√≥n de caracter√≠sticas tiene **23,564,800 par√°metros**, que son patrones previamente aprendidos por el modelo en el conjunto de datos **ImageNet**. Como configuramos `trainable=False`, estos patrones permanecen congelados (no entrenables) durante el entrenamiento.\n",
    "\n",
    "Esto significa que, durante el entrenamiento, el modelo actualiza los **20,490 par√°metros** de la capa de salida para adaptarse a nuestro conjunto de datos.\n",
    "\n",
    "Bien, hemos entrenado un modelo **ResNetV250**, ahora es momento de hacer lo mismo con el modelo **EfficientNetB0**.\n"
   ],
   "id": "a1531d3434101f9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Ahora crea un modelo basado en efficient_net, compila y entrena el modelo 5 √©pocas\n",
   "id": "4f8aafe522ee88f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# muestra las curvas de entrenamiento",
   "id": "edd2f3a105375351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# saca el resumen del modelo",
   "id": "249494730162b950",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "¬°Incre√≠ble! El modelo **EfficientNetB0** iguala al modelo **ResNetV250** con 1/4 de sus par√°metros... nuevamente **usando solo el 10% de los datos de entrenamiento**!\n",
    "\n",
    "Con solo unas pocas l√≠neas de c√≥digo, podemos aprovechar modelos de √∫ltima generaci√≥n y ajustarlos a nuestro propio caso de uso."
   ],
   "id": "394c87ed0af29a22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Para bonus\n",
    "### Puedes intentar utilizar transfer learning de ResNet50 o de EfficientNet con este dataset:\n",
    "[razas de perros](https://www.kaggle.com/code/thiennguyen15/predicting-dog-species-using-resnet50)"
   ],
   "id": "81f86d1cf8a54a61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
