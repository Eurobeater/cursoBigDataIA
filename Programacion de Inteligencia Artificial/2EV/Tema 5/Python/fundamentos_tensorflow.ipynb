{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fa22c6",
   "metadata": {},
   "source": [
    "#### Fundamentos de tensorflow.\n",
    "\n",
    "Vamos a aprender las nociones b√°sicas de tensorflow\n",
    "\n",
    "* Crear tensores\n",
    "* Obtener info de tensores\n",
    "* Manipular tensores\n",
    "* Tensores & numpy\n",
    "* usar @tf.function (una forma de acelerar las funciones de python)\n",
    "* usar gpus \n",
    "\n",
    "\n",
    "### Los Tensores\n",
    "los tensores son algo as√≠ como los arrays de NumPy, para los fines de este cuaderno y de ahora en adelante, puedes pensar en un tensor como una representaci√≥n num√©rica multidimensional (tambi√©n referida como n-dimensional, donde n puede ser cualquier n√∫mero) de algo. Donde algo puede ser casi cualquier cosa que puedas imaginar:\n",
    "\n",
    "- Podr√≠a ser los propios n√∫meros (usando tensores para representar el precio de las casas).\n",
    "- Podr√≠a ser una imagen (usando tensores para representar los p√≠xeles de una imagen).\n",
    "- Podr√≠a ser texto (usando tensores para representar palabras).\n",
    "- O podr√≠a ser alguna otra forma de informaci√≥n (o datos) que quieras representar con n√∫meros.\n",
    "\n",
    "La principal diferencia entre los tensores y los arrays de NumPy (tambi√©n un array n-dimensional de n√∫meros) es que los tensores pueden utilizarse en GPUs (unidades de procesamiento gr√°fico) y TPUs (unidades de procesamiento tensorial).\n",
    "\n",
    "La ventaja de poder ejecutarse en GPUs y TPUs es la computaci√≥n m√°s r√°pida, esto significa que si quisi√©ramos encontrar patrones en las representaciones num√©ricas de nuestros datos, generalmente podemos encontrarlos m√°s r√°pido usando GPUs y TPUs.\n",
    "\n",
    "Lo primero que haremos es importar TensorFlow bajo el alias com√∫n tf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f32f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaef03",
   "metadata": {},
   "source": [
    "### Creando Tensores con tf.constant()\n",
    "\n",
    "Como se mencion√≥ anteriormente, en general, normalmente no crear√°s tensores t√∫ mismo. Esto se debe a que TensorFlow tiene m√≥dulos integrados (como tf.io y tf.data) que son capaces de leer tus fuentes de datos y convertirlas autom√°ticamente en tensores y luego, m√°s adelante, los modelos de redes neuronales procesar√°n estos por nosotros.\n",
    "\n",
    "Pero por ahora, porque estamos familiariz√°ndonos con los tensores en s√≠ mismos y c√≥mo manipularlos, veremos c√≥mo podemos crearlos nosotros mismos.\n",
    "\n",
    "Comenzaremos usando `tf.constant()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d8fde",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor escalar (sin dimensi√≥n):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33c7776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scalar=tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7065be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n√∫mero de dimensiones\n",
    "scalar.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600b9d6",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor vector (una dimensi√≥n):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379daa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([10, 10, 10])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un vector\n",
    "vector = tf.constant([10,10,10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04b0c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0973e",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor matriz (dos dimensiones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19735edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[10,  3,  3],\n",
       "       [ 2,  4,  1]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear matrices\n",
    "matriz=tf.constant([[10,3,3],[2,4,1]])\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6bd561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfbce4",
   "metadata": {},
   "source": [
    "Los tensores en TensorFlow pueden contener diversos tipos de datos, clasificados principalmente por su dtype (tipo de dato). Aqu√≠ se presenta una lista de los tipos de datos m√°s comunes en TensorFlow:\n",
    "\n",
    "- `tf.float32`: Punto flotante de 32 bits.\n",
    "- `tf.float64`: Punto flotante de 64 bits, tambi√©n conocido como `tf.double`.\n",
    "- `tf.int8`: Entero de 8 bits.\n",
    "- `tf.int16`: Entero de 16 bits.\n",
    "- `tf.int32`: Entero de 32 bits.\n",
    "- `tf.int64`: Entero de 64 bits, utilizado com√∫nmente para √≠ndices.\n",
    "- `tf.uint8`: Entero sin signo de 8 bits.\n",
    "- `tf.uint16`: Entero sin signo de 16 bits.\n",
    "- `tf.uint32`: Entero sin signo de 32 bits.\n",
    "- `tf.uint64`: Entero sin signo de 64 bits.\n",
    "- `tf.bool`: Booleano.\n",
    "- `tf.string`: Cadenas de texto.\n",
    "- `tf.complex64`: N√∫mero complejo compuesto por dos floats de 32 bits.\n",
    "- `tf.complex128`: N√∫mero complejo compuesto por dos floats de 64 bits, tambi√©n conocido como `tf.double`.\n",
    "- `tf.qint8`: Entero de 8 bits utilizado en cuantificaci√≥n.\n",
    "- `tf.qint16`: Entero de 16 bits utilizado en cuantificaci√≥n.\n",
    "- `tf.qint32`: Entero de 32 bits utilizado en cuantificaci√≥n.\n",
    "- `tf.quint8`: Entero sin signo de 8 bits utilizado en cuantificaci√≥n.\n",
    "- `tf.quint16`: Entero sin signo de 16 bits utilizado en cuantificaci√≥n.\n",
    "\n",
    "Estos tipos de datos permiten que TensorFlow maneje eficientemente una amplia gama de datos para diferentes tipos de operaciones, incluyendo c√°lculos matem√°ticos, manipulaci√≥n de im√°genes, procesamiento de texto, y mucho m√°s.\n",
    "\n",
    "podemos especificar el tipo de dato de los componentes del tensor, por ejemplo, float, con el par√°metro dtype:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762a889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float16, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [5., 2., 3.]], dtype=float16)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz2=tf.constant([[1,2,3],[5,2,3]],dtype=tf.float16)\n",
    "matriz2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775afd1",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor multidimensional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03500a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
       "array([[[1, 2],\n",
       "        [2, 3],\n",
       "        [4, 5]],\n",
       "\n",
       "       [[2, 3],\n",
       "        [1, 5],\n",
       "        [7, 3]]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un tensor (3 o m√°s dimensiones)\n",
    "tensor=tf.constant([[[1,2],[2,3],[4,5]],\n",
    "                    [[2,3],[1,5],[7,3]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352869a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim  #2 matrices, de tres vectores, de dos posiciones cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d30304",
   "metadata": {},
   "source": [
    "El ejemplo anterior tambi√©n se conoce como un tensor de rango 3 (3 dimensiones), sin embargo, un tensor puede tener una cantidad arbitraria (ilimitada) de dimensiones.\n",
    "\n",
    "Por ejemplo, podr√≠as convertir una serie de im√°genes en tensores con forma (224, 224, 3, 32), donde:\n",
    "* 224, 224 (las primeras 2 dimensiones) son la altura y anchura de las im√°genes en p√≠xeles.\n",
    "* 3 es el n√∫mero de canales de color de la imagen (rojo, verde, azul).\n",
    "* 32 es el tama√±o del lote (el n√∫mero de im√°genes que una red neuronal ve en un momento dado).\n",
    "\n",
    "Todas las variables anteriores que hemos creado son en realidad tensores. Pero tambi√©n puedes escucharlas referidas con sus diferentes nombres (los que les dimos):\n",
    "* **escalar**: un solo n√∫mero.\n",
    "* **vector**: un n√∫mero con direcci√≥n (por ejemplo, velocidad del viento con direcci√≥n).\n",
    "* **matriz**: un array bidimensional de n√∫meros.\n",
    "* **tensor**: un array de n√∫meros n-dimensional (donde n puede ser cualquier n√∫mero, un tensor de 0 dimensiones es un escalar, un tensor de 1 dimensi√≥n es un vector).\n",
    "\n",
    "Para a√±adir a la confusi√≥n, los t√©rminos matriz y tensor a menudo se usan indistintamente.\n",
    "\n",
    "En adelante, dado que estamos utilizando TensorFlow, todo lo que nos referimos y usamos ser√°n tensores.\n",
    "\n",
    "Para m√°s informaci√≥n sobre la diferencia matem√°tica entre escalares, vectores y matrices, consulta la [publicaci√≥n de √°lgebra visual de Math is Fun](https://www.mathsisfun.com/algebra/scalar-vector-matrix.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7352378",
   "metadata": {},
   "source": [
    "### crear tensores con `tf.Variable`\n",
    "- https://www.tensorflow.org/api_docs/python/tf/Variable\n",
    "\n",
    "Tambi√©n puedes (aunque raramente lo har√°s, porque cuando trabajas con datos, los tensores se crean autom√°ticamente) crear tensores usando [`tf.Variable()`](https://www.tensorflow.org/api_docs/python/tf/Variable).\n",
    "\n",
    "La diferencia entre `tf.Variable()` y `tf.constant()` es que los tensores creados con `tf.constant()` son inmutables (no pueden cambiarse, solo pueden usarse para crear un nuevo tensor), mientras que, los tensores creados con `tf.Variable()` son mutables (pueden cambiarse).\n",
    "\n",
    "### Manipulando tensores `tf.Variable`\n",
    "\n",
    "Los tensores creados con `tf.Variable()` pueden ser modificados en su lugar utilizando m√©todos tales como:\n",
    "\n",
    "* [`.assign()`](https://www.tensorflow.org/api_docs/python/tf/Variable#assign) - asigna un valor diferente a un √≠ndice particular de un tensor variable.\n",
    "* [`.add_assign()`](https://www.tensorflow.org/api_docs/python/tf/Variable#assign_add) - a√±ade a un valor existente y lo reasigna en un √≠ndice particular de un tensor variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468154eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mutable=tf.Variable([10,7])\n",
    "tensor_nomutable=tf.constant([10,7])\n",
    "tensor_mutable,tensor_nomutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3158bd61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\382820706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cambiar uno de los elementos en un mutable -> ERROR!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtensor_mutable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# cambiar uno de los elementos en un mutable -> ERROR!\n",
    "tensor_mutable[0]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "310234b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2,) dtype=int32, numpy=array([5, 7])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hay que usar assign\n",
    "tensor_mutable[0].assign(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81de7e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\1837065464.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#no se puede usar assign en un tensor constante\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtensor_nomutable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \"\"\")\n\u001b[1;32m--> 444\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "#no se puede usar assign en un tensor constante\n",
    "tensor_nomutable[0].assign(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f0d77b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int32, numpy=array([ 0,  1,  2,  3, 50])>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una variable tensor y asignar valores\n",
    "I = tf.Variable(np.arange(0, 5))\n",
    "I.assign([0, 1, 2, 3, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e56929c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int32, numpy=array([10, 11, 12, 13, 60])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a√±adir 10 a todos los valores\n",
    "I.assign_add([10, 10, 10, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9fd1b",
   "metadata": {},
   "source": [
    "## crear tensores aleatorios\n",
    "#### tf.random.uniform y tf.random.normal \n",
    "\n",
    "Los tensores aleatorios son tensores de alg√∫n tama√±o arbitrario que contienen n√∫meros aleatorios.\n",
    "\n",
    "¬øPor qu√© querr√≠as crear tensores aleatorios?\n",
    "\n",
    "Esto es lo que las redes neuronales utilizan para inicializar sus pesos (patrones) que est√°n intentando aprender en los datos.\n",
    "\n",
    "Por ejemplo, el proceso de aprendizaje de una red neuronal a menudo implica tomar un array n-dimensional aleatorio de n√∫meros y refinarlos hasta que representen alg√∫n tipo de patr√≥n (una manera comprimida de representar los datos originales).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e5f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1 = tf.random.Generator.from_seed(42) # semilla para 'reproducibilidad'\n",
    "random_1 = random_1.normal(shape=(3, 2)) # crear un tensor desde la distribuci√≥n normal\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "\n",
    "# son iguales?\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b4a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [ 2,  5],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mezclar un tensor\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "\n",
    "# diferentes resultados cada vez\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "578d9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.45331386,  1.1487608 ],\n",
       "       [-1.2659091 , -0.47450137],\n",
       "       [ 2.006022  ,  0.28288034]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear utilizando semilla\n",
    "random1=tf.random.Generator.from_seed(50)\n",
    "tensor1=random1.normal(shape=(3,2))\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cb6288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 2.006022  ,  0.28288034],\n",
       "       [-1.2659091 , -0.47450137],\n",
       "       [ 0.45331386,  1.1487608 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mezclar utilizando semilla\n",
    "tensor1=tf.random.shuffle(tensor1,seed=42)\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149c6db",
   "metadata": {},
   "source": [
    "Prueba a ejecutar la celda anterior varias veces, ¬øPor qu√© no sale siempre el mismo orden?\n",
    "\n",
    "Es debido a la regla #4 de la documentaci√≥n de [`tf.random.set_seed()`](https://www.tensorflow.org/api_docs/python/tf/random/set_seed).\n",
    "\n",
    "> \"4. Si se establecen tanto la semilla global como la semilla de la operaci√≥n: Ambas semillas se utilizan en conjunto para determinar la secuencia aleatoria.\"\n",
    "\n",
    "`tf.random.set_seed(42)` establece la semilla global, y el par√°metro `seed` en `tf.random.shuffle(seed=42)` establece la semilla de la operaci√≥n.\n",
    "\n",
    "Porque, \"Las operaciones que dependen de una semilla aleatoria en realidad la derivan de dos semillas: las semillas global y de nivel de operaci√≥n.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "673807e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mezclar siempre en el mismo orden\n",
    "\n",
    "#global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# random seed de la operaci√≥n\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e6facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [ 2,  5],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establece la semilla global\n",
    "tf.random.set_seed(42) # si comentas esto, obtienes siempre resultados diferentes\n",
    "\n",
    "#se usa solo la semilla global\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3424af0",
   "metadata": {},
   "source": [
    "### Otras formas de crear tensores\n",
    "\n",
    "Aunque raramente las uses (recuerda, muchas operaciones de tensores se realizan detr√°s de escena por ti), puedes usar [`tf.ones()`](https://www.tensorflow.org/api_docs/python/tf/ones) para crear un tensor de unos y [`tf.zeros()`](https://www.tensorflow.org/api_docs/python/tf/zeros) para crear un tensor de ceros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7915398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(3, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697a6a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(shape=(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe6080",
   "metadata": {},
   "source": [
    "Tambi√©n puedes convertir arrays de NumPy en tensores.\n",
    "\n",
    "Recuerda, la principal diferencia entre los tensores y los arrays de NumPy es que los tensores pueden ejecutarse en GPUs.\n",
    "\n",
    "üîë Nota: Una matriz o tensor t√≠picamente se representa por una letra may√∫scula (por ejemplo, X o A) mientras que un vector se representa t√≠picamente por una letra min√∫scula (por ejemplo, y o b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a0384d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24]),\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15],\n",
       "         [16, 17, 18],\n",
       "         [19, 20, 21],\n",
       "         [22, 23, 24]]])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32) # crear un array de numpy\n",
    "A = tf.constant(numpy_A,  \n",
    "                shape=[2, 4, 3]) # nota: la forma total (2*4*3) tiene que casar con el n√∫mero de elementos del array\n",
    "numpy_A, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30437092",
   "metadata": {},
   "source": [
    "### Obteniendo informaci√≥n de los tensores (forma, rango, tama√±o)\n",
    "Habr√° momentos en los que querr√°s obtener diferentes piezas de informaci√≥n de tus tensores, en particular, debes conocer el siguiente vocabulario sobre tensores:\n",
    "\n",
    "- **Forma (shape)**: La longitud (n√∫mero de elementos) de cada una de las dimensiones de un tensor.\n",
    "- **Rango (rank) **: El n√∫mero de dimensiones de un tensor. Un escalar tiene rango 0, un vector tiene rango 1, una matriz tiene rango 2, un tensor tiene rango n.\n",
    "- **Eje o Dimensi√≥n (axis) **: Una dimensi√≥n particular de un tensor.\n",
    "- **Tama√±o (size)**: El n√∫mero total de elementos en el tensor.\n",
    "\n",
    "Especialmente utilizar√°s estos cuando est√©s intentando alinear las formas de tus datos con las formas de tu modelo. Por ejemplo, asegur√°ndote de que la forma de tus tensores de imagen sea la misma que la forma de la capa de entrada de tu modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fd4758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create un tensor de rango 4  (4 dimensiones)\n",
    "rank_4_tensor = tf.zeros([2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72038323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87037c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo de datos de cada elemento: <dtype: 'float32'>\n",
      "n√∫mero de dimensiones (rank): 4\n",
      "Forma del tensor: (2, 3, 4, 5)\n",
      "Elementos del eje 0 del tensor: 2\n",
      "Elementos del √∫ltimo eje del tensor: 5\n",
      "N√∫mero total de elementos (2*3*4*5): 120\n"
     ]
    }
   ],
   "source": [
    "print(\"tipo de datos de cada elemento:\", rank_4_tensor.dtype)\n",
    "print(\"n√∫mero de dimensiones (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Forma del tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elementos del eje 0 del tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elementos del √∫ltimo eje del tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"N√∫mero total de elementos (2*3*4*5):\", tf.size(rank_4_tensor).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b26f13",
   "metadata": {},
   "source": [
    "Se pueden indexar tensores como en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bb2a189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dame los dos primeros elementos de cada dimensi√≥n\n",
    "rank_4_tensor[:2, :2, :2, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7408e656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor = tf.constant([[10, 7],\n",
    "                             [3, 4]])\n",
    "\n",
    "# Obtener el √∫ltimo elemento de cada fila\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4944e9",
   "metadata": {},
   "source": [
    "Tambi√©n puedes a√±adir dimensiones a tu tensor mientras mantienes la misma informaci√≥n presente usando `tf.newaxis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad09909d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4]])>,\n",
       " <tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       " array([[[10],\n",
       "         [ 7]],\n",
       " \n",
       "        [[ 3],\n",
       "         [ 4]]])>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a√±adir una nueva dimensi√≥n (al final)\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis] # en Python \"...\" significa \"todas las dimensiones previas\"\n",
    "rank_2_tensor, rank_3_tensor # shape (2, 2), shape (2, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134d380",
   "metadata": {},
   "source": [
    "esto tambi√©n se puede hacer con `tf.expand_dims()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60d742ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" significa √∫ltimo eje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05dc407",
   "metadata": {},
   "source": [
    "## Manipulando tensores (operaciones con tensores)\n",
    "\n",
    "Encontrar patrones en tensores (representaci√≥n num√©rica de los datos) requiere manipularlos.\n",
    "\n",
    "De nuevo, cuando construyes modelos en TensorFlow, gran parte de este descubrimiento de patrones se hace por ti.\n",
    "\n",
    "### Operaciones b√°sicas\n",
    "\n",
    "Puedes realizar muchas de las operaciones matem√°ticas b√°sicas directamente en tensores usando operadores de Python, tales como, `+`, `-`, `*`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be7c2a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suma\n",
    "tensor = tf.constant([[10, 7], [3, 4]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "449a007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplicaci√≥n (elemento a elemento)\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29c26f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resta\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cade1af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply, id√©ntico a '*' \n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96321d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# los tensores originales no se cambian cuando se utilizan estos operadores\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552accc9",
   "metadata": {},
   "source": [
    "### Multiplicaci√≥n de matrices\n",
    "\n",
    "Una de las operaciones m√°s comunes en los algoritmos de aprendizaje autom√°tico es la [multiplicaci√≥n de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "TensorFlow implementa esta funcionalidad de multiplicaci√≥n de matrices en el m√©todo [`tf.matmul()`](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul).\n",
    "\n",
    "Las dos reglas principales para recordar sobre la multiplicaci√≥n de matrices son:\n",
    "1. Las dimensiones internas deben coincidir:\n",
    "  * `(3, 5) @ (3, 5)` no funcionar√°\n",
    "  * `(5, 3) @ (3, 5)` funcionar√°\n",
    "  * `(3, 5) @ (5, 3)` funcionar√°\n",
    "2. La matriz resultante tiene la forma de las dimensiones exteriores:\n",
    " * `(5, 3) @ (3, 5)` -> `(5, 5)`\n",
    " * `(3, 5) @ (5, 3)` -> `(3, 3)`\n",
    "\n",
    "> üîë **Nota:** '`@`' en Python es el s√≠mbolo para la multiplicaci√≥n de matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b6a9ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor)\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3651b92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id√©ntico al anterior\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1268b27",
   "metadata": {},
   "source": [
    "La multiplicaci√≥n anterior funcionaba porque los dos eran tensores de 2,2, si creamos de dimensiones incompatibles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d78d00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  (3, 2) \n",
    "X = tf.constant([[1, 2],\n",
    "                 [3, 4],\n",
    "                 [5, 6]])\n",
    "\n",
    "#  (3, 2) \n",
    "Y = tf.constant([[7, 8],\n",
    "                 [9, 10],\n",
    "                 [11, 12]])\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fba410d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\1809164124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mY\u001b[0m \u001b[1;31m#error!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7215\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "X @ Y #error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb378ac",
   "metadata": {},
   "source": [
    "Intentar multiplicar matrices de dos tensores con forma `(3, 2)` genera errores porque las dimensiones internas no coinciden.\n",
    "\n",
    "Necesitamos:\n",
    "* Cambiar la forma de X a `(2, 3)` para que sea `(2, 3) @ (3, 2)`.\n",
    "* Cambiar la forma de Y a `(3, 2)` para que sea `(3, 2) @ (2, 3)`.\n",
    "\n",
    "Podemos hacer esto con:\n",
    "* [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape) - nos permite cambiar la forma de un tensor a una forma definida.\n",
    "* [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) - cambia las dimensiones de un tensor dado.\n",
    "\n",
    "![alineando dimensiones para el producto de matrices (dot product)](https://www.mathsisfun.com/algebra/images/matrix-multiply-b.svg)\n",
    "\n",
    "Probemos primero `tf.reshape()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46d9d514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recuerda\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dedcd35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  8,  9],\n",
       "       [10, 11, 12]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(Y, shape=(2, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96461aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ tf.reshape(Y, shape=(2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bdaa7",
   "metadata": {},
   "source": [
    "Funcion√≥, intentemos lo mismo con un `X` reconfigurado, excepto que esta vez usaremos [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) y `tf.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f188f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcc47c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba3672",
   "metadata": {},
   "source": [
    "Se puede obtener el mismo resultado con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e20abe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a=X, b=Y, transpose_a=True, transpose_b=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd7acf",
   "metadata": {},
   "source": [
    "Observa la diferencia en las formas resultantes al transponer `X` o reconfigurar `Y`.\n",
    "\n",
    "Esto se debe a la 2da regla mencionada anteriormente:\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)` hecho con `X @ tf.reshape(Y, shape=(2, 3))` \n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)` hecho con `tf.matmul(tf.transpose(X), Y)`\n",
    "\n",
    "Este tipo de manipulaci√≥n de datos es un recordatorio: pasar√°s mucho de tu tiempo en el aprendizaje autom√°tico y trabajando con redes neuronales reconfigurando datos (en forma de tensores) para prepararlos para ser usados con varias operaciones (como alimentarlos a un modelo).\n",
    "\n",
    "### El dot product (producto punto)\n",
    "\n",
    "Multiplicar matrices de forma gen√©rica tambi√©n se conoce como el producto punto.\n",
    "\n",
    "Puedes realizar la operaci√≥n `tf.matmul()` usando [`tf.tensordot()`](https://www.tensorflow.org/api_docs/python/tf/tensordot).\n",
    "\n",
    "`tf.tensordot()`:\n",
    "\n",
    "Permite realizar el producto punto entre tensores, especificando los ejes sobre los cuales se quiere realizar la operaci√≥n.\n",
    "Es m√°s flexible ya que puedes especificar los ejes a lo largo de los cuales el producto punto debe ser calculado. Esto significa que `tf.tensordot()` puede ser usado no solo para la multiplicaci√≥n de matrices, sino tambi√©n para operaciones m√°s generales de producto punto.\n",
    "Puede manejar tensores de cualquier rango, y los ejes a lo largo de los cuales se realiza el producto punto pueden ser configurados, permitiendo as√≠ una gama m√°s amplia de operaciones de √°lgebra tensorial m√°s all√° de la simple multiplicaci√≥n de matrices.\n",
    "\n",
    "Las operaciones de producto punto (dot product) son fundamentales en √°lgebra lineal y tienen varias aplicaciones importantes, especialmente en el campo del aprendizaje autom√°tico y el procesamiento de se√±ales. Aqu√≠ se describen varios tipos de operaciones de producto punto:\n",
    "1. **Producto Punto Escalar (Scalar Dot Product):**\n",
    "   - Este es el caso m√°s simple y se aplica a vectores de la misma dimensi√≥n. El resultado es un escalar. Por ejemplo, el producto punto de dos vectores `a` y `b` se calcula como:\n",
    "   \n",
    "     $$\n",
    "     \\sum_{i=1}^{n} a_i b_i\n",
    "     $$\n",
    "\n",
    "2. **Multiplicaci√≥n de Matrices (Matrix Multiplication):**\n",
    "   - Es una generalizaci√≥n del producto punto escalar a matrices. Si tienes dos matrices, A de tama√±o $$ m \\times n $$ y B de tama√±o $$ n \\times p $$, el resultado es una nueva matriz C de tama√±o $$ m \\times p $$, donde cada elemento $$ C_{ij} $$ es el producto punto de la fila i de  A y la columna  j de  B:\n",
    "\n",
    "     $$\n",
    "     C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj}\n",
    "     $$\n",
    "\n",
    "3. **Producto Tensorial (Tensor Dot Product):**\n",
    "   - Esta operaci√≥n extiende el concepto de producto punto a tensores de orden superior. En el contexto de tensores, el producto punto puede realizarse a lo largo de uno o m√°s ejes especificados. Por ejemplo, si tienes dos tensores tridimensionales, puedes calcular el producto punto a lo largo de un eje particular, combinando las dimensiones correspondientes de cada tensor.\n",
    "\n",
    "\n",
    "4. **Producto Punto Interno (Inner Product):**\n",
    "   - Es similar al producto punto escalar, pero se usa en el contexto de espacios de dimensi√≥n superior. En matem√°ticas, el producto interior generaliza el concepto de producto punto a espacios vectoriales de dimensiones m√°s altas.\n",
    "\n",
    "     $$\n",
    "     \\langle \\mathbf{a}, \\mathbf{b} \\rangle = \\sum_{i=1}^{n} a_i b_i\n",
    "     $$\n",
    "\n",
    "5. **Producto Punto Externo (Outer Product):**\n",
    "   - A diferencia del producto punto que produce un escalar (en el caso de vectores) o una matriz (en el caso de matrices), el producto externo toma dos vectores y produce una matriz. Si tienes dos vectores `a` y `b`, el producto externo es una matriz donde cada elemento es:\n",
    "\n",
    "     $$\n",
    "     C_{ij} = a_i b_j\n",
    "     $$\n",
    "\n",
    "6. **Convolution:**\n",
    "   - Aunque no es un producto punto en el sentido tradicional, la convoluci√≥n en el procesamiento de se√±ales y en redes neuronales convolucionales se puede conceptualizar como una operaci√≥n de producto punto entre filtros y segmentos de la se√±al o imagen, especialmente cuando se implementa mediante operaciones de matriz.\n",
    "\n",
    "Cada uno de estos tipos de operaciones de producto punto tiene aplicaciones espec√≠ficas y se elige en funci√≥n del problema a resolver, la naturaleza de los datos y los objetivos del an√°lisis o del modelo de aprendizaje autom√°tico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1680949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza el producto X e Y (requiere la traspuesta de X)\n",
    "tf.tensordot(tf.transpose(X), Y, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1e7e6",
   "metadata": {},
   "source": [
    "### Cambiando el tipo de dato de un tensor\n",
    "\n",
    "A veces querr√°s alterar el tipo de dato predeterminado de tu tensor.\n",
    "\n",
    "Esto es com√∫n cuando quieres computar usando menos precisi√≥n (por ejemplo, n√∫meros de punto flotante de 16 bits vs. n√∫meros de punto flotante de 32 bits).\n",
    "\n",
    "Computar con menos precisi√≥n es √∫til en dispositivos con menor capacidad de c√≥mputo como dispositivos m√≥viles (porque menos bits, requieren menos espacio en las computaciones).\n",
    "\n",
    "Puedes cambiar el tipo de dato de un tensor usando [`tf.cast()`](https://www.tensorflow.org/api_docs/python/tf/cast).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7af62edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7, 7.4], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 7])>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor con tipo por defecto (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "\n",
    "# Crear un tensor con tipo por defecto(int32)\n",
    "C = tf.constant([1, 7])\n",
    "B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f8c32fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de float32 a float16 (precisi√≥n reducida)\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09ed0b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int32 to float32\n",
    "C = tf.cast(C, dtype=tf.float32)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62430791",
   "metadata": {},
   "source": [
    "### Obteniendo el valor absoluto\n",
    "A veces querr√°s los valores absolutos (todos los valores son positivos) de los elementos en tus tensores.\n",
    "\n",
    "Para hacerlo, puedes usar [`tf.abs()`](https://www.tensorflow.org/api_docs/python/tf/math/abs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "722387b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = tf.constant([-7, -10])\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2322ee",
   "metadata": {},
   "source": [
    "### Encontrando el m√≠nimo, m√°ximo, media, suma (agregaci√≥n)\n",
    "\n",
    "Es posible agregar (realizar un c√°lculo en todo un tensor) tensores para encontrar cosas como el valor m√≠nimo, valor m√°ximo, media y suma de todos los elementos.\n",
    "\n",
    "Para hacerlo, los m√©todos de agregaci√≥n t√≠picamente tienen la sintaxis `reduce()_[acci√≥n]`, tales como:\n",
    "* [`tf.reduce_min()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_min) - encontrar el valor m√≠nimo en un tensor.\n",
    "* [`tf.reduce_max()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_max) - encontrar el valor m√°ximo en un tensor (√∫til cuando quieres encontrar la probabilidad de predicci√≥n m√°s alta).\n",
    "* [`tf.reduce_mean()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean) - encontrar la media de todos los elementos en un tensor.\n",
    "* [`tf.reduce_sum()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum) - encontrar la suma de todos los elementos en un tensor.\n",
    "* **Nota:** t√≠picamente, cada uno de estos est√° bajo el m√≥dulo `math`, por ejemplo, `tf.math.reduce_min()` pero puedes usar el alias `tf.reduce_min()`.\n",
    "\n",
    "Ve√°moslos en acci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7921d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([ 2, 46, 25, 57, 86, 62, 57, 30, 65, 58, 83, 57, 18, 95, 33,  0, 82,\n",
       "       22, 44, 84,  0, 99, 86, 56, 23, 86,  6, 95, 60, 63, 87, 40, 20, 83,\n",
       "       72, 64, 32,  1, 94, 67, 72, 26, 45, 81, 62, 49, 73, 83, 70, 44])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor con 50 valores random entre 0 y 100\n",
    "E = tf.constant(np.random.randint(low=0, high=100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97d90938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m√≠nimo\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04066a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=99>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#m√°ximo\n",
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f102ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=54>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#media\n",
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a0f1020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2745>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suma\n",
    "tf.reduce_sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d03e9",
   "metadata": {},
   "source": [
    "Tambi√©n puedes calcular la desviaci√≥n est√°ndar ([`tf.reduce_std()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_std)) y la varianza ([`tf.reduce_variance()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_variance)) de los elementos en un tensor usando m√©todos similares.\n",
    "\n",
    "### Encontrando el m√°ximo y m√≠nimo posicional\n",
    "\n",
    "¬øY c√≥nmo se busca la posici√≥n en un tensor donde est√° el valor m√°ximo?\n",
    "\n",
    "Esto es √∫til cuando quieres alinear tus etiquetas (digamos `['Verde', 'Azul', 'Rojo']`) con tu tensor de probabilidades de predicci√≥n (por ejemplo, `[0.98, 0.01, 0.01]`).\n",
    "\n",
    "En este caso, la etiqueta predicha (la que tiene la probabilidad de predicci√≥n m√°s alta) ser√≠a `'Verde'`.\n",
    "\n",
    "Puedes hacer lo mismo para el m√≠nimo (si es necesario) con lo siguiente:\n",
    "* [`tf.argmax()`](https://www.tensorflow.org/api_docs/python/tf/math/argmax) - encontrar la posici√≥n del elemento m√°ximo en un tensor dado.\n",
    "* [`tf.argmin()`](https://www.tensorflow.org/api_docs/python/tf/math/argmin) - encontrar la posici√≥n del elemento m√≠nimo en un tensor dado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4421e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([0.72353716, 0.40246822, 0.83161408, 0.18778498, 0.59395943,\n",
       "       0.13271066, 0.51486337, 0.96825219, 0.35256278, 0.18844455,\n",
       "       0.02418701, 0.73970864, 0.29409647, 0.56235161, 0.19198946,\n",
       "       0.47516714, 0.5799864 , 0.41018299, 0.41333635, 0.70265714,\n",
       "       0.49633263, 0.54030857, 0.82307685, 0.04836412, 0.0091889 ,\n",
       "       0.07678453, 0.64558563, 0.05141719, 0.99844597, 0.91875711,\n",
       "       0.54139259, 0.53916083, 0.8578127 , 0.2051635 , 0.00872412,\n",
       "       0.22493663, 0.83131279, 0.89433529, 0.42100545, 0.26250721,\n",
       "       0.31896887, 0.17471295, 0.82056182, 0.26470344, 0.93565609,\n",
       "       0.61338234, 0.17960954, 0.45824037, 0.16195915, 0.78934159])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crear un tensor con 50 valores entre 0 y 1\n",
    "F = tf.constant(np.random.random(50))\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfdcc2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=28>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscar la posici√≥n del elemento m√°ximo de F\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f4a0880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=34>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscar la posici√≥n del elemento m√≠nimo de F\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07a045d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La posici√≥n del valor m√°ximo de F es: 28\n",
      "El valor m√°ximo de F es: 0.9984459657426845\n",
      "Usando tf.argmax() para indexar F, el valor m√°ximo de F es: 0.9984459657426845\n",
      "¬øSon los dos valores m√°ximos iguales (deber√≠an serlo)? True\n"
     ]
    }
   ],
   "source": [
    "# Encuentra la posici√≥n del elemento m√°ximo de F\n",
    "print(f\"La posici√≥n del valor m√°ximo de F es: {tf.argmax(F).numpy()}\") \n",
    "print(f\"El valor m√°ximo de F es: {tf.reduce_max(F).numpy()}\") \n",
    "print(f\"Usando tf.argmax() para indexar F, el valor m√°ximo de F es: {F[tf.argmax(F)].numpy()}\")\n",
    "print(f\"¬øSon los dos valores m√°ximos iguales (deber√≠an serlo)? {F[tf.argmax(F)].numpy() == tf.reduce_max(F).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77488b40",
   "metadata": {},
   "source": [
    "### Comprimiendo un tensor (eliminando todas las dimensiones unitarias)\n",
    "\n",
    "Si necesitas eliminar las dimensiones unitarias de un tensor (dimensiones de tama√±o 1), puedes usar `tf.squeeze()`.\n",
    "\n",
    "* [`tf.squeeze()`](https://www.tensorflow.org/api_docs/python/tf/squeeze) - elimina todas las dimensiones de 1 de un tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11fb600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1, 1, 1, 50]), 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor de rango 5 con n√∫meros entre 0 y 100\n",
    "G = tf.constant(np.random.randint(0, 100, 50), shape=(1, 1, 1, 1, 50))\n",
    "G.shape, G.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6298f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze G (eliminar todas las dimensiones 1)\n",
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed.shape, G_squeezed.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c167e5",
   "metadata": {},
   "source": [
    "### Codificaci√≥n one-hot\n",
    "\n",
    "Si tienes un tensor de √≠ndices y te gustar√≠a codificarlo en one-hot, puedes usar [`tf.one_hot()`](https://www.tensorflow.org/api_docs/python/tf/one_hot).\n",
    "\n",
    "Tambi√©n deber√≠as especificar el par√°metro `depth` (el nivel al que quieres codificar en one-hot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcb89103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una lista de √≠ndices\n",
    "some_list = [0, 1, 2, 3]\n",
    "\n",
    "# codificarlos en One hot\n",
    "tf.one_hot(some_list, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4057670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'activo!', b'inactivo!', b'inactivo!', b'inactivo!'],\n",
       "       [b'inactivo!', b'activo!', b'inactivo!', b'inactivo!'],\n",
       "       [b'inactivo!', b'inactivo!', b'activo!', b'inactivo!'],\n",
       "       [b'inactivo!', b'inactivo!', b'inactivo!', b'activo!']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especificar valores personalizados para on y off \n",
    "tf.one_hot(some_list, depth=4, on_value=\"activo!\", off_value=\"inactivo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddecb1",
   "metadata": {},
   "source": [
    "### Operaciones matem√°ticas ( log, raiz cuadrada, cuadrado...)\n",
    "\n",
    "Tensorflow tambi√©n ofrece operaciones matem√°ticas como: \n",
    "\n",
    "* [`tf.square()`](https://www.tensorflow.org/api_docs/python/tf/math/square) - cuadrado de todos los valores de un tensor. \n",
    "* [`tf.sqrt()`](https://www.tensorflow.org/api_docs/python/tf/math/sqrt) - ra√≠z cuadrada de todos los elementos de un tensor\n",
    "* [`tf.math.log()`](https://www.tensorflow.org/api_docs/python/tf/math/log) - logaritmo de todos los elementos (base 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f71a8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1  4  9 16 25 36 49 64 81], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "H = tf.constant(np.arange(1, 10))\n",
    "print(tf.square(H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dbc2682",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\4028006509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#no debe ser entero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7215\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]"
     ]
    }
   ],
   "source": [
    "print(tf.sqrt(H)) #no debe ser entero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a7188bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.236068 , 2.4494898,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast a float32\n",
    "H = tf.cast(H, dtype=tf.float32)\n",
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f6d8018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9567b",
   "metadata": {},
   "source": [
    "## Tensores y NumPy\n",
    "\n",
    "Hemos visto algunos ejemplos de c√≥mo los tensores interact√∫an con los arrays de NumPy, por ejemplo, utilizando arrays de NumPy para crear tensores.\n",
    "\n",
    "Los tensores tambi√©n pueden ser convertidos a arrays de NumPy utilizando:\n",
    "\n",
    "* `np.array()` - pasa un tensor para convertirlo en un ndarray (el tipo de dato principal de NumPy).\n",
    "* `tensor.numpy()` - se llama en un tensor para convertirlo en un ndarray.\n",
    "\n",
    "Hacer esto es √∫til ya que hace que los tensores sean iterables, as√≠ como tambi√©n nos permite usar cualquiera de los m√©todos de NumPy en ellos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c59dfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un tensor desde un array de numpy\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "648fcfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir el tensor J a un np array\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26eef7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir tensor J a NumPy con .numpy()\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0a3ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor desde NumPy y desde un array\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.])) # ser√° float64 (por NumPy)\n",
    "tensor_J = tf.constant([3., 7., 10.]) # ser√° float32 (por defecto de Tensorflow)\n",
    "numpy_J.dtype, tensor_J.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddf829",
   "metadata": {},
   "source": [
    "## Usando `@tf.function`\n",
    "\n",
    "En tus aventuras con TensorFlow, podr√≠as encontrarte con funciones de Python que tienen el decorador [`@tf.function`](https://www.tensorflow.org/api_docs/python/tf/function).\n",
    "\n",
    "Si no est√°s seguro de qu√© hacen los decoradores de Python, [lee la gu√≠a de RealPython sobre ellos](https://realpython.com/primer-on-python-decorators/).\n",
    "\n",
    "Pero en resumen, los decoradores modifican una funci√≥n de una manera u otra.\n",
    "\n",
    "En el caso del decorador `@tf.function`, convierte una funci√≥n de Python en un grafo de TensorFlow llamable. Que es una forma elegante de decir, si has escrito tu propia funci√≥n de Python, y la decoras con `@tf.function`, cuando exportas tu c√≥digo (para potencialmente ejecutar en otro dispositivo), TensorFlow intentar√° convertirlo en una versi√≥n m√°s r√°pida de s√≠ mismo (haci√©ndola parte de un grafo de computaci√≥n).\n",
    "\n",
    "Para m√°s informaci√≥n sobre esto, lee la gu√≠a [Mejor rendimiento con tf.function](https://www.tensorflow.org/guide/function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ead7dcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crear una funci√≥n sencilla\n",
    "def function(x, y):\n",
    "  return x ** 2 + y\n",
    "\n",
    "x = tf.constant(np.arange(0, 10))\n",
    "y = tf.constant(np.arange(10, 20))\n",
    "function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee8f8751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear la misma funci√≥n con el decorador tf.function\n",
    "@tf.function\n",
    "def tf_function(x, y):\n",
    "  return x ** 2 + y\n",
    "\n",
    "tf_function(x, y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d9553d2",
   "metadata": {},
   "source": [
    "Ver√°s que no hay diferencia visible entre las dos funciones anterior. Las diferencias est√°n en la forma de ejecutarse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842fc6c",
   "metadata": {},
   "source": [
    "## Encontrando acceso a GPUs\n",
    "\n",
    "¬øc√≥mo se puede verificar si hay una disponible?\n",
    "\n",
    "Puedes comprobar si tienes acceso a una GPU utilizando [`tf.config.list_physical_devices()`](https://www.tensorflow.org/guide/gpu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad6f0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f870790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 07:43:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.70                 Driver Version: 537.70       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX350         WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   38C    P8              N/A / ERR! |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe1961",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| **Hyperparameter** | **Typical value** |\n",
    "| --- | --- |\n",
    "| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |\n",
    "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
    "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
    "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
    "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n",
    "| Output activation | None, ReLU, logistic/tanh |\n",
    "| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n",
    "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n",
    "\n",
    "*Table 1: Typical architecture of a regression network. Source: Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aur√©lien G√©ron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e4d6e",
   "metadata": {},
   "source": [
    "> üîë **Nota:** Si tienes acceso a una GPU, autom√°ticamente Tensorflow la usar√° cuando sea posible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
