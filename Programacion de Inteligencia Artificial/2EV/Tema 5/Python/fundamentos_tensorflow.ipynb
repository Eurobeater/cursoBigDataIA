{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fa22c6",
   "metadata": {},
   "source": [
    "#### Fundamentos de tensorflow.\n",
    "\n",
    "Vamos a aprender las nociones básicas de tensorflow\n",
    "\n",
    "* Crear tensores\n",
    "* Obtener info de tensores\n",
    "* Manipular tensores\n",
    "* Tensores & numpy\n",
    "* usar @tf.function (una forma de acelerar las funciones de python)\n",
    "* usar gpus \n",
    "\n",
    "\n",
    "### Los Tensores\n",
    "los tensores son algo así como los arrays de NumPy, para los fines de este cuaderno y de ahora en adelante, puedes pensar en un tensor como una representación numérica multidimensional (también referida como n-dimensional, donde n puede ser cualquier número) de algo. Donde algo puede ser casi cualquier cosa que puedas imaginar:\n",
    "\n",
    "- Podría ser los propios números (usando tensores para representar el precio de las casas).\n",
    "- Podría ser una imagen (usando tensores para representar los píxeles de una imagen).\n",
    "- Podría ser texto (usando tensores para representar palabras).\n",
    "- O podría ser alguna otra forma de información (o datos) que quieras representar con números.\n",
    "\n",
    "La principal diferencia entre los tensores y los arrays de NumPy (también un array n-dimensional de números) es que los tensores pueden utilizarse en GPUs (unidades de procesamiento gráfico) y TPUs (unidades de procesamiento tensorial).\n",
    "\n",
    "La ventaja de poder ejecutarse en GPUs y TPUs es la computación más rápida, esto significa que si quisiéramos encontrar patrones en las representaciones numéricas de nuestros datos, generalmente podemos encontrarlos más rápido usando GPUs y TPUs.\n",
    "\n",
    "Lo primero que haremos es importar TensorFlow bajo el alias común tf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f32f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaef03",
   "metadata": {},
   "source": [
    "### Creando Tensores con tf.constant()\n",
    "\n",
    "Como se mencionó anteriormente, en general, normalmente no crearás tensores tú mismo. Esto se debe a que TensorFlow tiene módulos integrados (como tf.io y tf.data) que son capaces de leer tus fuentes de datos y convertirlas automáticamente en tensores y luego, más adelante, los modelos de redes neuronales procesarán estos por nosotros.\n",
    "\n",
    "Pero por ahora, porque estamos familiarizándonos con los tensores en sí mismos y cómo manipularlos, veremos cómo podemos crearlos nosotros mismos.\n",
    "\n",
    "Comenzaremos usando `tf.constant()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d8fde",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor escalar (sin dimensión):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33c7776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scalar=tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7065be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#número de dimensiones\n",
    "scalar.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600b9d6",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor vector (una dimensión):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379daa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([10, 10, 10])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un vector\n",
    "vector = tf.constant([10,10,10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04b0c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0973e",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor matriz (dos dimensiones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19735edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[10,  3,  3],\n",
       "       [ 2,  4,  1]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear matrices\n",
    "matriz=tf.constant([[10,3,3],[2,4,1]])\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6bd561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfbce4",
   "metadata": {},
   "source": [
    "Los tensores en TensorFlow pueden contener diversos tipos de datos, clasificados principalmente por su dtype (tipo de dato). Aquí se presenta una lista de los tipos de datos más comunes en TensorFlow:\n",
    "\n",
    "- `tf.float32`: Punto flotante de 32 bits.\n",
    "- `tf.float64`: Punto flotante de 64 bits, también conocido como `tf.double`.\n",
    "- `tf.int8`: Entero de 8 bits.\n",
    "- `tf.int16`: Entero de 16 bits.\n",
    "- `tf.int32`: Entero de 32 bits.\n",
    "- `tf.int64`: Entero de 64 bits, utilizado comúnmente para índices.\n",
    "- `tf.uint8`: Entero sin signo de 8 bits.\n",
    "- `tf.uint16`: Entero sin signo de 16 bits.\n",
    "- `tf.uint32`: Entero sin signo de 32 bits.\n",
    "- `tf.uint64`: Entero sin signo de 64 bits.\n",
    "- `tf.bool`: Booleano.\n",
    "- `tf.string`: Cadenas de texto.\n",
    "- `tf.complex64`: Número complejo compuesto por dos floats de 32 bits.\n",
    "- `tf.complex128`: Número complejo compuesto por dos floats de 64 bits, también conocido como `tf.double`.\n",
    "- `tf.qint8`: Entero de 8 bits utilizado en cuantificación.\n",
    "- `tf.qint16`: Entero de 16 bits utilizado en cuantificación.\n",
    "- `tf.qint32`: Entero de 32 bits utilizado en cuantificación.\n",
    "- `tf.quint8`: Entero sin signo de 8 bits utilizado en cuantificación.\n",
    "- `tf.quint16`: Entero sin signo de 16 bits utilizado en cuantificación.\n",
    "\n",
    "Estos tipos de datos permiten que TensorFlow maneje eficientemente una amplia gama de datos para diferentes tipos de operaciones, incluyendo cálculos matemáticos, manipulación de imágenes, procesamiento de texto, y mucho más.\n",
    "\n",
    "podemos especificar el tipo de dato de los componentes del tensor, por ejemplo, float, con el parámetro dtype:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762a889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float16, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [5., 2., 3.]], dtype=float16)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz2=tf.constant([[1,2,3],[5,2,3]],dtype=tf.float16)\n",
    "matriz2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775afd1",
   "metadata": {},
   "source": [
    "### Se puede crear un tensor multidimensional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03500a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
       "array([[[1, 2],\n",
       "        [2, 3],\n",
       "        [4, 5]],\n",
       "\n",
       "       [[2, 3],\n",
       "        [1, 5],\n",
       "        [7, 3]]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un tensor (3 o más dimensiones)\n",
    "tensor=tf.constant([[[1,2],[2,3],[4,5]],\n",
    "                    [[2,3],[1,5],[7,3]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352869a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim  #2 matrices, de tres vectores, de dos posiciones cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d30304",
   "metadata": {},
   "source": [
    "El ejemplo anterior también se conoce como un tensor de rango 3 (3 dimensiones), sin embargo, un tensor puede tener una cantidad arbitraria (ilimitada) de dimensiones.\n",
    "\n",
    "Por ejemplo, podrías convertir una serie de imágenes en tensores con forma (224, 224, 3, 32), donde:\n",
    "* 224, 224 (las primeras 2 dimensiones) son la altura y anchura de las imágenes en píxeles.\n",
    "* 3 es el número de canales de color de la imagen (rojo, verde, azul).\n",
    "* 32 es el tamaño del lote (el número de imágenes que una red neuronal ve en un momento dado).\n",
    "\n",
    "Todas las variables anteriores que hemos creado son en realidad tensores. Pero también puedes escucharlas referidas con sus diferentes nombres (los que les dimos):\n",
    "* **escalar**: un solo número.\n",
    "* **vector**: un número con dirección (por ejemplo, velocidad del viento con dirección).\n",
    "* **matriz**: un array bidimensional de números.\n",
    "* **tensor**: un array de números n-dimensional (donde n puede ser cualquier número, un tensor de 0 dimensiones es un escalar, un tensor de 1 dimensión es un vector).\n",
    "\n",
    "Para añadir a la confusión, los términos matriz y tensor a menudo se usan indistintamente.\n",
    "\n",
    "En adelante, dado que estamos utilizando TensorFlow, todo lo que nos referimos y usamos serán tensores.\n",
    "\n",
    "Para más información sobre la diferencia matemática entre escalares, vectores y matrices, consulta la [publicación de álgebra visual de Math is Fun](https://www.mathsisfun.com/algebra/scalar-vector-matrix.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7352378",
   "metadata": {},
   "source": [
    "### crear tensores con `tf.Variable`\n",
    "- https://www.tensorflow.org/api_docs/python/tf/Variable\n",
    "\n",
    "También puedes (aunque raramente lo harás, porque cuando trabajas con datos, los tensores se crean automáticamente) crear tensores usando [`tf.Variable()`](https://www.tensorflow.org/api_docs/python/tf/Variable).\n",
    "\n",
    "La diferencia entre `tf.Variable()` y `tf.constant()` es que los tensores creados con `tf.constant()` son inmutables (no pueden cambiarse, solo pueden usarse para crear un nuevo tensor), mientras que, los tensores creados con `tf.Variable()` son mutables (pueden cambiarse).\n",
    "\n",
    "### Manipulando tensores `tf.Variable`\n",
    "\n",
    "Los tensores creados con `tf.Variable()` pueden ser modificados en su lugar utilizando métodos tales como:\n",
    "\n",
    "* [`.assign()`](https://www.tensorflow.org/api_docs/python/tf/Variable#assign) - asigna un valor diferente a un índice particular de un tensor variable.\n",
    "* [`.add_assign()`](https://www.tensorflow.org/api_docs/python/tf/Variable#assign_add) - añade a un valor existente y lo reasigna en un índice particular de un tensor variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468154eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mutable=tf.Variable([10,7])\n",
    "tensor_nomutable=tf.constant([10,7])\n",
    "tensor_mutable,tensor_nomutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3158bd61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\382820706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cambiar uno de los elementos en un mutable -> ERROR!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtensor_mutable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# cambiar uno de los elementos en un mutable -> ERROR!\n",
    "tensor_mutable[0]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "310234b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2,) dtype=int32, numpy=array([5, 7])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hay que usar assign\n",
    "tensor_mutable[0].assign(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81de7e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\1837065464.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#no se puede usar assign en un tensor constante\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtensor_nomutable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \"\"\")\n\u001b[1;32m--> 444\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "#no se puede usar assign en un tensor constante\n",
    "tensor_nomutable[0].assign(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f0d77b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int32, numpy=array([ 0,  1,  2,  3, 50])>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una variable tensor y asignar valores\n",
    "I = tf.Variable(np.arange(0, 5))\n",
    "I.assign([0, 1, 2, 3, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e56929c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int32, numpy=array([10, 11, 12, 13, 60])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#añadir 10 a todos los valores\n",
    "I.assign_add([10, 10, 10, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9fd1b",
   "metadata": {},
   "source": [
    "## crear tensores aleatorios\n",
    "#### tf.random.uniform y tf.random.normal \n",
    "\n",
    "Los tensores aleatorios son tensores de algún tamaño arbitrario que contienen números aleatorios.\n",
    "\n",
    "¿Por qué querrías crear tensores aleatorios?\n",
    "\n",
    "Esto es lo que las redes neuronales utilizan para inicializar sus pesos (patrones) que están intentando aprender en los datos.\n",
    "\n",
    "Por ejemplo, el proceso de aprendizaje de una red neuronal a menudo implica tomar un array n-dimensional aleatorio de números y refinarlos hasta que representen algún tipo de patrón (una manera comprimida de representar los datos originales).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e5f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1 = tf.random.Generator.from_seed(42) # semilla para 'reproducibilidad'\n",
    "random_1 = random_1.normal(shape=(3, 2)) # crear un tensor desde la distribución normal\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "\n",
    "# son iguales?\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b4a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [ 2,  5],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mezclar un tensor\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "\n",
    "# diferentes resultados cada vez\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "578d9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.45331386,  1.1487608 ],\n",
       "       [-1.2659091 , -0.47450137],\n",
       "       [ 2.006022  ,  0.28288034]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear utilizando semilla\n",
    "random1=tf.random.Generator.from_seed(50)\n",
    "tensor1=random1.normal(shape=(3,2))\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cb6288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 2.006022  ,  0.28288034],\n",
       "       [-1.2659091 , -0.47450137],\n",
       "       [ 0.45331386,  1.1487608 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mezclar utilizando semilla\n",
    "tensor1=tf.random.shuffle(tensor1,seed=42)\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149c6db",
   "metadata": {},
   "source": [
    "Prueba a ejecutar la celda anterior varias veces, ¿Por qué no sale siempre el mismo orden?\n",
    "\n",
    "Es debido a la regla #4 de la documentación de [`tf.random.set_seed()`](https://www.tensorflow.org/api_docs/python/tf/random/set_seed).\n",
    "\n",
    "> \"4. Si se establecen tanto la semilla global como la semilla de la operación: Ambas semillas se utilizan en conjunto para determinar la secuencia aleatoria.\"\n",
    "\n",
    "`tf.random.set_seed(42)` establece la semilla global, y el parámetro `seed` en `tf.random.shuffle(seed=42)` establece la semilla de la operación.\n",
    "\n",
    "Porque, \"Las operaciones que dependen de una semilla aleatoria en realidad la derivan de dos semillas: las semillas global y de nivel de operación.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "673807e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mezclar siempre en el mismo orden\n",
    "\n",
    "#global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# random seed de la operación\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e6facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [ 2,  5],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establece la semilla global\n",
    "tf.random.set_seed(42) # si comentas esto, obtienes siempre resultados diferentes\n",
    "\n",
    "#se usa solo la semilla global\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3424af0",
   "metadata": {},
   "source": [
    "### Otras formas de crear tensores\n",
    "\n",
    "Aunque raramente las uses (recuerda, muchas operaciones de tensores se realizan detrás de escena por ti), puedes usar [`tf.ones()`](https://www.tensorflow.org/api_docs/python/tf/ones) para crear un tensor de unos y [`tf.zeros()`](https://www.tensorflow.org/api_docs/python/tf/zeros) para crear un tensor de ceros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7915398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(3, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697a6a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(shape=(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe6080",
   "metadata": {},
   "source": [
    "También puedes convertir arrays de NumPy en tensores.\n",
    "\n",
    "Recuerda, la principal diferencia entre los tensores y los arrays de NumPy es que los tensores pueden ejecutarse en GPUs.\n",
    "\n",
    "🔑 Nota: Una matriz o tensor típicamente se representa por una letra mayúscula (por ejemplo, X o A) mientras que un vector se representa típicamente por una letra minúscula (por ejemplo, y o b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a0384d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24]),\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15],\n",
       "         [16, 17, 18],\n",
       "         [19, 20, 21],\n",
       "         [22, 23, 24]]])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32) # crear un array de numpy\n",
    "A = tf.constant(numpy_A,  \n",
    "                shape=[2, 4, 3]) # nota: la forma total (2*4*3) tiene que casar con el número de elementos del array\n",
    "numpy_A, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30437092",
   "metadata": {},
   "source": [
    "### Obteniendo información de los tensores (forma, rango, tamaño)\n",
    "Habrá momentos en los que querrás obtener diferentes piezas de información de tus tensores, en particular, debes conocer el siguiente vocabulario sobre tensores:\n",
    "\n",
    "- **Forma (shape)**: La longitud (número de elementos) de cada una de las dimensiones de un tensor.\n",
    "- **Rango (rank) **: El número de dimensiones de un tensor. Un escalar tiene rango 0, un vector tiene rango 1, una matriz tiene rango 2, un tensor tiene rango n.\n",
    "- **Eje o Dimensión (axis) **: Una dimensión particular de un tensor.\n",
    "- **Tamaño (size)**: El número total de elementos en el tensor.\n",
    "\n",
    "Especialmente utilizarás estos cuando estés intentando alinear las formas de tus datos con las formas de tu modelo. Por ejemplo, asegurándote de que la forma de tus tensores de imagen sea la misma que la forma de la capa de entrada de tu modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fd4758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create un tensor de rango 4  (4 dimensiones)\n",
    "rank_4_tensor = tf.zeros([2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72038323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87037c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo de datos de cada elemento: <dtype: 'float32'>\n",
      "número de dimensiones (rank): 4\n",
      "Forma del tensor: (2, 3, 4, 5)\n",
      "Elementos del eje 0 del tensor: 2\n",
      "Elementos del último eje del tensor: 5\n",
      "Número total de elementos (2*3*4*5): 120\n"
     ]
    }
   ],
   "source": [
    "print(\"tipo de datos de cada elemento:\", rank_4_tensor.dtype)\n",
    "print(\"número de dimensiones (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Forma del tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elementos del eje 0 del tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elementos del último eje del tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Número total de elementos (2*3*4*5):\", tf.size(rank_4_tensor).numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b26f13",
   "metadata": {},
   "source": [
    "Se pueden indexar tensores como en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bb2a189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dame los dos primeros elementos de cada dimensión\n",
    "rank_4_tensor[:2, :2, :2, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7408e656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor = tf.constant([[10, 7],\n",
    "                             [3, 4]])\n",
    "\n",
    "# Obtener el último elemento de cada fila\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4944e9",
   "metadata": {},
   "source": [
    "También puedes añadir dimensiones a tu tensor mientras mantienes la misma información presente usando `tf.newaxis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad09909d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4]])>,\n",
       " <tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       " array([[[10],\n",
       "         [ 7]],\n",
       " \n",
       "        [[ 3],\n",
       "         [ 4]]])>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# añadir una nueva dimensión (al final)\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis] # en Python \"...\" significa \"todas las dimensiones previas\"\n",
    "rank_2_tensor, rank_3_tensor # shape (2, 2), shape (2, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134d380",
   "metadata": {},
   "source": [
    "esto también se puede hacer con `tf.expand_dims()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60d742ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" significa último eje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05dc407",
   "metadata": {},
   "source": [
    "## Manipulando tensores (operaciones con tensores)\n",
    "\n",
    "Encontrar patrones en tensores (representación numérica de los datos) requiere manipularlos.\n",
    "\n",
    "De nuevo, cuando construyes modelos en TensorFlow, gran parte de este descubrimiento de patrones se hace por ti.\n",
    "\n",
    "### Operaciones básicas\n",
    "\n",
    "Puedes realizar muchas de las operaciones matemáticas básicas directamente en tensores usando operadores de Python, tales como, `+`, `-`, `*`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be7c2a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suma\n",
    "tensor = tf.constant([[10, 7], [3, 4]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "449a007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplicación (elemento a elemento)\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29c26f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resta\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cade1af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply, idéntico a '*' \n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96321d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# los tensores originales no se cambian cuando se utilizan estos operadores\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552accc9",
   "metadata": {},
   "source": [
    "### Multiplicación de matrices\n",
    "\n",
    "Una de las operaciones más comunes en los algoritmos de aprendizaje automático es la [multiplicación de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "TensorFlow implementa esta funcionalidad de multiplicación de matrices en el método [`tf.matmul()`](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul).\n",
    "\n",
    "Las dos reglas principales para recordar sobre la multiplicación de matrices son:\n",
    "1. Las dimensiones internas deben coincidir:\n",
    "  * `(3, 5) @ (3, 5)` no funcionará\n",
    "  * `(5, 3) @ (3, 5)` funcionará\n",
    "  * `(3, 5) @ (5, 3)` funcionará\n",
    "2. La matriz resultante tiene la forma de las dimensiones exteriores:\n",
    " * `(5, 3) @ (3, 5)` -> `(5, 5)`\n",
    " * `(3, 5) @ (5, 3)` -> `(3, 3)`\n",
    "\n",
    "> 🔑 **Nota:** '`@`' en Python es el símbolo para la multiplicación de matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b6a9ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor)\n",
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3651b92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idéntico al anterior\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1268b27",
   "metadata": {},
   "source": [
    "La multiplicación anterior funcionaba porque los dos eran tensores de 2,2, si creamos de dimensiones incompatibles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d78d00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  (3, 2) \n",
    "X = tf.constant([[1, 2],\n",
    "                 [3, 4],\n",
    "                 [5, 6]])\n",
    "\n",
    "#  (3, 2) \n",
    "Y = tf.constant([[7, 8],\n",
    "                 [9, 10],\n",
    "                 [11, 12]])\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fba410d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\1809164124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mY\u001b[0m \u001b[1;31m#error!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7215\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "X @ Y #error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb378ac",
   "metadata": {},
   "source": [
    "Intentar multiplicar matrices de dos tensores con forma `(3, 2)` genera errores porque las dimensiones internas no coinciden.\n",
    "\n",
    "Necesitamos:\n",
    "* Cambiar la forma de X a `(2, 3)` para que sea `(2, 3) @ (3, 2)`.\n",
    "* Cambiar la forma de Y a `(3, 2)` para que sea `(3, 2) @ (2, 3)`.\n",
    "\n",
    "Podemos hacer esto con:\n",
    "* [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape) - nos permite cambiar la forma de un tensor a una forma definida.\n",
    "* [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) - cambia las dimensiones de un tensor dado.\n",
    "\n",
    "![alineando dimensiones para el producto de matrices (dot product)](https://www.mathsisfun.com/algebra/images/matrix-multiply-b.svg)\n",
    "\n",
    "Probemos primero `tf.reshape()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46d9d514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recuerda\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dedcd35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  8,  9],\n",
       "       [10, 11, 12]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(Y, shape=(2, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96461aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ tf.reshape(Y, shape=(2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bdaa7",
   "metadata": {},
   "source": [
    "Funcionó, intentemos lo mismo con un `X` reconfigurado, excepto que esta vez usaremos [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) y `tf.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f188f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcc47c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba3672",
   "metadata": {},
   "source": [
    "Se puede obtener el mismo resultado con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e20abe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a=X, b=Y, transpose_a=True, transpose_b=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd7acf",
   "metadata": {},
   "source": [
    "Observa la diferencia en las formas resultantes al transponer `X` o reconfigurar `Y`.\n",
    "\n",
    "Esto se debe a la 2da regla mencionada anteriormente:\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)` hecho con `X @ tf.reshape(Y, shape=(2, 3))` \n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)` hecho con `tf.matmul(tf.transpose(X), Y)`\n",
    "\n",
    "Este tipo de manipulación de datos es un recordatorio: pasarás mucho de tu tiempo en el aprendizaje automático y trabajando con redes neuronales reconfigurando datos (en forma de tensores) para prepararlos para ser usados con varias operaciones (como alimentarlos a un modelo).\n",
    "\n",
    "### El dot product (producto punto)\n",
    "\n",
    "Multiplicar matrices de forma genérica también se conoce como el producto punto.\n",
    "\n",
    "Puedes realizar la operación `tf.matmul()` usando [`tf.tensordot()`](https://www.tensorflow.org/api_docs/python/tf/tensordot).\n",
    "\n",
    "`tf.tensordot()`:\n",
    "\n",
    "Permite realizar el producto punto entre tensores, especificando los ejes sobre los cuales se quiere realizar la operación.\n",
    "Es más flexible ya que puedes especificar los ejes a lo largo de los cuales el producto punto debe ser calculado. Esto significa que `tf.tensordot()` puede ser usado no solo para la multiplicación de matrices, sino también para operaciones más generales de producto punto.\n",
    "Puede manejar tensores de cualquier rango, y los ejes a lo largo de los cuales se realiza el producto punto pueden ser configurados, permitiendo así una gama más amplia de operaciones de álgebra tensorial más allá de la simple multiplicación de matrices.\n",
    "\n",
    "Las operaciones de producto punto (dot product) son fundamentales en álgebra lineal y tienen varias aplicaciones importantes, especialmente en el campo del aprendizaje automático y el procesamiento de señales. Aquí se describen varios tipos de operaciones de producto punto:\n",
    "1. **Producto Punto Escalar (Scalar Dot Product):**\n",
    "   - Este es el caso más simple y se aplica a vectores de la misma dimensión. El resultado es un escalar. Por ejemplo, el producto punto de dos vectores `a` y `b` se calcula como:\n",
    "   \n",
    "     $$\n",
    "     \\sum_{i=1}^{n} a_i b_i\n",
    "     $$\n",
    "\n",
    "2. **Multiplicación de Matrices (Matrix Multiplication):**\n",
    "   - Es una generalización del producto punto escalar a matrices. Si tienes dos matrices, A de tamaño $$ m \\times n $$ y B de tamaño $$ n \\times p $$, el resultado es una nueva matriz C de tamaño $$ m \\times p $$, donde cada elemento $$ C_{ij} $$ es el producto punto de la fila i de  A y la columna  j de  B:\n",
    "\n",
    "     $$\n",
    "     C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj}\n",
    "     $$\n",
    "\n",
    "3. **Producto Tensorial (Tensor Dot Product):**\n",
    "   - Esta operación extiende el concepto de producto punto a tensores de orden superior. En el contexto de tensores, el producto punto puede realizarse a lo largo de uno o más ejes especificados. Por ejemplo, si tienes dos tensores tridimensionales, puedes calcular el producto punto a lo largo de un eje particular, combinando las dimensiones correspondientes de cada tensor.\n",
    "\n",
    "\n",
    "4. **Producto Punto Interno (Inner Product):**\n",
    "   - Es similar al producto punto escalar, pero se usa en el contexto de espacios de dimensión superior. En matemáticas, el producto interior generaliza el concepto de producto punto a espacios vectoriales de dimensiones más altas.\n",
    "\n",
    "     $$\n",
    "     \\langle \\mathbf{a}, \\mathbf{b} \\rangle = \\sum_{i=1}^{n} a_i b_i\n",
    "     $$\n",
    "\n",
    "5. **Producto Punto Externo (Outer Product):**\n",
    "   - A diferencia del producto punto que produce un escalar (en el caso de vectores) o una matriz (en el caso de matrices), el producto externo toma dos vectores y produce una matriz. Si tienes dos vectores `a` y `b`, el producto externo es una matriz donde cada elemento es:\n",
    "\n",
    "     $$\n",
    "     C_{ij} = a_i b_j\n",
    "     $$\n",
    "\n",
    "6. **Convolution:**\n",
    "   - Aunque no es un producto punto en el sentido tradicional, la convolución en el procesamiento de señales y en redes neuronales convolucionales se puede conceptualizar como una operación de producto punto entre filtros y segmentos de la señal o imagen, especialmente cuando se implementa mediante operaciones de matriz.\n",
    "\n",
    "Cada uno de estos tipos de operaciones de producto punto tiene aplicaciones específicas y se elige en función del problema a resolver, la naturaleza de los datos y los objetivos del análisis o del modelo de aprendizaje automático.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1680949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza el producto X e Y (requiere la traspuesta de X)\n",
    "tf.tensordot(tf.transpose(X), Y, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1e7e6",
   "metadata": {},
   "source": [
    "### Cambiando el tipo de dato de un tensor\n",
    "\n",
    "A veces querrás alterar el tipo de dato predeterminado de tu tensor.\n",
    "\n",
    "Esto es común cuando quieres computar usando menos precisión (por ejemplo, números de punto flotante de 16 bits vs. números de punto flotante de 32 bits).\n",
    "\n",
    "Computar con menos precisión es útil en dispositivos con menor capacidad de cómputo como dispositivos móviles (porque menos bits, requieren menos espacio en las computaciones).\n",
    "\n",
    "Puedes cambiar el tipo de dato de un tensor usando [`tf.cast()`](https://www.tensorflow.org/api_docs/python/tf/cast).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7af62edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7, 7.4], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 7])>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor con tipo por defecto (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "\n",
    "# Crear un tensor con tipo por defecto(int32)\n",
    "C = tf.constant([1, 7])\n",
    "B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f8c32fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de float32 a float16 (precisión reducida)\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09ed0b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int32 to float32\n",
    "C = tf.cast(C, dtype=tf.float32)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62430791",
   "metadata": {},
   "source": [
    "### Obteniendo el valor absoluto\n",
    "A veces querrás los valores absolutos (todos los valores son positivos) de los elementos en tus tensores.\n",
    "\n",
    "Para hacerlo, puedes usar [`tf.abs()`](https://www.tensorflow.org/api_docs/python/tf/math/abs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "722387b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = tf.constant([-7, -10])\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2322ee",
   "metadata": {},
   "source": [
    "### Encontrando el mínimo, máximo, media, suma (agregación)\n",
    "\n",
    "Es posible agregar (realizar un cálculo en todo un tensor) tensores para encontrar cosas como el valor mínimo, valor máximo, media y suma de todos los elementos.\n",
    "\n",
    "Para hacerlo, los métodos de agregación típicamente tienen la sintaxis `reduce()_[acción]`, tales como:\n",
    "* [`tf.reduce_min()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_min) - encontrar el valor mínimo en un tensor.\n",
    "* [`tf.reduce_max()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_max) - encontrar el valor máximo en un tensor (útil cuando quieres encontrar la probabilidad de predicción más alta).\n",
    "* [`tf.reduce_mean()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean) - encontrar la media de todos los elementos en un tensor.\n",
    "* [`tf.reduce_sum()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum) - encontrar la suma de todos los elementos en un tensor.\n",
    "* **Nota:** típicamente, cada uno de estos está bajo el módulo `math`, por ejemplo, `tf.math.reduce_min()` pero puedes usar el alias `tf.reduce_min()`.\n",
    "\n",
    "Veámoslos en acción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7921d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([ 2, 46, 25, 57, 86, 62, 57, 30, 65, 58, 83, 57, 18, 95, 33,  0, 82,\n",
       "       22, 44, 84,  0, 99, 86, 56, 23, 86,  6, 95, 60, 63, 87, 40, 20, 83,\n",
       "       72, 64, 32,  1, 94, 67, 72, 26, 45, 81, 62, 49, 73, 83, 70, 44])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor con 50 valores random entre 0 y 100\n",
    "E = tf.constant(np.random.randint(low=0, high=100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97d90938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mínimo\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04066a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=99>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#máximo\n",
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f102ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=54>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#media\n",
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a0f1020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2745>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suma\n",
    "tf.reduce_sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d03e9",
   "metadata": {},
   "source": [
    "También puedes calcular la desviación estándar ([`tf.reduce_std()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_std)) y la varianza ([`tf.reduce_variance()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_variance)) de los elementos en un tensor usando métodos similares.\n",
    "\n",
    "### Encontrando el máximo y mínimo posicional\n",
    "\n",
    "¿Y cónmo se busca la posición en un tensor donde está el valor máximo?\n",
    "\n",
    "Esto es útil cuando quieres alinear tus etiquetas (digamos `['Verde', 'Azul', 'Rojo']`) con tu tensor de probabilidades de predicción (por ejemplo, `[0.98, 0.01, 0.01]`).\n",
    "\n",
    "En este caso, la etiqueta predicha (la que tiene la probabilidad de predicción más alta) sería `'Verde'`.\n",
    "\n",
    "Puedes hacer lo mismo para el mínimo (si es necesario) con lo siguiente:\n",
    "* [`tf.argmax()`](https://www.tensorflow.org/api_docs/python/tf/math/argmax) - encontrar la posición del elemento máximo en un tensor dado.\n",
    "* [`tf.argmin()`](https://www.tensorflow.org/api_docs/python/tf/math/argmin) - encontrar la posición del elemento mínimo en un tensor dado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4421e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([0.72353716, 0.40246822, 0.83161408, 0.18778498, 0.59395943,\n",
       "       0.13271066, 0.51486337, 0.96825219, 0.35256278, 0.18844455,\n",
       "       0.02418701, 0.73970864, 0.29409647, 0.56235161, 0.19198946,\n",
       "       0.47516714, 0.5799864 , 0.41018299, 0.41333635, 0.70265714,\n",
       "       0.49633263, 0.54030857, 0.82307685, 0.04836412, 0.0091889 ,\n",
       "       0.07678453, 0.64558563, 0.05141719, 0.99844597, 0.91875711,\n",
       "       0.54139259, 0.53916083, 0.8578127 , 0.2051635 , 0.00872412,\n",
       "       0.22493663, 0.83131279, 0.89433529, 0.42100545, 0.26250721,\n",
       "       0.31896887, 0.17471295, 0.82056182, 0.26470344, 0.93565609,\n",
       "       0.61338234, 0.17960954, 0.45824037, 0.16195915, 0.78934159])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crear un tensor con 50 valores entre 0 y 1\n",
    "F = tf.constant(np.random.random(50))\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfdcc2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=28>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscar la posición del elemento máximo de F\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f4a0880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=34>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscar la posición del elemento mínimo de F\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07a045d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La posición del valor máximo de F es: 28\n",
      "El valor máximo de F es: 0.9984459657426845\n",
      "Usando tf.argmax() para indexar F, el valor máximo de F es: 0.9984459657426845\n",
      "¿Son los dos valores máximos iguales (deberían serlo)? True\n"
     ]
    }
   ],
   "source": [
    "# Encuentra la posición del elemento máximo de F\n",
    "print(f\"La posición del valor máximo de F es: {tf.argmax(F).numpy()}\") \n",
    "print(f\"El valor máximo de F es: {tf.reduce_max(F).numpy()}\") \n",
    "print(f\"Usando tf.argmax() para indexar F, el valor máximo de F es: {F[tf.argmax(F)].numpy()}\")\n",
    "print(f\"¿Son los dos valores máximos iguales (deberían serlo)? {F[tf.argmax(F)].numpy() == tf.reduce_max(F).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77488b40",
   "metadata": {},
   "source": [
    "### Comprimiendo un tensor (eliminando todas las dimensiones unitarias)\n",
    "\n",
    "Si necesitas eliminar las dimensiones unitarias de un tensor (dimensiones de tamaño 1), puedes usar `tf.squeeze()`.\n",
    "\n",
    "* [`tf.squeeze()`](https://www.tensorflow.org/api_docs/python/tf/squeeze) - elimina todas las dimensiones de 1 de un tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11fb600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1, 1, 1, 50]), 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor de rango 5 con números entre 0 y 100\n",
    "G = tf.constant(np.random.randint(0, 100, 50), shape=(1, 1, 1, 1, 50))\n",
    "G.shape, G.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6298f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze G (eliminar todas las dimensiones 1)\n",
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed.shape, G_squeezed.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c167e5",
   "metadata": {},
   "source": [
    "### Codificación one-hot\n",
    "\n",
    "Si tienes un tensor de índices y te gustaría codificarlo en one-hot, puedes usar [`tf.one_hot()`](https://www.tensorflow.org/api_docs/python/tf/one_hot).\n",
    "\n",
    "También deberías especificar el parámetro `depth` (el nivel al que quieres codificar en one-hot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcb89103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una lista de índices\n",
    "some_list = [0, 1, 2, 3]\n",
    "\n",
    "# codificarlos en One hot\n",
    "tf.one_hot(some_list, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4057670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'activo!', b'inactivo!', b'inactivo!', b'inactivo!'],\n",
       "       [b'inactivo!', b'activo!', b'inactivo!', b'inactivo!'],\n",
       "       [b'inactivo!', b'inactivo!', b'activo!', b'inactivo!'],\n",
       "       [b'inactivo!', b'inactivo!', b'inactivo!', b'activo!']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especificar valores personalizados para on y off \n",
    "tf.one_hot(some_list, depth=4, on_value=\"activo!\", off_value=\"inactivo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddecb1",
   "metadata": {},
   "source": [
    "### Operaciones matemáticas ( log, raiz cuadrada, cuadrado...)\n",
    "\n",
    "Tensorflow también ofrece operaciones matemáticas como: \n",
    "\n",
    "* [`tf.square()`](https://www.tensorflow.org/api_docs/python/tf/math/square) - cuadrado de todos los valores de un tensor. \n",
    "* [`tf.sqrt()`](https://www.tensorflow.org/api_docs/python/tf/math/sqrt) - raíz cuadrada de todos los elementos de un tensor\n",
    "* [`tf.math.log()`](https://www.tensorflow.org/api_docs/python/tf/math/log) - logaritmo de todos los elementos (base 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f71a8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1  4  9 16 25 36 49 64 81], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "H = tf.constant(np.arange(1, 10))\n",
    "print(tf.square(H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dbc2682",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7368\\4028006509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#no debe ser entero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7215\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]"
     ]
    }
   ],
   "source": [
    "print(tf.sqrt(H)) #no debe ser entero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a7188bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.236068 , 2.4494898,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast a float32\n",
    "H = tf.cast(H, dtype=tf.float32)\n",
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f6d8018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9567b",
   "metadata": {},
   "source": [
    "## Tensores y NumPy\n",
    "\n",
    "Hemos visto algunos ejemplos de cómo los tensores interactúan con los arrays de NumPy, por ejemplo, utilizando arrays de NumPy para crear tensores.\n",
    "\n",
    "Los tensores también pueden ser convertidos a arrays de NumPy utilizando:\n",
    "\n",
    "* `np.array()` - pasa un tensor para convertirlo en un ndarray (el tipo de dato principal de NumPy).\n",
    "* `tensor.numpy()` - se llama en un tensor para convertirlo en un ndarray.\n",
    "\n",
    "Hacer esto es útil ya que hace que los tensores sean iterables, así como también nos permite usar cualquiera de los métodos de NumPy en ellos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c59dfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear un tensor desde un array de numpy\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "648fcfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir el tensor J a un np array\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26eef7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir tensor J a NumPy con .numpy()\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0a3ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor desde NumPy y desde un array\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.])) # será float64 (por NumPy)\n",
    "tensor_J = tf.constant([3., 7., 10.]) # será float32 (por defecto de Tensorflow)\n",
    "numpy_J.dtype, tensor_J.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddf829",
   "metadata": {},
   "source": [
    "## Usando `@tf.function`\n",
    "\n",
    "En tus aventuras con TensorFlow, podrías encontrarte con funciones de Python que tienen el decorador [`@tf.function`](https://www.tensorflow.org/api_docs/python/tf/function).\n",
    "\n",
    "Si no estás seguro de qué hacen los decoradores de Python, [lee la guía de RealPython sobre ellos](https://realpython.com/primer-on-python-decorators/).\n",
    "\n",
    "Pero en resumen, los decoradores modifican una función de una manera u otra.\n",
    "\n",
    "En el caso del decorador `@tf.function`, convierte una función de Python en un grafo de TensorFlow llamable. Que es una forma elegante de decir, si has escrito tu propia función de Python, y la decoras con `@tf.function`, cuando exportas tu código (para potencialmente ejecutar en otro dispositivo), TensorFlow intentará convertirlo en una versión más rápida de sí mismo (haciéndola parte de un grafo de computación).\n",
    "\n",
    "Para más información sobre esto, lee la guía [Mejor rendimiento con tf.function](https://www.tensorflow.org/guide/function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ead7dcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crear una función sencilla\n",
    "def function(x, y):\n",
    "  return x ** 2 + y\n",
    "\n",
    "x = tf.constant(np.arange(0, 10))\n",
    "y = tf.constant(np.arange(10, 20))\n",
    "function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee8f8751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear la misma función con el decorador tf.function\n",
    "@tf.function\n",
    "def tf_function(x, y):\n",
    "  return x ** 2 + y\n",
    "\n",
    "tf_function(x, y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d9553d2",
   "metadata": {},
   "source": [
    "Verás que no hay diferencia visible entre las dos funciones anterior. Las diferencias están en la forma de ejecutarse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842fc6c",
   "metadata": {},
   "source": [
    "## Encontrando acceso a GPUs\n",
    "\n",
    "¿cómo se puede verificar si hay una disponible?\n",
    "\n",
    "Puedes comprobar si tienes acceso a una GPU utilizando [`tf.config.list_physical_devices()`](https://www.tensorflow.org/guide/gpu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad6f0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f870790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 07:43:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.70                 Driver Version: 537.70       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX350         WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   38C    P8              N/A / ERR! |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe1961",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| **Hyperparameter** | **Typical value** |\n",
    "| --- | --- |\n",
    "| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |\n",
    "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
    "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
    "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
    "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n",
    "| Output activation | None, ReLU, logistic/tanh |\n",
    "| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n",
    "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n",
    "\n",
    "*Table 1: Typical architecture of a regression network. Source: Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e4d6e",
   "metadata": {},
   "source": [
    "> 🔑 **Nota:** Si tienes acceso a una GPU, automáticamente Tensorflow la usará cuando sea posible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
