{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3cf113a-dee8-4096-85a7-0f6cdae7dc90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "# Monitoriza el directorio logs y lee las líneas\n",
    "accessLines = spark.readStream.text(\"dbfs:/FileStore/logs\")\n",
    "\n",
    "# Parsea las líneas según el formato del log\n",
    "contentSizeExp = r'\\s(\\d+)$'\n",
    "statusExp = r'\\s(\\d{3})\\s'\n",
    "generalExp = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n",
    "timeExp = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\n",
    "hostExp = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\n",
    "\n",
    "logsDF = accessLines.select(regexp_extract('value', hostExp, 1).alias('host'),\n",
    "                         regexp_extract('value', timeExp, 1).alias('timestamp'),\n",
    "                         regexp_extract('value', generalExp, 1).alias('method'),\n",
    "                         regexp_extract('value', generalExp, 2).alias('endpoint'),\n",
    "                         regexp_extract('value', generalExp, 3).alias('protocol'),\n",
    "                         regexp_extract('value', statusExp, 1).cast('integer').alias('status'),\n",
    "                         regexp_extract('value', contentSizeExp, 1).cast('integer').alias('content_size'))\n",
    "\n",
    "# Contabiliza el número de accesos por status code\n",
    "statusCountsDF = logsDF.groupBy(logsDF.status).count()\n",
    "\n",
    "# Arranca el procesamiento en streaming, volcando datos en la consola.\n",
    "# Envía la salida al log de la consola del driver, no al notebook web. \n",
    "# Es útil en entornos tipo terminal, pero Databricks no muestra por defecto esa salida en las celdas del notebook.\n",
    "\n",
    "# query = ( statusCountsDF.writeStream.outputMode(\"complete\").format(\"console\").queryName(\"counts\").start() )\n",
    "# query.awaitTermination()\n",
    "\n",
    "# display(dataframe) es un comando específico de Databricks que:\n",
    "#   - Ejecuta una consulta de streaming en modo “append” o “update”.\n",
    "#   - Muestra los resultados visualmente dentro del notebook, en una tabla o gráfico interactivo.\n",
    "#   - Y lo hace internamente con su propio displayStreamQuery.\n",
    "\n",
    "display(statusCountsDF)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ejercicio ventanas",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
