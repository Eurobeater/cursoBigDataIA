{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e159755-b0e0-4c0f-a130-1464cf602b94",
   "metadata": {},
   "source": [
    "# Inicializa contexto Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973cccae-919b-476d-9892-f8f93ab3727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySpark libraries\n",
    "from pyspark import SparkContext, SparkConf \n",
    "\n",
    "# Initialize SparkConf\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Ejercicios RDD\")\n",
    "\n",
    "conf.set(\"spark.hadoop.fs.defaultFS\", \"file:///\")  # Sistema de archivos local\n",
    "conf.set(\"spark.hadoop.io.file.buffer.size\", \"4096\")\n",
    "\n",
    "# Initialize SparkContext\n",
    "sc = SparkContext(conf = conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d689a3-0d46-410a-8bca-1c1ddb92fadb",
   "metadata": {},
   "source": [
    "# 1. Crea un RDD y visualiza su contenido\n",
    "\n",
    "Ejercicio  \n",
    "Crea un RDD con los nombres de países más visitados del mundo. Muestra su contenido.  \n",
    "\n",
    "Datos  \n",
    "paises = [\"Francia\", \"España\", \"Estados Unidos\", \"China\", \"Italia\", \"Turquía\"]  \n",
    "\n",
    "Tarea\n",
    " - Crear un RDD a partir de la lista de países (usar función parallelize de SparkContext).\n",
    " - Mostrar su contenido usando collect().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d31c7-e38d-4c3d-a00e-1ad3e362c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "paises = [\"Francia\", \"España\", \"Estados Unidos\", \"China\", \"Italia\", \"Turquía\"]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con la lista.\n",
    "rdd = sc.parallelize(paises)\n",
    "\n",
    "# - Mostrar su contenido usando collect(). collect() es una acción que recupera todos los elementos del RDD y los devuelve como una lista.\n",
    "rdd.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e999a-e47e-41e9-a507-c4ea87c70025",
   "metadata": {},
   "source": [
    "# 2. map(): Transformar datos  \n",
    "Aplica una función a cada elemento del RDD y devuelve un nuevo RDD.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.map.html\n",
    "\n",
    "Ejercicio  \n",
    "Tenemos las temperaturas promedio (en °C) de las principales ciudades del mundo en una lista. Convierte estas temperaturas a grados Fahrenheit.  \n",
    "\n",
    "Datos  \n",
    "temperaturas_c = [20, 15, 30, 25, 10]\n",
    "\n",
    "Tarea\n",
    " - Crear un RDD con las temperaturas.\n",
    " - Convertir cada temperatura de °C a °F usando la fórmula: (°C × 9/5) + 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21788b-c90c-4202-84cc-9fa9f7139c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "temperaturas_c = [20, 15, 30, 25, 10]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con las temperaturas\n",
    "\n",
    "\n",
    "# - Convertir temperaturas a grados Fahrenheit\n",
    "\n",
    "# - Mostrar su contenido usando collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81495387-5173-4a4b-9b3b-a11da2aba787",
   "metadata": {},
   "source": [
    "# 3. filter(): Filtrar datos\n",
    "Devuelve un nuevo RDD que contiene solo los elementos que cumplen con la condición dada.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.filter.html\n",
    "\n",
    "Ejercicio  \n",
    "De una lista de alturas de montañas (en metros), selecciona solo las montañas que superen los 3000 metros.  \n",
    "\n",
    "Datos  \n",
    "alturas_montanas = [8848, 8611, 2825, 4500, 1500, 3100]\n",
    "\n",
    "Tarea\n",
    " - Crear un RDD con las alturas.\n",
    " - Filtrar las alturas mayores a 3000 metros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018dfedf-27db-46d7-a178-659dd812ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "alturas_montanas = [8848, 8611, 2825, 4500, 1500, 3100]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un rdd con las alturas\n",
    "\n",
    "\n",
    "# - Filtrar las alturas mayores que 3000\n",
    "\n",
    "# - Mostrar su contenido usando collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d28b3f-de9b-4490-8372-81062e50900f",
   "metadata": {},
   "source": [
    "# 4. flatMap(): Generar múltiples elementos por entrada\n",
    "Similar a map, pero cada elemento de entrada puede ser mapeado a cero o más elementos de salida (aplana el resultado).\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.flatMap.html\n",
    "\n",
    "Ejercicio  \n",
    "Divide las siguientes frases en palabras individuales.  \n",
    "\n",
    "Datos  \n",
    "frases = [\"El león es el rey de la selva\", \"Los elefantes son los mamíferos terrestres más grandes\", \"Las ballenas son gigantes del océano\"]\n",
    "\n",
    "Tarea\n",
    " - Crear un RDD con las frases.\n",
    " - Usar flatMap para dividir cada frase en palabras (la función split divide una cadena por el separador indicado).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228b4cc-4792-43b3-a9b8-dfbbc87fda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "frases = [\"El león es el rey de la selva\", \"Los elefantes son los mamíferos terrestres más grandes\", \"Las ballenas son gigantes del océano\"]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un rdd con las frases\n",
    "\n",
    "# - Dividir cada frase en palabras\n",
    "\n",
    "# - Mostrar su contenido usando collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd6ae8-d6fa-4571-a4af-3d6b3924b178",
   "metadata": {},
   "source": [
    "# 5. reduce(): Agregar valores\n",
    "Agrega los elementos del RDD usando una función de reducción (combinación).\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.reduce.html \n",
    "\n",
    "Ejercicio  \n",
    "Calcula el total de puntos de una temporada de un equipo de fútbol sumando los puntos de cada partido.  \n",
    "\n",
    "Datos\n",
    "puntos_partidos = [3, 1, 0, 3, 3, 1]\n",
    "\n",
    " Tarea\n",
    " - Crear un RDD con los puntos de cada partido.\n",
    " - Usar reduce para obtener la suma total de puntos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5bff1-5316-43b7-9c83-a0ba1728fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "puntos_partidos = [3, 1, 0, 3, 3, 1]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con los puntos de cada partido.\n",
    "\n",
    "# - Usar reduce para obtener la suma total de puntos.\n",
    "\n",
    "# - Imprimir resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396b98c-689e-4118-8319-370df8576284",
   "metadata": {},
   "source": [
    "# 6. groupBy(): Agrupar datos\n",
    "Agrupa los elementos del RDD usando una función de agrupamiento.  \n",
    "  - https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.groupBy.html\n",
    "\n",
    "\n",
    "Ejercicio  \n",
    "Agrupa los nombres de animales según su longitud (número de letras).  \n",
    " \n",
    " \n",
    "Datos  \n",
    "animales = [\"gato\", \"elefante\", \"perro\", \"jirafa\", \"pez\", \"león\"]\n",
    "\n",
    " Tarea\n",
    " - Crear un RDD con los nombres de los animales.\n",
    " - Agrupar los animales por la longitud de sus nombres (función len()).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c09126-a0c9-493f-abb5-3fb9626aa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "animales = [\"gato\", \"elefante\", \"perro\", \"jirafa\", \"pez\", \"león\"]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con los nombres de los animales.\n",
    "\n",
    "# - Agrupar los animales por la longitud de sus nombres.\n",
    "\n",
    "# - Convertir a lista con collect() y recorrer con un bucle para mostrar longitud y lista del iterable grupo\n",
    "\n",
    "for longitud, grupo in rdd_animales_agrupados.collect():\n",
    "    print(f\"Longitud: {longitud}, grupo: {list(grupo)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada47cd1-07ba-465e-9c7b-0a0d2d691e27",
   "metadata": {},
   "source": [
    "# 7. distinct(): Eliminar duplicados\n",
    "Devuelve un nuevo RDD que contiene solo elementos distintos del RDD original.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.distinct.html\n",
    "\n",
    "Ejercicio  \n",
    "Tienes una lista de destinos turísticos visitados por diferentes personas. Obtén una lista de destinos únicos.  \n",
    "\n",
    "Datos  \n",
    "destinos = [\"París\", \"Nueva York\", \"Londres\", \"París\", \"Tokio\", \"Londres\"]\n",
    "\n",
    "Tarea\n",
    " - Crear un RDD con los destinos.\n",
    " - Obtener una lista de destinos únicos usando distinct().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069793a-3e3c-424e-beb7-2764ecf0a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "destinos = [\"París\", \"Nueva York\", \"Londres\", \"París\", \"Tokio\", \"Londres\"]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con los destinos.\n",
    "\n",
    "# - Obtener una lista de destinos únicos usando distinct().\n",
    "\n",
    "# - Mostrar su contenido usando collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320c868-3017-44df-99f7-d5d41130f4ab",
   "metadata": {},
   "source": [
    "# 8. sortBy(): Ordenar datos\n",
    "Devuelve un nuevo RDD ordenado según una función de ordenamiento.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.sortBy.html\n",
    "\n",
    "Ejercicio  \n",
    "Tienes una lista de edades de estudiantes. Ordena las edades de menor a mayor.  \n",
    " \n",
    "Datos  \n",
    "edades = [21, 19, 22, 20, 18, 23]\n",
    "\n",
    "Tarea\n",
    " - Crear un RDD con las edades.\n",
    " - Ordenar las edades de menor a mayor usando sortBy().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fd544-fdff-45cc-9083-e8b6f3b87054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "edades = [21, 19, 22, 20, 18, 23]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con las edades.\n",
    "\n",
    "# - Ordenar las edades de menor a mayor usando sortBy().\n",
    "\n",
    "# - Mostrar su contenido usando collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82433a4c-57f5-479c-b6f2-6326f1c20220",
   "metadata": {},
   "source": [
    "# 9. count(): Contar elementos\n",
    "Devuelve el número de elementos en el RDD.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.count.html\n",
    "\n",
    "Calcula cuántos nombres hay en una lista de personas invitadas a una fiesta.  \n",
    " \n",
    " \n",
    "Datos  \n",
    "invitados = [\"Carlos\", \"Ana\", \"Luis\", \"Sofía\", \"Carlos\", \"María\"]\n",
    "\n",
    " Tarea\n",
    " - Crear un RDD con los nombres de los invitados.\n",
    " - Contar cuántos nombres hay en total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ed76b-a2c5-4b13-9310-ddac84049df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "invitados = [\"Carlos\", \"Ana\", \"Luis\", \"Sofía\", \"Carlos\", \"María\"]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con los nombres de los invitados.\n",
    "\n",
    "# - Contar cuántos nombres hay en total.\n",
    "\n",
    "# - Imprimir el total de invitados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225aee21-8970-45ca-891c-36c9950c03ed",
   "metadata": {},
   "source": [
    "# 10. take(): Obtener los primeros elementos\n",
    "Devuelve una lista con los primeros n elementos del RDD.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.take.html\n",
    "\n",
    "De una lista de puntuaciones de videojuegos, muestra las 3 puntuaciones más altas.  \n",
    " \n",
    " \n",
    "Datos  \n",
    "puntuaciones = [50, 80, 100, 40, 90, 70]\n",
    "\n",
    " Tarea\n",
    " - Crear un RDD con las puntuaciones.\n",
    " - Mostrar las 3 puntuaciones más altas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cef891-494f-42aa-b2fd-6ab2e9af9ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "puntuaciones = [50, 80, 100, 40, 90, 70]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con las puntuaciones.\n",
    "\n",
    "# - Obtener un RDD con las 3 puntuaciones más altas.\n",
    "\n",
    "# - Mostrar su contenido usando collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b19f5-00a2-46e2-a2df-3d230dd59ade",
   "metadata": {},
   "source": [
    "# 11. saveAsTextFile(): Guardar resultados\n",
    "Guarda el contenido del RDD como un archivo de texto en la ruta especificada.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.saveAsTextFile.html\n",
    "  \n",
    "De una lista de nombres de películas, guarda los nombres en un archivo de texto.  \n",
    " \n",
    " \n",
    "Datos  \n",
    "peliculas = [\"Inception\", \"Avatar\", \"The Dark Knight\", \"Titanic\", \"Interstellar\"]\n",
    "\n",
    "Tarea\n",
    " - Crear un RDD con los nombres de las películas.\n",
    " - Guardar los nombres en un archivo de texto llamado \"peliculas.txt\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf49d61-4a89-4a33-850c-5f73ce307e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "peliculas = [\"Inception\", \"Avatar\", \"The Dark Knight\", \"Titanic\", \"Interstellar\"]\n",
    "\n",
    "# Tarea\n",
    "# - Crear un RDD con los nombres de las películas.\n",
    "\n",
    "# - Guardar los nombres en un archivo de texto llamado \"peliculas.txt\".\n",
    "rdd_peliculas.saveAsTextFile(\"file:///c:/users/acalv/peliculas.txt\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d74e23-e116-43a8-8295-e26067f34854",
   "metadata": {},
   "source": [
    "# 12. textFile(): Carga un fichero en un RDD\n",
    "Lee un archivo de texto y lo convierte en un RDD.\n",
    "\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.textFile.html\n",
    "\n",
    "Tarea\n",
    "- Leer el fichero 1800.csv del directorio BDASpark (\"file:///c:/BDASpark/1800.csv\")\n",
    "- Mostrar las líneas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c518e8e4-bf95-4308-b685-664ea7aaf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Leer el fichero 1800.csv del directorio BDASpark (\"file:///c:/BDASpark/1800.csv\")\n",
    "\n",
    "# - Mostrar las líneas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf9153-5bf5-4d2a-b621-23c3665de1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
