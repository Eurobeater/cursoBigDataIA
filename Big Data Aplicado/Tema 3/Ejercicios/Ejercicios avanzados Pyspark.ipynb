{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aefdde03-0857-4239-b384-7fa3c5083c8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Películas más votadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030bf8f7-abe9-4626-b8e2-de2f498794f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sin nombre, solo tabla Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de075843-6c9d-414f-b5f7-0b2c7ab6d652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n|movieID|count|\n+-------+-----+\n|     50|  583|\n|    258|  509|\n|    100|  508|\n|    181|  507|\n|    294|  485|\n|    286|  481|\n|    288|  478|\n|      1|  452|\n|    300|  431|\n|    121|  429|\n+-------+-----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "\n",
    "# Definir el esquema del DataFrame de ratings\n",
    "schema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])\n",
    "\n",
    "# Cargar el archivo de ratings u-data en un DataFrame, con separador el tabulador \\t\n",
    "moviesDF = spark.read.option(\"sep\", \"\\t\").schema(schema).csv(\"dbfs:/FileStore/u.data\")\n",
    "\n",
    "# Funciones tipo SQL para agrupar y ordenar\n",
    "topMovieIDs = moviesDF.groupBy(\"movieID\").count().orderBy(func.desc(\"count\"))\n",
    "\n",
    "# Top 10\n",
    "topMovieIDs.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "866be386-5ec8-4a26-9677-a69fbe6c8bca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Con nombre, haciendo inner join con películas (u.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f9259d-af09-4309-a8f0-4587bbbdcb9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n|               Title|Ratings|\n+--------------------+-------+\n|    Star Wars (1977)|    583|\n|      Contact (1997)|    509|\n|        Fargo (1996)|    508|\n|Return of the Jed...|    507|\n|    Liar Liar (1997)|    485|\n|English Patient, ...|    481|\n|       Scream (1996)|    478|\n|    Toy Story (1995)|    452|\n|Air Force One (1997)|    431|\n|Independence Day ...|    429|\n+--------------------+-------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Definir el esquema del DataFrame de ratings\n",
    "esquemaRatings = StructType([\n",
    "    StructField(\"UserID\", IntegerType(), True),\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"Rating\", IntegerType(), True),\n",
    "    StructField(\"Timestamp\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Cargar el archivo de ratings u-data en un DataFrame, con separador el tabulador \\t\n",
    "dfRatings = spark.read.csv(\"dbfs:/FileStore/u.data\", sep=\"\\t\", schema=esquemaRatings, header=False)\n",
    "\n",
    "# Definir esquema para el DataFrame de películas\n",
    "esquemaPeliculas = StructType([\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"ReleaseDate\", StringType(), True),\n",
    "    StructField(\"EmptyColumn\", StringType(), True),\n",
    "    StructField(\"IMDB_URL\", StringType(), True),\n",
    "    StructField(\"Unknown\", IntegerType(), True),\n",
    "    StructField(\"Action\", IntegerType(), True),\n",
    "    StructField(\"Adventure\", IntegerType(), True),\n",
    "    StructField(\"Animation\", IntegerType(), True),\n",
    "    StructField(\"Children\", IntegerType(), True),\n",
    "    StructField(\"Comedy\", IntegerType(), True),\n",
    "    StructField(\"Crime\", IntegerType(), True),\n",
    "    StructField(\"Documentary\", IntegerType(), True),\n",
    "    StructField(\"Drama\", IntegerType(), True),\n",
    "    StructField(\"Fantasy\", IntegerType(), True),\n",
    "    StructField(\"FilmNoir\", IntegerType(), True),\n",
    "    StructField(\"Horror\", IntegerType(), True),\n",
    "    StructField(\"Musical\", IntegerType(), True),\n",
    "    StructField(\"Mystery\", IntegerType(), True),\n",
    "    StructField(\"Romance\", IntegerType(), True),\n",
    "    StructField(\"SciFi\", IntegerType(), True),\n",
    "    StructField(\"Thriller\", IntegerType(), True),\n",
    "    StructField(\"War\", IntegerType(), True),\n",
    "    StructField(\"Western\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Cargar el archivo de películas en un DataFrame, con separador |\n",
    "dfPeliculas = spark.read.csv(\"dbfs:/FileStore/u.item\", sep=\"|\", schema=esquemaPeliculas, header=False)\n",
    "\n",
    "# Mostrar las 10 películas con más votos\n",
    "dfRatingsNombres = dfRatings.join(dfPeliculas,on=\"MovieID\",how=\"inner\")\n",
    "\n",
    "dfRatingsAgrupados = dfRatingsNombres.groupBy(\"Title\").agg(F.count(\"Title\").alias(\"Ratings\")).orderBy(\"Ratings\",ascending=False)\n",
    "dfRatingsAgrupados.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a48cf54a-3c5b-4316-953b-1add9bbbc77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Con un diccionario, UDF y broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de445b87-228c-4d7f-a4b0-b45a8b978956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------------------+\n|movieID|count|movieTitle                   |\n+-------+-----+-----------------------------+\n|50     |583  |Star Wars (1977)             |\n|258    |509  |Contact (1997)               |\n|100    |508  |Fargo (1996)                 |\n|181    |507  |Return of the Jedi (1983)    |\n|294    |485  |Liar Liar (1997)             |\n|286    |481  |English Patient, The (1996)  |\n|288    |478  |Scream (1996)                |\n|1      |452  |Toy Story (1995)             |\n|300    |431  |Air Force One (1997)         |\n|121    |429  |Independence Day (ID4) (1996)|\n+-------+-----+-----------------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "import codecs\n",
    "\n",
    "# Genera un diccionario con código y nombre de película\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    lines = sc.textFile(\"dbfs:/FileStore/u.item\")\n",
    "    collected_lines = lines.collect()  # Convierte el RDD en una lista\n",
    "    for line in collected_lines:\n",
    "        fields = line.split('|')\n",
    "        movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "# Carga el diccionario en una variable distribuida a todos los nodos con broadcast\n",
    "nameDict = spark.sparkContext.broadcast(loadMovieNames())\n",
    "\n",
    "# Crea el esquema de rating\n",
    "schema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])\n",
    "\n",
    "# Carga df de ratings\n",
    "moviesDF = spark.read.option(\"sep\", \"\\t\").schema(schema).csv(\"dbfs:/FileStore/u.data\")\n",
    "\n",
    "movieCounts = moviesDF.groupBy(\"movieID\").count()\n",
    "\n",
    "# Crea una función definida por usuario (UDF) para buscar nombres de películas en el diccionario distribuido a partir del código\n",
    "def lookupName(movieID):\n",
    "    return nameDict.value[movieID]\n",
    "\n",
    "lookupNameUDF = func.udf(lookupName)\n",
    "\n",
    "# Añade la columna nombre de película usando la función UDF\n",
    "moviesWithNames = movieCounts.withColumn(\"movieTitle\", lookupNameUDF(func.col(\"movieID\")))\n",
    "\n",
    "# Ordena los resultados\n",
    "sortedMoviesWithNames = moviesWithNames.orderBy(func.desc(\"count\"))\n",
    "\n",
    "# Muestra los 10 primeros\n",
    "sortedMoviesWithNames.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3df213d1-b2f6-433f-8165-4f146aa8da42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Obtener una lista de nombres de películas y un diccionario con el número de votos en cada puntuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4f23e6b-16ae-4988-a617-01c28bb19c79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Nos quedamos con las columnas MovieID y Rating\n",
    "dfRatings = dfRatings.select(\"MovieID\", \"Rating\")\n",
    "\n",
    "# Convertir el DataFrame de ratings a un RDD de filas\n",
    "rddFilas = dfRatings.rdd\n",
    "\n",
    "# Convertir el RDD de filas a un RDD de tuplas\n",
    "rddTuplas = rddFilas.map(lambda fila: (fila[0], (fila[1],1)))\n",
    "\n",
    "# Función para crear un diccionario con el número de votos para cada puntuación\n",
    "def crearRatingDict(tuplas):\n",
    "    RatingDict = {}\n",
    "    for rating, cont in tuplas:\n",
    "        if rating in RatingDict:\n",
    "            RatingDict[rating] += cont\n",
    "        else:\n",
    "            RatingDict[rating] = cont\n",
    "    return RatingDict\n",
    "\n",
    "# Agrupar por MovieID y agregar las puntuaciones\n",
    "rddRatingsAgrupados = rddTuplas.groupByKey().mapValues(crearRatingDict)\n",
    "\n",
    "# Volver a convertir a dataframe y hacer join con películas para obtener el nombre\n",
    "\n",
    "# Mostrar 10 películas con su nombre y puntuaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61e1202d-7d0a-4ce2-b434-03f80316e210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Superhéroe más relacionado\n",
    "En cada línea aparece un código de superhéroe y los códigos de otros superhéroes que aparecen con él en algún comic. Puede aparecer repetido en más de una línea.\n",
    "\n",
    "Ficheros: Marvel-names.txt, Marvel-graph.txt\n",
    "\n",
    "Obtener cuál es el superhéroe que más relaciones tiene con otros superhéroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1497bedb-8db4-45d5-96c0-ce8b7b83b806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Distancia entre superhéroes\n",
    "Grado de separación entre dos superhéroes, calculándolo a partir de las apariciones conjuntas en un comic.\n",
    "\n",
    "Utilizamos algoritmo Breadth-first search: recorre un árbol o grafo nivel por nivel, comenzando desde la raíz (o nodo inicial) y explorando todos los nodos vecinos en el nivel actual antes de moverse al siguiente nivel.\n",
    "\n",
    "BFS es útil para encontrar la ruta más corta en grafos no ponderados y para explorar todos los nodos a una cierta \"profundidad\" del nodo inicial.\n",
    "\n",
    "Pasos del algoritmo:\n",
    "\n",
    "- Inicialización:\n",
    "\n",
    "    - Coloca el nodo inicial en una cola (queue).\n",
    "    - Marca el nodo inicial como visitado.\n",
    "\n",
    "- Proceso de recorrido:\n",
    "\n",
    "    - Mientras la cola no esté vacía:\n",
    "        - Saca (dequeue) el nodo al frente de la cola.\n",
    "        - Procesa el nodo (por ejemplo, imprime su valor).\n",
    "        - Para cada nodo vecino no visitado:\n",
    "            - Marca el vecino como visitado.\n",
    "            - Añade (enqueue) el vecino a la cola.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaec909e-dac0-4f24-96fc-5a1ef9359a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\nB\nC\nD\nE\nF\nG\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo en Python:\n",
    "from collections import deque\n",
    "\n",
    "def bfs(tree, start_node):\n",
    "    visited = set()\n",
    "    queue = deque([start_node])\n",
    "    visited.add(start_node)\n",
    "    \n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        print(node)  # Procesa el nodo\n",
    "        \n",
    "        for neighbor in tree[node]:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "# Ejemplo de uso\n",
    "tree = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['D', 'E'],\n",
    "    'C': ['F', 'G'],\n",
    "    'D': [],\n",
    "    'E': [],\n",
    "    'F': [],\n",
    "    'G': []\n",
    "}\n",
    "\n",
    "bfs(tree, 'A')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ejercicios avanzados Pyspark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
