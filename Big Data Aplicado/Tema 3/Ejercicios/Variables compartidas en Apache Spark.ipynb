{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f480180b-a455-4f66-a5d3-52af40595e08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Variables Compartidas en Apache Spark\n",
    "\n",
    "## Introducción\n",
    "Las variables compartidas son tipos de variables especiales que se pueden usar dentro de las tareas de Spark. Aunque se crean en el Driver, se actualizan y se les da uso en los workers, dentro de cada tarea de Spark.\n",
    "\n",
    "Las variables compartidas permiten:\n",
    "- **Broadcast**: Distribuir datos de solo lectura a todos los nodos\n",
    "- **Acumuladores**: Agregar valores desde los ejecutores al driver\n",
    "\n",
    "Son esenciales para optimizar operaciones y recolectar métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9582fc-acdf-4b56-aeb3-123e53b358e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Broadcast Variables\n",
    "**Propiedades:**\n",
    "- Datos de solo lectura\n",
    "- Almacenados en caché en cada nodo\n",
    "- Útiles para tablas de lookup grandes\n",
    "\n",
    "**Consideraciones:**\n",
    "- Usar para datos que caben en memoria y > 100KB\n",
    "- No modificar después de crear\n",
    "- Limpiar variables broadcast después de usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330584b6-7882-4e12-8b25-c8d0ac82ac64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('user1', 'United States'), ('user2', 'United Kingdom'), ('user3', 'India'), ('user4', 'Desconocido')]\n"
     ]
    }
   ],
   "source": [
    "### Ejemplo: Mapeo de Códigos de País\n",
    "\n",
    "# Datos de muestra\n",
    "data = [\n",
    "    (\"user1\", \"US\"),\n",
    "    (\"user2\", \"UK\"),\n",
    "    (\"user3\", \"IN\"),\n",
    "    (\"user4\", \"AU\")\n",
    "]\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "# Diccionario de mapeo de códigos\n",
    "country_map = {\"US\": \"United States\", \"UK\": \"United Kingdom\", \"IN\": \"India\"}\n",
    "\n",
    "# Crear variable broadcast\n",
    "broadcast_var = sc.broadcast(country_map)\n",
    "\n",
    "# Función para mapear códigos usando broadcast\n",
    "def map_country(user):\n",
    "    code = user[1]\n",
    "    return (user[0], broadcast_var.value.get(code, \"Desconocido\"))\n",
    "\n",
    "resultado = rdd.map(map_country).collect()\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b0b9c0-6e7a-441e-94d3-0404a558a73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Acumuladores\n",
    "**Propiedades:**\n",
    "- Variables de solo adición\n",
    "- Suma agregada disponible en driver\n",
    "- Útiles para contadores o métricas  \n",
    "\n",
    "**Importante:**\n",
    "- Solo el driver puede leer el valor final\n",
    "- Se actualizan una vez por tarea con éxito\n",
    "- Usar acciones para garantizar ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b39efeaf-44da-4002-ad02-187d23aa6501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errores detectados: 2\n"
     ]
    }
   ],
   "source": [
    "### Ejemplo: Contar Registros Inválidos\n",
    "\n",
    "# Inicializar acumulador\n",
    "acumulador_errores = sc.accumulator(0)\n",
    "\n",
    "# Datos con posibles errores\n",
    "datos = [\"123\", \"456\", \"abc\", \"789\", \"def\"]\n",
    "rdd = sc.parallelize(datos)\n",
    "\n",
    "def validar_numero(texto):\n",
    "    if texto.isdigit():\n",
    "        return int(texto)\n",
    "    else:\n",
    "        acumulador_errores.add(1)  # Incrementar acumulador\n",
    "        return None\n",
    "\n",
    "numeros = rdd.map(validar_numero)\n",
    "\n",
    "# Forzar ejecución para actualizar acumulador\n",
    "numeros.count()\n",
    "\n",
    "print(\"Errores detectados:\", acumulador_errores.value)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Variables compartidas en Apache Spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
